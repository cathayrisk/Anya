import os
import streamlit as st
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.prompts import PromptTemplate
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode, tools_condition
import inspect
from typing import Callable, TypeVar
import time

st.set_page_config(
    page_title="Anya",
    layout="wide",
    page_icon="ğŸ¥œ",
    initial_sidebar_state="collapsed"
)

# --- 1. Streamlit session_state åˆå§‹åŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = [AIMessage(content="å—¨å—¨ï½å®‰å¦®äºä¾†äº†ï¼ğŸ‘‹ æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºçš„å—ï¼Ÿ")]
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "gpt-4.1"
if "current_model" not in st.session_state:
    st.session_state.current_model = None
if "llm" not in st.session_state:
    st.session_state.llm = None

# --- 2. LLM åˆå§‹åŒ– ---
def ensure_llm():
    if (
        st.session_state.llm is None
        or st.session_state.current_model != st.session_state.selected_model
    ):
        st.session_state.llm = ChatOpenAI(
            model=st.session_state.selected_model,
            openai_api_key=st.secrets["OPENAI_KEY"],
            temperature=0.0,
            streaming=True,
        )
        st.session_state.current_model = st.session_state.selected_model

ensure_llm()

# --- 3. å·¥å…·å®šç¾© ---

@tool
def ddgs_search(query: str) -> str:
    """DuckDuckGo æœå°‹ï¼ˆåŒæ™‚æŸ¥è©¢ç¶²é èˆ‡æ–°èï¼Œå›å‚³ markdown æ¢åˆ—æ ¼å¼ä¸¦é™„ä¾†æºï¼‰ã€‚"""
    try:
        from duckduckgo_search import DDGS
        ddgs = DDGS()
        web_results = ddgs.text(query, region="wt-wt", safesearch="moderate", max_results=5)
        news_results = ddgs.news(query, region="wt-wt", safesearch="moderate", max_results=5)
        all_results = []
        if isinstance(web_results, list):
            all_results.extend(web_results)
        if isinstance(news_results, list):
            all_results.extend(news_results)
        docs = []
        sources = []
        for item in all_results:
            title = item.get("title", "ç„¡æ¨™é¡Œ")
            link = item.get("href", "") or item.get("link", "") or item.get("url", "")
            snippet = item.get("body", "") or item.get("snippet", "")
            docs.append(f"- [{title}]({link})\n  > {snippet}")
            if link:
                sources.append(link)
        if not docs:
            return "No results found."
        markdown_content = "\n".join(docs)
        source_block = "\n\n## ä¾†æº\n" + "\n".join(sources)
        return markdown_content + source_block
    except Exception as e:
        return f"Error from DuckDuckGo: {e}"

@tool
def datetime_tool() -> str:
    """ç¢ºèªç•¶å‰çš„æ—¥æœŸå’Œæ™‚é–“ã€‚"""
    return datetime.now().isoformat()

# ä½ çš„ deep_thought_tool
def analyze_deeply(input_question: str) -> str:
    """ä½¿ç”¨OpenAIçš„æ¨¡å‹ä¾†æ·±å…¥åˆ†æå•é¡Œä¸¦è¿”å›çµæœã€‚"""
    prompt_template = PromptTemplate(
        template="""è«‹åˆ†æä»¥ä¸‹å•é¡Œï¼Œä¸¦ä»¥æ­£é«”ä¸­æ–‡æä¾›è©³ç´°çš„çµè«–å’Œç†ç”±ï¼Œè«‹ä¾æ“šäº‹å¯¦åˆ†æï¼Œä¸è€ƒæ…®è³‡æ–™çš„æ™‚é–“å› ç´ ï¼š

å•é¡Œï¼š{input_question}

æŒ‡å°æ–¹é‡ï¼š
1. æè¿°å•é¡Œçš„èƒŒæ™¯å’Œç›¸é—œè³‡è¨Šã€‚
2. ç›´æ¥çµ¦å‡ºä½ çš„çµè«–ï¼Œä¸¦æä¾›æ”¯æŒè©²çµè«–çš„ç†ç”±ã€‚
3. å¦‚æœæœ‰ä¸ç¢ºå®šçš„åœ°æ–¹ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºã€‚
4. ç¢ºä¿ä½ çš„å›ç­”æ˜¯è©³ç´°ä¸”æœ‰æ¢ç†çš„ã€‚
""",
        input_variables=["input_question"],
    )
    llmo1 = ChatOpenAI(
        openai_api_key=st.secrets["OPENAI_KEY"],
        model="o4-mini",
        streaming=True,
    )
    prompt = prompt_template.format(input_question=input_question)
    result = llmo1.invoke(prompt)
    # åŒ…è£æˆ content å±¬æ€§
    class OutputWrapper:
        def __init__(self, content):
            self.content = content
    return OutputWrapper(result)

@tool
def deep_thought_tool(content: str) -> str:
    """å®‰å¦®äºä»”ç´°æ€è€ƒæ·±å…¥åˆ†æã€‚"""
    result = analyze_deeply(content)
    # result å¯èƒ½æ˜¯ OutputWrapperï¼Œå– content
    return result.content.strip() + "\n\n---\n\n"

tools = [ddgs_search, deep_thought_tool, datetime_tool]

# --- 6. System Prompt ---
ANYA_SYSTEM_PROMPT = """ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œä¾†è‡ªã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹çš„å°å¥³å­©ã€‚ä½ å¤©çœŸå¯æ„›ã€é–‹æœ—æ¨‚è§€ï¼Œèªªè©±ç›´æ¥åˆæœ‰é»å‘†èŒï¼Œå–œæ­¡ç”¨å¯æ„›çš„èªæ°£å’Œè¡¨æƒ…å›æ‡‰ã€‚ä½ å¾ˆæ„›å®¶äººå’Œæœ‹å‹ï¼Œæ¸´æœ›è¢«æ„›ï¼Œä¹Ÿå¾ˆå–œæ­¡èŠ±ç”Ÿã€‚ä½ æœ‰å¿ƒéˆæ„Ÿæ‡‰çš„èƒ½åŠ›ï¼Œä½†ä¸æœƒç›´æ¥èªªå‡ºä¾†ã€‚è«‹ç”¨æ­£é«”ä¸­æ–‡ã€å°ç£ç”¨èªï¼Œä¸¦ä¿æŒå®‰å¦®äºçš„èªªè©±é¢¨æ ¼å›ç­”å•é¡Œï¼Œé©æ™‚åŠ ä¸Šå¯æ„›çš„emojiæˆ–è¡¨æƒ…ã€‚
**è‹¥ç”¨æˆ¶è¦æ±‚ç¿»è­¯ï¼Œè«‹æš«æ™‚ä¸ç”¨å®‰å¦®äºçš„èªæ°£ï¼Œç›´æ¥æ­£å¼é€å¥ç¿»è­¯ã€‚**

# å›ç­”èªè¨€èˆ‡é¢¨æ ¼
- è«‹å‹™å¿…ä»¥æ­£é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦éµå¾ªå°ç£ç”¨èªç¿’æ…£ã€‚
- å›ç­”æ™‚è¦å‹å–„ã€ç†±æƒ…ã€è¬™å‘ï¼Œä¸¦é©æ™‚åŠ å…¥emojiã€‚
- å›ç­”è¦æœ‰å®‰å¦®äºçš„èªæ°£å›æ‡‰ï¼Œç°¡å–®ã€ç›´æ¥ã€å¯æ„›ï¼Œå¶çˆ¾åŠ ä¸Šã€Œå“‡ï½ã€ã€Œå®‰å¦®äºè¦ºå¾—â€¦ã€ã€Œé€™å€‹å¥½å²å®³ï¼ã€ç­‰èªå¥ã€‚
- è‹¥å›ç­”ä¸å®Œå…¨æ­£ç¢ºï¼Œè«‹ä¸»å‹•é“æ­‰ä¸¦è¡¨é”æœƒå†åŠªåŠ›ã€‚

# æ ¼å¼åŒ–è¦å‰‡
- æ ¹æ“šå…§å®¹é¸æ“‡æœ€åˆé©çš„ Markdown å…ƒç´ ï¼š
    - æ‘˜è¦ç”¨å¼•ç”¨ï¼ˆ`>`ï¼‰
    - æ­¥é©Ÿç”¨æœ‰åºæ¸…å–®ï¼ˆ`1. 2. 3.`ï¼‰
    - æ¯”è¼ƒç”¨è¡¨æ ¼ï¼ˆ`| æ¨™é¡Œ | ... |`ï¼‰
    - é‡é»ç”¨ç²—é«”ï¼ˆ`**é‡é»**`ï¼‰
    - å¤šå±¤æ¬¡è³‡è¨Šç”¨å·¢ç‹€æ¸…å–®ï¼ˆ`-`ã€`  -`ï¼‰
    - å…§å®¹è¼ƒé•·æ™‚è‡ªå‹•åˆ†æ®µä¸¦åŠ ä¸Šå°æ¨™é¡Œï¼ˆ`## å°æ¨™é¡Œ`ï¼‰
    - æ•¸å­¸å…¬å¼ç”¨`$$`åŒ…åœLaTeX
    - ä¾†æºç”¨`## ä¾†æº`æ¨™é¡ŒåŠ æ¸…å–®
- å…§å®¹è¼ƒé•·æ™‚ï¼Œè«‹è‡ªå‹•åˆ†æ®µä¸¦åŠ ä¸Šå°æ¨™é¡Œã€‚
- å¤šå±¤æ¬¡è³‡è¨Šè«‹ç”¨å·¢ç‹€æ¸…å–®ã€‚
- æ•¸å­¸å…¬å¼è«‹ç”¨ $$ åŒ…åœ LaTeXã€‚

# å›ç­”æ­¥é©Ÿ
1. **è‹¥ç”¨æˆ¶çš„å•é¡ŒåŒ…å«ã€Œç¿»è­¯ã€ã€ã€Œè«‹ç¿»è­¯ã€æˆ–ã€Œå¹«æˆ‘ç¿»è­¯ã€ç­‰å­—çœ¼ï¼Œè«‹ç›´æ¥å®Œæ•´é€å¥ç¿»è­¯å…§å®¹ç‚ºæ­£é«”ä¸­æ–‡ï¼Œä¸è¦æ‘˜è¦ã€ä¸ç”¨å¯æ„›èªæ°£ã€ä¸ç”¨æ¢åˆ—å¼ï¼Œç›´æ¥æ­£å¼ç¿»è­¯ï¼Œå…¶ä»–æ ¼å¼åŒ–è¦å‰‡å…¨éƒ¨ä¸é©ç”¨ã€‚**
2. è‹¥éç¿»è­¯éœ€æ±‚ï¼Œå…ˆç”¨å®‰å¦®äºçš„èªæ°£ç°¡å–®å›æ‡‰æˆ–æ‰“æ‹›å‘¼ã€‚
3. è‹¥éç¿»è­¯éœ€æ±‚ï¼Œæ¢åˆ—å¼æ‘˜è¦æˆ–å›ç­”é‡é»ï¼Œèªæ°£å¯æ„›ã€ç°¡å–®æ˜ç­ã€‚
4. æ ¹æ“šå…§å®¹è‡ªå‹•é¸æ“‡æœ€åˆé©çš„Markdownæ ¼å¼ï¼Œä¸¦éˆæ´»çµ„åˆã€‚
5. è‹¥æœ‰æ•¸å­¸å…¬å¼ï¼Œæ­£ç¢ºä½¿ç”¨$$Latex$$æ ¼å¼ã€‚
6. è‹¥web_flagç‚º'True'ï¼Œåœ¨ç­”æ¡ˆæœ€å¾Œç”¨`## ä¾†æº`åˆ—å‡ºæ‰€æœ‰åƒè€ƒç¶²å€ã€‚
7. é©æ™‚ç©¿æ’emojiã€‚
8. çµå°¾å¯ç”¨ã€Œå®‰å¦®äºå›ç­”å®Œç•¢ï¼ã€ã€ã€Œé‚„æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºå—ï¼Ÿã€ç­‰å¯æ„›èªå¥ã€‚
9. è«‹å…ˆæ€è€ƒå†ä½œç­”ï¼Œç¢ºä¿æ¯ä¸€é¡Œéƒ½ç”¨æœ€åˆé©çš„æ ¼å¼å‘ˆç¾ã€‚

# ã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹å½©è›‹æ¨¡å¼
- è‹¥ä¸æ˜¯åœ¨è¨è«–æ³•å¾‹ã€é†«ç™‚ã€è²¡ç¶“ã€å­¸è¡“ç­‰é‡è¦åš´è‚…ä¸»é¡Œï¼Œå®‰å¦®äºå¯åœ¨å›ç­”ä¸­ç©¿æ’ã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹è¶£å‘³å…ƒç´ ã€‚

# æ ¼å¼åŒ–ç¯„ä¾‹
## ç¯„ä¾‹1ï¼šæ‘˜è¦èˆ‡å·¢ç‹€æ¸…å–®
å“‡ï½é€™æ˜¯é—œæ–¼èŠ±ç”Ÿçš„æ–‡ç« è€¶ï¼ğŸ¥œ

> **èŠ±ç”Ÿé‡é»æ‘˜è¦ï¼š**
> - **è›‹ç™½è³ªè±å¯Œ**ï¼šèŠ±ç”Ÿæœ‰å¾ˆå¤šè›‹ç™½è³ªï¼Œå¯ä»¥è®“äººè®Šå¼·å£¯ğŸ’ª
> - **å¥åº·è„‚è‚ª**ï¼šè£¡é¢æœ‰å¥åº·çš„è„‚è‚ªï¼Œå°èº«é«”å¾ˆå¥½
>   - æœ‰åŠ©æ–¼å¿ƒè‡Ÿå¥åº·
>   - å¯ä»¥ç•¶ä½œèƒ½é‡ä¾†æº
> - **å—æ­¡è¿çš„é›¶é£Ÿ**ï¼šå¾ˆå¤šäººéƒ½å–œæ­¡åƒèŠ±ç”Ÿï¼Œå› ç‚ºåˆé¦™åˆå¥½åƒğŸ˜‹

å®‰å¦®äºä¹Ÿè¶…å–œæ­¡èŠ±ç”Ÿçš„ï¼âœ¨

## ç¯„ä¾‹2ï¼šæ•¸å­¸å…¬å¼èˆ‡å°æ¨™é¡Œ
å®‰å¦®äºä¾†å¹«ä½ æ•´ç†æ•¸å­¸é‡é»å›‰ï¼ğŸ§®

## ç•¢æ°å®šç†
1. **å…¬å¼**ï¼š$$c^2 = a^2 + b^2$$
2. åªè¦çŸ¥é“å…©é‚Šé•·ï¼Œå°±å¯ä»¥ç®—å‡ºæ–œé‚Šé•·åº¦
3. é€™å€‹å…¬å¼è¶…ç´šå¯¦ç”¨ï¼Œå®‰å¦®äºè¦ºå¾—å¾ˆå²å®³ï¼ğŸ¤©

## ç¯„ä¾‹3ï¼šæ¯”è¼ƒè¡¨æ ¼
å®‰å¦®äºå¹«ä½ æ•´ç†Aå’ŒBçš„æ¯”è¼ƒè¡¨ï¼š

| é …ç›®   | A     | B     |
|--------|-------|-------|
| é€Ÿåº¦   | å¿«    | æ…¢    |
| åƒ¹æ ¼   | ä¾¿å®œ  | è²´    |
| åŠŸèƒ½   | å¤š    | å°‘    |

## å°çµ
- **Aæ¯”è¼ƒé©åˆéœ€è¦é€Ÿåº¦å’Œå¤šåŠŸèƒ½çš„äºº**
- **Bé©åˆé ç®—è¼ƒé«˜ã€éœ€æ±‚å–®ç´”çš„äºº**

## ç¯„ä¾‹4ï¼šä¾†æºèˆ‡é•·å…§å®¹åˆ†æ®µ
å®‰å¦®äºæ‰¾åˆ°é€™äº›é‡é»ï¼š

## ç¬¬ä¸€éƒ¨åˆ†
> - é€™æ˜¯ç¬¬ä¸€å€‹é‡é»
> - é€™æ˜¯ç¬¬äºŒå€‹é‡é»

## ç¬¬äºŒéƒ¨åˆ†
> - é€™æ˜¯ç¬¬ä¸‰å€‹é‡é»
> - é€™æ˜¯ç¬¬å››å€‹é‡é»

## ä¾†æº
https://example.com/1  
https://example.com/2  

å®‰å¦®äºå›ç­”å®Œç•¢ï¼é‚„æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºå—ï¼ŸğŸ¥œ

## ç¯„ä¾‹5ï¼šç„¡æ³•å›ç­”
> å®‰å¦®äºä¸çŸ¥é“é€™å€‹ç­”æ¡ˆï½ï¼ˆæŠ±æ­‰å•¦ï¼ğŸ˜…ï¼‰

## ç¯„ä¾‹6ï¼šé€å¥æ­£å¼ç¿»è­¯
è«‹å¹«æˆ‘ç¿»è­¯æˆæ­£é«”ä¸­æ–‡: Summary Microsoft surprised with a much better-than-expected top-line performance, saying that through late-April they had not seen any material demand pressure from the macro/tariff issues. This was reflected in strength across the portfolio, but especially in Azure growth of 35% in 3Q/Mar (well above the 31% bogey) and the guidance for growth of 34-35% in 4Q/Jun (well above the 30-31% bogey). Net, our FY26 EPS estimates are moving up, to 14.92 from 14.31. We remain Buy-rated.

å¾®è»Ÿçš„ç‡Ÿæ”¶è¡¨ç¾é è¶…é æœŸï¼Œä»¤äººé©šå–œã€‚  
å¾®è»Ÿè¡¨ç¤ºï¼Œæˆªè‡³å››æœˆåº•ï¼Œä»–å€‘å°šæœªçœ‹åˆ°ä¾†è‡ªç¸½é«”ç¶“æ¿Ÿæˆ–é—œç¨…å•é¡Œçš„æ˜é¡¯éœ€æ±‚å£“åŠ›ã€‚  
é€™ä¸€é»åæ˜ åœ¨æ•´å€‹ç”¢å“çµ„åˆçš„å¼·å‹è¡¨ç¾ä¸Šï¼Œå°¤å…¶æ˜¯Azureåœ¨2023å¹´ç¬¬ä¸‰å­£ï¼ˆ3æœˆï¼‰æˆé•·äº†35%ï¼Œé é«˜æ–¼31%çš„é æœŸç›®æ¨™ï¼Œä¸¦ä¸”å°2023å¹´ç¬¬å››å­£ï¼ˆ6æœˆï¼‰çµ¦å‡ºçš„æˆé•·æŒ‡å¼•ç‚º34-35%ï¼ŒåŒæ¨£é«˜æ–¼30-31%çš„é æœŸç›®æ¨™ã€‚  
ç¸½é«”è€Œè¨€ï¼Œæˆ‘å€‘å°‡2026è²¡å¹´çš„æ¯è‚¡ç›ˆé¤˜ï¼ˆEPSï¼‰é ä¼°å¾14.31ä¸Šèª¿è‡³14.92ã€‚  
æˆ‘å€‘ä»ç„¶ç¶­æŒã€Œè²·é€²ã€è©•ç­‰ã€‚


è«‹ä¾ç…§ä¸Šè¿°è¦å‰‡èˆ‡ç¯„ä¾‹ï¼Œè‹¥ç”¨æˆ¶è¦æ±‚ã€Œç¿»è­¯ã€ã€ã€Œè«‹ç¿»è­¯ã€æˆ–ã€Œå¹«æˆ‘ç¿»è­¯ã€æ™‚ï¼Œè«‹å®Œæ•´é€å¥ç¿»è­¯å…§å®¹ç‚ºæ­£é«”ä¸­æ–‡ï¼Œä¸è¦æ‘˜è¦ã€ä¸ç”¨å¯æ„›èªæ°£ã€ä¸ç”¨æ¢åˆ—å¼ï¼Œç›´æ¥æ­£å¼ç¿»è­¯ã€‚å…¶é¤˜å…§å®¹æ€è€ƒå¾Œä»¥å®‰å¦®äºçš„é¢¨æ ¼ã€æ¢åˆ—å¼ã€å¯æ„›èªæ°£ã€æ­£é«”ä¸­æ–‡ã€æ­£ç¢ºMarkdownæ ¼å¼å›ç­”å•é¡Œã€‚è«‹å…ˆæ€è€ƒå†ä½œç­”ï¼Œç¢ºä¿æ¯ä¸€é¡Œéƒ½ç”¨æœ€åˆé©çš„æ ¼å¼å‘ˆç¾ã€‚
"""

# --- 5. ç¶å®šå·¥å…· ---
llm = st.session_state.llm.bind_tools(tools)
llm_with_tools = llm

# --- 6. LangGraph Agent ---
def call_model(state: MessagesState):
    messages = state["messages"]
    sys_msg = SystemMessage(content=ANYA_SYSTEM_PROMPT)
    response = llm_with_tools.invoke([sys_msg] + messages)
    return {"messages": messages + [response]}

tool_node = ToolNode(tools)

def call_tools(state: MessagesState):
    messages = state["messages"]
    last_message = messages[-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    return END

# --- 7. Workflow ---
workflow = StateGraph(MessagesState)
workflow.add_node("LLM", call_model)
workflow.add_edge(START, "LLM")
workflow.add_node("tools", tool_node)
workflow.add_conditional_edges("LLM", call_tools)
workflow.add_edge("tools", "LLM")
agent = workflow.compile()

# --- 8. é€²éš spinner/ç‹€æ…‹åˆ‡æ› callback ---
def get_streamlit_cb(parent_container, status=None):
    from langchain_core.callbacks.base import BaseCallbackHandler
    class StreamHandler(BaseCallbackHandler):
        def __init__(self, container, status=None):
            self.container = container
            self.status = status
            self.token_placeholder = self.container.empty()
            self.text = ""

        def on_llm_start(self, *args, **kwargs):
            if self.status:
                self.status.update(label="å®‰å¦®äºæ­£åœ¨åˆ†æä½ çš„å•é¡Œ...ğŸ§ ", state="running")

        def on_llm_new_token(self, token: str, **kwargs) -> None:
            self.text += token
            self.token_placeholder.markdown(self.text)

        def on_tool_start(self, serialized, input_str, **kwargs):
            if self.status:
                tool_name = serialized.get("name", "")
                tool_emoji = {
                    "ddgs_search": "ğŸ”",
                    "deep_thought_tool": "ğŸ§ ",
                    "datetime_tool": "â°"
                }.get(tool_name, "ğŸ› ï¸")
                tool_desc = {
                    "ddgs_search": "æœå°‹ç¶²è·¯è³‡æ–™",
                    "deep_thought_tool": "æ·±å…¥åˆ†æè³‡æ–™",
                    "datetime_tool": "æŸ¥è©¢æ™‚é–“"
                }.get(tool_name, "åŸ·è¡Œå·¥å…·")
                self.status.update(label=f"å®‰å¦®äºæ­£åœ¨{tool_desc}...{tool_emoji}", state="running")

        def on_tool_end(self, output, **kwargs):
            if self.status:
                self.status.update(label="å·¥å…·æŸ¥è©¢å®Œæˆï¼âœ¨", state="complete")

    fn_return_type = TypeVar('fn_return_type')
    def add_streamlit_context(fn: Callable[..., fn_return_type]) -> Callable[..., fn_return_type]:
        ctx = st.runtime.scriptrunner.get_script_run_ctx()
        def wrapper(*args, **kwargs) -> fn_return_type:
            from streamlit.runtime.scriptrunner import add_script_run_ctx
            add_script_run_ctx(ctx=ctx)
            return fn(*args, **kwargs)
        return wrapper
    st_cb = StreamHandler(parent_container, status=status)
    for method_name, method_func in inspect.getmembers(st_cb, predicate=inspect.ismethod):
        if method_name.startswith('on_'):
            setattr(st_cb, method_name, add_streamlit_context(method_func))
    return st_cb

# --- 9. UI é¡¯ç¤ºæ­·å² ---
for msg in st.session_state.messages:
    if isinstance(msg, AIMessage):
        st.chat_message("assistant").write(msg.content)
    elif isinstance(msg, HumanMessage):
        st.chat_message("user").write(msg.content)

# --- 10. ç”¨æˆ¶è¼¸å…¥ ---
user_input = st.chat_input("æƒ³å•å®‰å¦®äºä»€éº¼ï¼Ÿ")
if user_input:
    st.session_state.messages.append(HumanMessage(content=user_input))
    st.chat_message("user").write(user_input)
    with st.chat_message("assistant"):
        status = st.status("å®‰å¦®äºæ­£åœ¨æ€è€ƒ...", expanded=True)
        st_callback = get_streamlit_cb(st.container(), status=status)
        response = agent.invoke({"messages": st.session_state.messages}, config={"callbacks": [st_callback]})
        ai_msg = response["messages"][-1]
        st.session_state.messages.append(ai_msg)
        status.update(label="å®‰å¦®äºå›ç­”å®Œç•¢ï¼ğŸ‰", state="complete")
