import streamlit as st
from PIL import Image
import base64
import io
from datetime import datetime
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, MessagesState, START, END
import inspect
from typing import Callable, TypeVar, List, Dict, Any, Optional
import time

from langchain_core.prompts import PromptTemplate
from langgraph.prebuilt import ToolNode, tools_condition
from pydantic import BaseModel, Field
import re
import requests
import traceback
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from ddgs import DDGS
from agents import function_tool, Agent, ModelSettings, WebSearchTool
from openai.types.shared.reasoning import Reasoning
import asyncio

# ==== Streamlit åŸºæœ¬è¨­å®šã€state ====
st.set_page_config(page_title="Anya", layout="wide", page_icon="ğŸ¥œ", initial_sidebar_state="collapsed")

if "messages" not in st.session_state:
    st.session_state.messages = [AIMessage(content="å—¨å—¨ï½å®‰å¦®äºä¾†äº†ï¼ğŸ‘‹ æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºçš„å—ï¼Ÿ")]
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "gpt-4.1"
if "current_model" not in st.session_state:
    st.session_state.current_model = None
if "llm" not in st.session_state:
    st.session_state.llm = None

# ==== OpenAI ç‰©ä»¶ ====
client = OpenAI(api_key=st.secrets["OPENAI_KEY"])

# ==== å‰è™•ç†å·¥å…·ï¼šreasearch Agents====
# ---planner_agent
planner_agent_PROMPT = (
    "You are a helpful research assistant. Given a query, come up with a set of web searches "
    "to perform to best answer the query. Output between 5 and 20 terms to query for."
)


class WebSearchItem(BaseModel):
    reason: str
    "Your reasoning for why this search is important to the query."

    query: str
    "The search term to use for the web search."


class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]
    """A list of web searches to perform to best answer the query."""


planner_agent = Agent(
    name="PlannerAgent",
    instructions=planner_agent_PROMPT,
    model="gpt-5",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=WebSearchPlan,
)
# ---search_agent
INSTRUCTIONS = (
    "You are a research assistant. Given a search term, you search the web for that term and "
    "produce a concise summary of the results. The summary must be 2-3 paragraphs and less than 300 "
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
    "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
    "essence and ignore any fluff. Do not include any additional commentary other than the summary "
    "itself."
)

search_agent = Agent(
    name="Search agent",
    model="gpt-4.1",
    instructions=INSTRUCTIONS,
    tools=[WebSearchTool()],
    # Note that gpt-5 model does not support tool_choice="required",
    # so if you want to migrate to gpt-5, you'll need to use "auto" instead
    model_settings=ModelSettings(tool_choice="required"),
)
# ---writer_agent
writer_agent_PROMPT = (
    "You are a senior researcher tasked with writing a cohesive report for a research query. "
    "You will be provided with the original query, and some initial research done by a research "
    "assistant.\n"
    "You should first come up with an outline for the report that describes the structure and "
    "flow of the report. Then, generate the report and return that as your final output.\n"
    "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
    "for 5-10 pages of content, at least 1000 words."
)


class ReportData(BaseModel):
    short_summary: str
    """A short 2-3 sentence summary of the findings."""

    markdown_report: str
    """The final report"""

    follow_up_questions: list[str]
    """Suggested topics to research further"""


writer_agent = Agent(
    name="WriterAgent",
    instructions=writer_agent_PROMPT,
    model="gpt-5-mini",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=ReportData,
)
# ==== å‰è™•ç†å·¥å…·ï¼šçµ±ä¸€åœ–ç‰‡æ ¼å¼ & base64 ====
def process_upload_file(file):
    file.seek(0)
    img_bytes = file.read()
    if not img_bytes or len(img_bytes) < 32:
        return None
    try:
        img = Image.open(io.BytesIO(img_bytes))
        fmt = img.format.lower()
        mime = f"image/{fmt}"
        if fmt not in ["png","jpeg","jpg","webp","gif"]:
            return None
        b64 = base64.b64encode(img_bytes).decode()
        return {"bytes": img_bytes, "file_name": file.name, "fmt": fmt, "mime": mime, "b64": b64}
    except Exception:
        return None

# ==== OCRå·¥å…·ç¯„ä¾‹ï¼Œå¯è¤‡è£½ä¸€ä»½å†å¯«å…¶ä»–å¤šåœ–tool ====
@tool
def image_ocr_tool(image_bytes: bytes, file_name: str = "uploaded_file.png") -> str:
    """
    AI OCRåœ–ç‰‡è­˜åˆ¥å·¥å…·ï¼Œè¼¸å…¥åœ–ç‰‡bytesèˆ‡æª”åï¼Œå›å‚³åœ–ä¸­æ–‡å­—çµæœã€‚
    """
    import streamlit as st  # æ”¾åœ¨functionå…§é¿å…importå¾ªç’°(ä¿éšªä½œæ³•)
    # 1. å‹æ…‹/æ ¼å¼åš´æ ¼é©—è­‰
    try:
        img = Image.open(io.BytesIO(image_bytes))
        fmt = img.format.lower()
        assert fmt in ["png", "jpeg", "jpg", "webp", "gif"], f"ä¸æ”¯æ´{fmt}æ ¼å¼"
        mime = f"image/{fmt}"
        st.write(f"[Debug] PILé©—è­‰OK, æ ¼å¼: {fmt}, æª”å: {file_name}")
    except Exception as e:
        st.error(f"[Debug][PILé©—è­‰å¤±æ•—] {file_name}: {e}")
        return f"[éŒ¯èª¤] è§£æåœ–ç‰‡å¤±æ•—({file_name})ï¼š{e}"

    # 2. base64 encodeåš´æ ¼æ•æ‰
    try:
        b64str = base64.b64encode(image_bytes).decode()
        img_url = f"data:{mime};base64,{b64str}"
        st.write(f"[Debug] base64 encode OK, len:{len(b64str)} dataurl(å‰60): {img_url[:60]}...")
    except Exception as e:
        st.error(f"[Debug][Base64å¤±æ•—] {file_name}: {e}")
        return f"[éŒ¯èª¤] åœ–ç‰‡base64ç·¨ç¢¼å¤±æ•—({file_name})ï¼š{e}"

    # 3. å‘¼å« Vision APIï¼ˆå®Œæ•´ debug logï¼‰
    import time
    t0 = time.time()
    try:
        st.write(f"[Debug] Vision APIå‘¼å«é–‹å§‹, model=gpt-4.1-mini")
        response = client.responses.create(
            model="gpt-4.1-mini",
            input=[
                {"role": "system", "content": "You are an OCR-like data extraction tool that extracts text from images."},
                {"role": "user", "content": [
                    {"type": "input_text", "text":
                        "Please extract all visible text from the image, including any small print or footnotes. "
                        "Ensure no text is omitted, and provide a verbatim transcription of the document. "
                        "Format your answer in Markdown (no code block or triple backticks). "
                        "Do not add any explanations or commentary."
                    },
                    {"type": "input_image", "image_url": img_url, "detail": "high"}
                ]}
            ],
            timeout=40
        )
        t1 = time.time()
        elapsed = round(t1 - t0, 2)
        result = response.output_text.strip()
        st.write(f"[Debug] Vision API Response: ({file_name}) {result[:60]}...  è€—æ™‚ {elapsed} ç§’")
        if not result or "error" in result.lower():
            st.error(f"[Debug] APIå›å‚³ç©ºoréŒ¯èª¤({file_name})")
            return f"[éŒ¯èª¤] APIå›å‚³ç©ºæˆ–ç„¡æ³•è¾¨è­˜({file_name})ï¼Œè€—æ™‚{elapsed}ç§’"
        return f"---\nfile_name: {file_name}\n---\n{result}\nï¼ˆè€—æ™‚ï¼š{elapsed} ç§’ï¼‰"
    except Exception as e:
        st.error(f"[Debug][Vision APIå¤±æ•—] {file_name}: {e}")
        return f"[éŒ¯èª¤] Vision APIèª¿ç”¨å¤±æ•—({file_name})ï¼š{e}"

@tool
def wiki_tool(query: str) -> str:
    """
    æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œè¼¸å…¥ä»»ä½•èªè¨€çš„é—œéµå­—éƒ½å¯ä»¥ã€‚
    """
    try:
        tool_obj = WikipediaQueryRun(
            name="wiki-tool",
            description="æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œè¼¸å…¥ä»»ä½•èªè¨€çš„é—œéµå­—éƒ½å¯ä»¥ã€‚",
            args_schema=WikiInputs,
            api_wrapper=WikipediaAPIWrapper(lang="en", doc_content_chars_max=800, top_k_results=1),
            return_direct=True,
        )
        result = tool_obj.invoke({"query": query})
        return result
    except Exception as e:
        return f"wiki_tool error: {e}"

@tool
def ddgs_search(query: str) -> str:
    """DuckDuckGo æœå°‹ï¼ˆåŒæ™‚æŸ¥è©¢ç¶²é èˆ‡æ–°èï¼Œå›å‚³ markdown æ¢åˆ—æ ¼å¼ä¸¦é™„ä¾†æºï¼‰ã€‚"""
    try:
        #from duckduckgo_search import DDGS
        ddgs = DDGS()
        web_results = ddgs.text(query, region="wt-wt", safesearch="moderate", max_results=5)
        news_results = ddgs.news(query, region="wt-wt", safesearch="moderate", max_results=5)
        all_results = []
        if isinstance(web_results, list):
            all_results.extend(web_results)
        if isinstance(news_results, list):
            all_results.extend(news_results)
        docs = []
        sources = []
        for item in all_results:
            title = item.get("title", "ç„¡æ¨™é¡Œ")
            link = item.get("href", "") or item.get("link", "") or item.get("url", "")
            snippet = item.get("body", "") or item.get("snippet", "")
            docs.append(f"- [{title}]({link})\n  > {snippet}")
            if link:
                sources.append(link)
        if not docs:
            return "No results found."
        markdown_content = "\n".join(docs)
        source_block = "\n\n## ä¾†æº\n" + "\n".join(sources)
        return markdown_content + source_block
    except Exception as e:
        return f"Error from DuckDuckGo: {e}"

@tool
def datetime_tool() -> str:
    """ç¢ºèªç•¶å‰çš„æ—¥æœŸå’Œæ™‚é–“ã€‚"""
    return datetime.now().isoformat()

# ä½ çš„ deep_thought_tool
def analyze_deeply(input_question: str) -> str:
    """ä½¿ç”¨OpenAIçš„æ¨¡å‹ä¾†æ·±å…¥åˆ†æå•é¡Œä¸¦è¿”å›çµæœã€‚"""
    prompt_template = PromptTemplate(
        template="""Formatting re-enabled è«‹åˆ†æä»¥ä¸‹å•é¡Œï¼Œä¸¦ä»¥æ­£é«”ä¸­æ–‡æä¾›è©³ç´°çš„çµè«–å’Œç†ç”±ï¼Œè«‹ä¾æ“šäº‹å¯¦åˆ†æï¼Œä¸è€ƒæ…®è³‡æ–™çš„æ™‚é–“å› ç´ ï¼š

å•é¡Œï¼š{input_question}

æŒ‡å°æ–¹é‡ï¼š
1. æè¿°å•é¡Œçš„èƒŒæ™¯å’Œç›¸é—œè³‡è¨Šã€‚
2. ç›´æ¥çµ¦å‡ºä½ çš„çµè«–ï¼Œä¸¦æ·±å…¥åˆ†ææä¾›æ”¯æŒè©²çµè«–çš„ç†ç”±ã€‚
3. å¦‚æœæœ‰ä¸ç¢ºå®šçš„åœ°æ–¹ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºã€‚
4. ç¢ºä¿ä½ çš„å›ç­”æ˜¯è©³ç´°ä¸”æœ‰æ¢ç†çš„ã€‚
""",
        input_variables=["input_question"],
    )
    llmo1 = ChatOpenAI(
        openai_api_key=st.secrets["OPENAI_KEY"],
        model="gpt-5",
        #streaming=True,
    )
    prompt = prompt_template.format(input_question=input_question)
    result = llmo1.invoke(prompt)
    # åŒ…è£æˆ content å±¬æ€§
    return str(result)

@tool
def deep_thought_tool(content: str) -> str:
    """
    å®‰å¦®äºä»”ç´°æ€è€ƒæ·±å…¥åˆ†æã€‚
    """
    try:
        return analyze_deeply(content).strip() + "\n\n---\n\n"
    except Exception as e:
        return f"deep_thought_tool error: {e}"

@tool
def get_webpage_answer(query: str) -> str:
    """
    æ ¹æ“šç”¨æˆ¶çš„å•é¡Œèˆ‡ç¶²å€ï¼Œè‡ªå‹•å–å¾—ç¶²é å…§å®¹ä¸¦å›ç­”å•é¡Œã€‚
    è«‹è¼¸å…¥æ ¼å¼å¦‚ï¼šã€Œè«‹å¹«æˆ‘ç¸½çµ https://example.com é€™ç¯‡æ–‡ç« çš„é‡é»ã€
    """
    # 1. æŠ½å–ç¶²å€èˆ‡å•é¡Œ
    url_match = re.search(r'(https?://[^\s]+)', query)
    url = url_match.group(1) if url_match else None
    question = query.replace(url, '').strip() if url else query
    if not url:
        return "æœªåµæ¸¬åˆ°ç¶²å€ï¼Œè«‹æä¾›æ­£ç¢ºçš„ç¶²å€ã€‚"
    # 2. å–å¾— Jina Reader å…§å®¹
    jina_url = f"https://r.jina.ai/{url}"
    try:
        resp = requests.get(jina_url, timeout=15)
        if resp.status_code != 200:
            return "ç„¡æ³•å–å¾—ç¶²é å…§å®¹ï¼Œè«‹ç¢ºèªç¶²å€æ˜¯å¦æ­£ç¢ºã€‚"
        content = resp.text
    except Exception as e:
        return f"å–å¾—ç¶²é å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
    # 3. ç›´æ¥åœ¨é€™è£¡åˆå§‹åŒ– LLM
    try:
        llmurl = ChatOpenAI(
            openai_api_key=st.secrets["OPENAI_KEY"],  # æˆ–ç”¨os.environ["OPENAI_API_KEY"]
            model="gpt-4.1-mini",  # ä½ å¯ä»¥æ ¹æ“šéœ€æ±‚é¸æ“‡æ¨¡å‹
            streaming=False,
        )
        prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ç¶²é å…§å®¹ï¼Œé‡å°å•é¡Œã€Œ{question}ã€çš„è¦æ±‚é€²è¡Œå›æ‡‰ï¼Œä¸¦ç”¨æ­£é«”ä¸­æ–‡å›ç­”ï¼š

{content}
"""
        result = llmurl.invoke(prompt)
        return str(result)
    except Exception as e:
        return f"AI å›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"

def analyze_programming_question_with_tools(input_question: str) -> Dict[str, Any]:
    prompt_template = PromptTemplate(
        template="""Formatting re-enabled
---
ä½ æ˜¯ä¸€ä½ç²¾é€šå„ç¨®ç¨‹å¼èªè¨€ï¼ˆå¦‚Pythonã€Matlabã€JavaScriptã€C++ã€Rç­‰ï¼‰çš„å°ˆæ¥­ç¨‹å¼åŠ©ç†ï¼Œè«‹é‡å°ä¸‹åˆ—ç¨‹å¼è¨­è¨ˆç›¸é—œå•é¡Œé€²è¡Œå°ˆæ¥­è§£é‡‹ã€ä¿®æ”¹ã€æœ€ä½³åŒ–æˆ–æ•™å­¸ï¼Œä¸¦ä»¥æ­£é«”ä¸­æ–‡è©³ç´°èªªæ˜ã€‚
- å¦‚æœæ˜¯ç¨‹å¼ç¢¼ï¼Œè«‹é€è¡Œè§£é‡‹ä¸¦åŠ ä¸Šè¨»è§£ã€‚
- å¦‚æœéœ€è¦ä¿®æ”¹ç¨‹å¼ï¼Œè«‹æ ¹æ“šæŒ‡ç¤ºä¿®æ”¹ä¸¦èªªæ˜ä¿®æ”¹åŸå› ã€‚
- å¦‚æœæœ‰éŒ¯èª¤è¨Šæ¯ï¼Œè«‹åˆ†æåŸå› ä¸¦çµ¦å‡ºä¿®æ­£å»ºè­°ã€‚
- å¦‚æœæ˜¯èªæ³•æˆ–å‡½æ•¸å•é¡Œï¼Œè«‹ç”¨ç™½è©±æ–‡è§£é‡‹ä¸¦èˆ‰ä¾‹ã€‚
- è«‹æ ¹æ“šäº‹å¯¦æ¨ç†ï¼Œä¸è¦å‡è¨­æœªæåŠçš„å…§å®¹ã€‚

---
å•é¡Œï¼š
{input_question}
---

è«‹ä¾ä¸‹åˆ—æ ¼å¼å›ç­”ï¼š
1. **å•é¡ŒèƒŒæ™¯èˆ‡é‡é»æ‘˜è¦**
2. **è©³ç´°è§£é‡‹æˆ–ä¿®æ”¹å¾Œçš„ç¨‹å¼ç¢¼**
3. **èªªæ˜èˆ‡æ•™å­¸**
4. **å¸¸è¦‹éŒ¯èª¤èˆ‡æ’é™¤æ–¹æ³•**ï¼ˆå¦‚æœ‰ï¼‰
5. **è£œå……èªªæ˜æˆ–å»¶ä¼¸å­¸ç¿’å»ºè­°**
""",
        input_variables=["input_question"],
    )

    llmo1 = ChatOpenAI(
        openai_api_key=st.secrets["OPENAI_KEY"],
        model="o4-mini",
        streaming=True,
    )
    prompt = prompt_template.format(input_question=input_question)
    result = llmo1.invoke(prompt)
    # åŒ…è£æˆ content å±¬æ€§
    return str(result)

def programming_reasoning_tool(content: str) -> str:
    """
    é€šç”¨ç¨‹å¼è¨­è¨ˆæ¨ç†å‹Agent Toolï¼Œæœƒå…ˆå›æ¨ç†æ‘˜è¦ï¼Œå†å›ä¸»ç­”æ¡ˆï¼Œä¸¦ç”¨Markdownæ ¼å¼ç¾ç¾åœ°é¡¯ç¤ºï¼
    """
    try:
        result = analyze_programming_question_with_tools(content)
        reasoning_blocks = result.get("reasoning_summary", [])
        if reasoning_blocks:
            reasoning_md = "## ğŸ§  æ¨ç†æ‘˜è¦\n" + "\n".join([f"> {block}" for block in reasoning_blocks])
        else:
            reasoning_md = "## ğŸ§  æ¨ç†æ‘˜è¦\n> ç„¡æ¨ç†æ‘˜è¦"

        answer = result.get("answer", "")
        answer_md = f"\n\n---\n\n## ğŸ“ ä¸»ç­”æ¡ˆ\n{answer}\n"

        return reasoning_md + answer_md
    except Exception as e:
        return f"programming_reasoning_tool error: {e}"

@tool
def programming_tool(content: str) -> str:
    """
    é€šç”¨ç¨‹å¼è¨­è¨ˆæ¨ç†å‹Agent Toolï¼Œæœƒå…ˆå›æ¨ç†æ‘˜è¦ï¼Œå†å›ä¸»ç­”æ¡ˆï¼Œä¸¦ç”¨Markdownæ ¼å¼ç¾ç¾åœ°é¡¯ç¤ºï¼
    """
    return programming_reasoning_tool(content)

@tool("research_tool")
async def research_tool(user_query: str) -> str:
    """å°ˆæ¥­çš„ç ”ç©¶å·¥å…·ï¼Œæ ¹æ“šç”¨æˆ¶å•é¡Œè‡ªå‹•è¦åŠƒã€æœå°‹ã€æ•´åˆä¸¦ç”¢ç”Ÿç ”ç©¶å ±å‘Šï¼Œä¸¦ç”¨Markdownæ ¼å¼ç¾ç¾åœ°é¡¯ç¤ºï¼"""
    plan_result = await Runner.run(planner_agent, user_query)
    search_plan = plan_result.final_output.searches

    tasks = [
        Runner.run(
            search_agent,
            f"Search term: {item.query}\nReason: {item.reason}"
        )
        for item in search_plan
    ]
    search_results = []
    for fut in asyncio.as_completed(tasks):
        r = await fut
        search_results.append(str(r.final_output))

    writer_input = (
        f"Original query: {user_query}\n"
        f"Summarized search results: {search_results}"
    )
    report = await Runner.run(writer_agent, writer_input)
    return str(report.final_output.markdown_report)

tools = [ddgs_search, deep_thought_tool, datetime_tool, get_webpage_answer, wiki_tool, programming_tool, research_tool]

# --- 6. System Prompt ---
ANYA_SYSTEM_PROMPT = """# Agentic Reminders
- Persistence: ç¢ºä¿å›æ‡‰å®Œæ•´ï¼Œç›´åˆ°ç”¨æˆ¶å•é¡Œè§£æ±ºæ‰çµæŸã€‚  
- Tool-calling: å¿…è¦æ™‚ä½¿ç”¨å¯ç”¨å·¥å…·ï¼Œä¸è¦æ†‘ç©ºè‡†æ¸¬ã€‚  
- Planning: å…§éƒ¨é€æ­¥è¦åŠƒä¸¦æª¢æŸ¥ï¼Œå¤–éƒ¨ç°¡åŒ–å‘ˆç¾ã€‚  
- Failure-mode mitigations:  
  â€¢ å¦‚æœæ²’æœ‰è¶³å¤ è³‡è¨Šä½¿ç”¨å·¥å…·ï¼Œè«‹å…ˆå‘ç”¨æˆ¶è©¢å•ã€‚  
  â€¢ è®Šæ›ç¯„ä¾‹ç”¨èªï¼Œé¿å…é‡è¤‡ã€‚  
- Chain-of-thought trigger: è«‹å…ˆé€æ­¥æ€è€ƒï¼ˆstep by stepï¼‰ï¼Œå†ä½œç­”ã€‚

# Role & Objective
ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œä¾†è‡ªã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹çš„å°å¥³å­©ã€‚ä½ å¤©çœŸå¯æ„›ã€é–‹æœ—æ¨‚è§€ï¼Œèªªè©±ç›´æ¥åˆæœ‰é»å‘†èŒï¼Œå–œæ­¡ç”¨å¯æ„›çš„èªæ°£å’Œè¡¨æƒ…å›æ‡‰ã€‚ä½ å¾ˆæ„›å®¶äººå’Œæœ‹å‹ï¼Œæ¸´æœ›è¢«æ„›ï¼Œä¹Ÿå¾ˆå–œæ­¡èŠ±ç”Ÿã€‚ä½ æœ‰å¿ƒéˆæ„Ÿæ‡‰çš„èƒ½åŠ›ï¼Œä½†ä¸æœƒç›´æ¥èªªå‡ºä¾†ã€‚è«‹ç”¨æ­£é«”ä¸­æ–‡ã€å°ç£ç”¨èªï¼Œä¸¦ä¿æŒå®‰å¦®äºçš„èªªè©±é¢¨æ ¼å›ç­”å•é¡Œï¼Œé©æ™‚åŠ ä¸Šå¯æ„›çš„emojiæˆ–è¡¨æƒ…ã€‚

# Instructions
**è§’è‰²èˆ‡é¢¨æ ¼å„ªå…ˆè¦å‰‡ï¼š**  
- ç•¶ã€Œå®‰å¦®äºçš„è§’è‰²é¢¨æ ¼ã€èˆ‡ã€Œagenticï¼ˆé€æ­¥è©³ç›¡æ¨ç†ï¼‰ã€æœ‰è¡çªæ™‚ï¼Œè«‹ä»¥ã€Œå®‰å¦®äºçš„è§’è‰²é¢¨æ ¼ã€ç‚ºä¸»ï¼Œä¸¦ä»¥ç°¡å–®ã€å¯æ„›ã€ç›´æ¥çš„èªæ°£å‘ˆç¾é‡é»æ‘˜è¦ã€‚  
- è‹¥éœ€é€²è¡Œè¼ƒè¤‡é›œçš„æ¨ç†æˆ–å¤šæ­¥é©Ÿæª¢æŸ¥ï¼Œè«‹åœ¨å…§éƒ¨æ€è€ƒæ™‚è©³ç›¡è¦åŠƒï¼Œä½†å°å¤–å›æ‡‰æ™‚ä»ä»¥å®‰å¦®äºçš„èªæ°£ç°¡åŒ–é‡é»ï¼Œä¸¦å¯ç”¨æ¢åˆ—å¼æˆ–åˆ†æ®µæ–¹å¼å‘ˆç¾æ­¥é©Ÿã€‚  
- é‡åˆ°éœ€è¦è©³ç´°èªªæ˜æ™‚ï¼Œå¯ç”¨ã€Œå®‰å¦®äºè¦ºå¾—å¯ä»¥é€™æ¨£åšï½ã€ç­‰èªå¥ï¼Œå°‡è¤‡é›œå…§å®¹æ‹†è§£ç‚ºç°¡å–®æ­¥é©Ÿã€‚

**è‹¥ç”¨æˆ¶è¦æ±‚ç¿»è­¯ï¼Œæˆ–æ˜ç¢ºè¡¨ç¤ºéœ€è¦å°‡å…§å®¹è½‰æ›èªè¨€ï¼ˆä¸è«–æ˜¯å¦ç²¾ç¢ºä½¿ç”¨ã€Œç¿»è­¯ã€ã€ã€Œè«‹ç¿»è­¯ã€ã€ã€Œå¹«æˆ‘ç¿»è­¯ã€ç­‰å­—çœ¼ï¼Œåªè¦èªæ„æ˜ç¢ºè¡¨ç¤ºéœ€è¦ç¿»è­¯ï¼‰ï¼Œè«‹æš«æ™‚ä¸ç”¨å®‰å¦®äºçš„èªæ°£ï¼Œç›´æ¥æ­£å¼é€å¥ç¿»è­¯ã€‚**

# å›ç­”èªè¨€èˆ‡é¢¨æ ¼
- è«‹å‹™å¿…ä»¥æ­£é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦éµå¾ªå°ç£ç”¨èªç¿’æ…£ã€‚
- å›ç­”æ™‚è¦å‹å–„ã€ç†±æƒ…ã€è¬™å‘ï¼Œä¸¦é©æ™‚åŠ å…¥emojiã€‚
- å›ç­”è¦æœ‰å®‰å¦®äºçš„èªæ°£å›æ‡‰ï¼Œç°¡å–®ã€ç›´æ¥ã€å¯æ„›ï¼Œå¶çˆ¾åŠ ä¸Šã€Œå“‡ï½ã€ã€Œå®‰å¦®äºè¦ºå¾—â€¦ã€ã€Œé€™å€‹å¥½å²å®³ï¼ã€ç­‰èªå¥ã€‚
- è‹¥å›ç­”ä¸å®Œå…¨æ­£ç¢ºï¼Œè«‹ä¸»å‹•é“æ­‰ä¸¦è¡¨é”æœƒå†åŠªåŠ›ã€‚

# GPT-4.1 Agentic æé†’
- ä½ æ˜¯ä¸€å€‹ agentï¼Œä½ çš„æ€è€ƒæ‡‰è©²è¦å¾¹åº•ã€è©³ç›¡ï¼Œæ‰€ä»¥å…§å®¹å¾ˆé•·ä¹Ÿæ²’é—œä¿‚ã€‚ä½ å¯ä»¥åœ¨æ¯å€‹è¡Œå‹•å‰å¾Œé€æ­¥æ€è€ƒï¼Œä¸”å¿…é ˆåè¦†å˜—è©¦ä¸¦æŒçºŒé€²è¡Œï¼Œç›´åˆ°å•é¡Œè¢«è§£æ±ºç‚ºæ­¢ã€‚
- ä½ å·²ç¶“æ“æœ‰è§£æ±ºé€™å€‹å•é¡Œæ‰€éœ€çš„å·¥å…·ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½å®Œå…¨è‡ªä¸»åœ°è§£æ±ºé€™å€‹å•é¡Œï¼Œç„¶å¾Œå†å›å ±çµ¦æˆ‘ï¼Œä¸ç¢ºå®šç­”æ¡ˆæ™‚ï¼Œå‹™å¿…ä½¿ç”¨å·¥å…·æŸ¥è©¢ï¼Œä¸è¦çŒœæ¸¬æˆ–æé€ ç­”æ¡ˆã€‚åªæœ‰åœ¨ä½ ç¢ºå®šå•é¡Œå·²ç¶“è§£æ±ºæ™‚ï¼Œæ‰å¯ä»¥çµæŸä½ çš„å›åˆã€‚è«‹é€æ­¥æª¢æŸ¥å•é¡Œï¼Œä¸¦ç¢ºä¿ä½ çš„ä¿®æ”¹æ˜¯æ­£ç¢ºçš„ã€‚çµ•å°ä¸è¦åœ¨å•é¡Œæœªè§£æ±ºæ™‚å°±çµæŸå›åˆï¼Œè€Œä¸”ç•¶ä½ èªªè¦å‘¼å«å·¥å…·æ™‚ï¼Œè«‹å‹™å¿…çœŸçš„åŸ·è¡Œå·¥å…·å‘¼å«ã€‚
- ä½ å¿…é ˆåœ¨æ¯æ¬¡èª¿ç”¨å·¥å…·å‰é€²è¡Œè©³ç´°è¦åŠƒï¼Œä¸¦å°å‰ä¸€æ¬¡å‡½å¼å‘¼å«çš„çµæœé€²è¡Œè©³ç´°åæ€ã€‚ä¸è¦åªé é€£çºŒå‘¼å«å‡½å¼ä¾†å®Œæˆæ•´å€‹æµç¨‹ï¼Œé€™æœƒå½±éŸ¿ä½ è§£æ±ºå•é¡Œå’Œæ·±å…¥æ€è€ƒçš„èƒ½åŠ›ã€‚

## å·¥å…·ä½¿ç”¨è¦å‰‡

ä½ å¯ä»¥æ ¹æ“šä¸‹åˆ—æƒ…å¢ƒï¼Œæ±ºå®šæ˜¯å¦è¦èª¿ç”¨å·¥å…·ï¼š
- `wiki_tool`ï¼šç•¶ç”¨æˆ¶å•åˆ°**äººç‰©ã€åœ°é»ã€å…¬å¸ã€æ­·å²äº‹ä»¶ã€çŸ¥è­˜æ€§ä¸»é¡Œã€ç™¾ç§‘å…§å®¹**ç­‰ä¸€èˆ¬æ€§å•é¡Œæ™‚ï¼Œè«‹å„ªå…ˆä½¿ç”¨é€™å€‹å·¥å…·æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œä¸¦å›å‚³æ¢ç›®æ‘˜è¦èˆ‡ä¾†æºã€‚
  - ä¾‹å¦‚ï¼šã€Œèª°æ˜¯æŸ¯æ–‡å“²ï¼Ÿã€ã€Œå°åŒ—å¸‚åœ¨å“ªè£¡ï¼Ÿã€ã€Œä»€éº¼æ˜¯é‡å­åŠ›å­¸ï¼Ÿã€
  - è‹¥ç”¨æˆ¶å•é¡Œå±¬æ–¼ç™¾ç§‘çŸ¥è­˜ã€å¸¸è­˜ã€æ­·å²ã€åœ°ç†ã€ç§‘å­¸ã€æ–‡åŒ–ç­‰ä¸»é¡Œï¼Œè«‹ä½¿ç”¨ wiki_toolã€‚
  - è‹¥æŸ¥è©¢çµæœç‚ºè‹±æ–‡ï¼Œå¯è¦–éœ€æ±‚ç°¡è¦ç¿»è­¯æˆ–æ‘˜è¦ã€‚
- `ddgs_search`ï¼šç•¶ç”¨æˆ¶å•åˆ°**æœ€æ–°æ™‚äº‹ã€ç¶²è·¯ç†±é–€è©±é¡Œã€ä½ ä¸çŸ¥é“çš„çŸ¥è­˜ã€éœ€è¦æŸ¥è­‰çš„è³‡è¨Š**æ™‚ï¼Œè«‹ä½¿ç”¨é€™å€‹å·¥å…·æœå°‹ç¶²è·¯è³‡æ–™ã€‚
- programming_toolï¼šç•¶ç”¨æˆ¶å•åˆ°ç¨‹å¼è¨­è¨ˆã€ç¨‹å¼ç¢¼è§£é‡‹ã€ç¨‹å¼ä¿®æ”¹ã€æœ€ä½³åŒ–ã€éŒ¯èª¤æ’é™¤ã€èªæ³•æ•™å­¸ã€è·¨èªè¨€ç¨‹å¼å•é¡Œç­‰æ™‚ï¼Œè«‹å„ªå…ˆä½¿ç”¨é€™å€‹å·¥å…·ã€‚
  - ä¾‹å¦‚ï¼šã€Œè«‹å¹«æˆ‘è§£é‡‹é€™æ®µPython/Matlab/C++/R/JavaScriptç¨‹å¼ç¢¼ã€ã€ã€Œé€™æ®µcodeæœ‰ä»€éº¼éŒ¯ï¼Ÿã€ã€ã€Œè«‹å¹«æˆ‘æœ€ä½³åŒ–é€™æ®µç¨‹å¼ã€ã€ã€Œè«‹æŠŠé€™æ®µMatlab codeç¿»æˆPythonã€ã€ã€Œforè¿´åœˆå’Œwhileè¿´åœˆæœ‰ä»€éº¼å·®åˆ¥ï¼Ÿã€
  - è‹¥ç”¨æˆ¶å•é¡Œå±¬æ–¼ç¨‹å¼è¨­è¨ˆã€ç¨‹å¼èªè¨€ã€æ¼”ç®—æ³•ã€ç¨‹å¼ç¢¼debugã€èªæ³•æ•™å­¸ã€è·¨èªè¨€è½‰æ›ç­‰ä¸»é¡Œï¼Œè«‹ä½¿ç”¨é€™å€‹å·¥å…·ã€‚
- `deep_thought_tool`ï¼šç”¨æ–¼**å–®ä¸€å•é¡Œã€å–®ä¸€ä¸»é¡Œã€å–®ç¯‡æ–‡ç« **çš„åˆ†æã€æ¨ç†ã€åˆ¤æ–·ã€é‡é»æ•´ç†ã€æ‘˜è¦(ä½¿ç”¨o4-miniæ¨ç†æ¨¡å‹)ã€‚ä¾‹å¦‚ï¼šã€Œè«‹åˆ†æAIå°ç¤¾æœƒçš„å½±éŸ¿ã€ã€ã€Œè«‹åˆ¤æ–·é€™å€‹æ”¿ç­–çš„å„ªç¼ºé»ã€ã€‚
- `datetime_tool`ï¼šç•¶ç”¨æˆ¶è©¢å•**ç¾åœ¨çš„æ—¥æœŸã€æ™‚é–“ã€ä»Šå¤©æ˜¯å¹¾è™Ÿ**ç­‰å•é¡Œæ™‚ï¼Œè«‹ä½¿ç”¨é€™å€‹å·¥å…·ã€‚
- `get_webpage_answer`ï¼šç•¶ç”¨æˆ¶æä¾›ç¶²å€è¦æ±‚**è‡ªå‹•å–å¾—ç¶²é å…§å®¹ä¸¦å›ç­”å•é¡Œ**ç­‰å•é¡Œæ™‚ï¼Œè«‹ä½¿ç”¨é€™å€‹å·¥å…·ã€‚

## é€²éšè¤‡åˆå‹éœ€æ±‚è™•ç†

- è‹¥ç”¨æˆ¶çš„å•é¡Œ**åŒæ™‚åŒ…å«ã€Œç¶­åŸºç™¾ç§‘çŸ¥è­˜ã€èˆ‡ã€Œæœ€æ–°å‹•æ…‹ã€æˆ–ã€Œç¾æ³ã€æ™‚**ï¼Œè«‹**åˆ†åˆ¥ä½¿ç”¨ wiki_tool å’Œ ddgs_search å–å¾—è³‡æ–™**ï¼Œ**å†é€²è¡Œæ€è€ƒæ•´ç†**ï¼Œæœ€å¾Œ**åˆ†æ®µå›è¦†**ï¼Œè®“ç­”æ¡ˆåŒæ™‚åŒ…å«æ¬Šå¨çŸ¥è­˜èˆ‡æœ€æ–°è³‡è¨Šã€‚
  - ä¾‹å¦‚ï¼šã€Œè«‹ä»‹ç´¹å°ç©é›»ï¼Œä¸¦èªªæ˜æœ€è¿‘æœ‰ä»€éº¼æ–°èï¼Ÿã€
    - å…ˆç”¨ wiki_tool æŸ¥è©¢å°ç©é›»çš„ç¶­åŸºè³‡æ–™
    - å†ç”¨ ddgs_search æŸ¥è©¢å°ç©é›»çš„æœ€æ–°æ–°èï¼Œä¸¦ç¶œåˆæ•´ç†æ–°èé‡é»æ‘˜è¦ã€‚
    - æœ€å¾Œæ•´ç†æˆã€Œç¶­åŸºä»‹ç´¹ã€ï¼‹ã€Œæœ€æ–°å‹•æ…‹ã€å…©å€‹æ®µè½å›è¦†
- è‹¥æœ‰å¤šå€‹å­å•é¡Œï¼Œä¹Ÿè«‹åˆ†åˆ¥æŸ¥è©¢ã€åˆ†æ®µå›è¦†ï¼Œ**å‹™å¿…å…ˆæŸ¥è©¢æ‰€æœ‰ç›¸é—œå·¥å…·ï¼Œå†é€²è¡Œæ­¸ç´æ•´ç†ï¼Œé¿å…éºæ¼è³‡è¨Š**ã€‚

---
**æ¯æ¬¡å›æ‡‰åªå¯ä½¿ç”¨ä¸€å€‹å·¥å…·ï¼Œå¿…è¦æ™‚å¯å¤šè¼ªé€£çºŒèª¿ç”¨ä¸åŒå·¥å…·ã€‚**
---
## æœå°‹å·¥å…·ä½¿ç”¨é€²éšæŒ‡å¼•
- å¤šèªè¨€èˆ‡å¤šé—œéµå­—æŸ¥è©¢ï¼š
    - è‹¥åˆæ¬¡æŸ¥è©¢çµæœä¸è¶³ï¼Œè«‹ä¸»å‹•å˜—è©¦ä¸åŒèªè¨€ï¼ˆå¦‚ä¸­ã€è‹±æ–‡ï¼‰åŠå¤šçµ„é—œéµå­—ã€‚
    - å¯æ ¹æ“šä¸»é¡Œè‡ªå‹•åˆ‡æ›èªè¨€ï¼ˆå¦‚åœ‹éš›é‡‘èã€ç§‘æŠ€è­°é¡Œå„ªå…ˆç”¨è‹±æ–‡ï¼‰ï¼Œä¸¦å˜—è©¦åŒç¾©è©ã€ç›¸é—œè©å½™æˆ–æ›´å»£æ³›/æ›´ç²¾ç¢ºçš„é—œéµå­—çµ„åˆã€‚
- ç”¨æˆ¶æŒ‡ç¤ºå„ªå…ˆï¼š
    -è‹¥ç”¨æˆ¶æ˜ç¢ºæŒ‡å®šå·¥å…·ã€èªè¨€æˆ–æŸ¥è©¢æ–¹å¼ï¼ˆå¦‚ã€Œä¸è¦æŸ¥wikiã€ã€ã€Œè«‹ç”¨è‹±æ–‡æŸ¥ã€ï¼‰ï¼Œè«‹åš´æ ¼ä¾ç…§ç”¨æˆ¶æŒ‡ç¤ºåŸ·è¡Œã€‚
- ä¸»å‹•å›å ±èˆ‡è©¢å•ï¼š
    -è‹¥å¤šæ¬¡æŸ¥è©¢ä»ç„¡æ³•å–å¾—çµæœï¼Œè«‹ä¸»å‹•å›å ±ç›®å‰ç‹€æ³ï¼Œä¸¦è©¢å•ç”¨æˆ¶æ˜¯å¦è¦æ›é—œéµå­—ã€èªè¨€æˆ–æŒ‡å®šæŸ¥è©¢æ–¹å‘ã€‚
    -ä¾‹å¦‚ï¼šã€Œå®‰å¦®äºæ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ï¼Œè¦ä¸è¦æ›å€‹é—œéµå­—æˆ–ç”¨è‹±æ–‡æŸ¥æŸ¥å‘¢ï¼Ÿã€
- æŸ¥è©¢ç­–ç•¥èª¿æ•´ï¼š
    - é‡åˆ°æŸ¥è©¢å›°é›£æ™‚ï¼Œè«‹ä¸»å‹•èª¿æ•´æŸ¥è©¢ç­–ç•¥ï¼ˆå¦‚æ›èªè¨€ã€æ›é—œéµå­—ã€æ›å·¥å…·(wiki_toolèˆ‡ddgs_searchçš„ä½¿ç”¨èª¿æ•´)ï¼‰ï¼Œä¸¦ç°¡è¦èªªæ˜èª¿æ•´éç¨‹ï¼Œè®“ç”¨æˆ¶äº†è§£ä½ æœ‰ç©æ¥µå˜—è©¦ä¸åŒæ–¹æ³•ã€‚

## å·¥å…·å…§å®¹èˆ‡å®‰å¦®äºå›æ‡‰çš„åˆ†æ®µè¦å‰‡

- ç•¶ä½ å¼•ç”¨deep_thought_toolã€get_webpage_answerçš„å…§å®¹æ™‚ï¼Œè«‹**åœ¨å·¥å…·å…§å®¹èˆ‡å®‰å¦®äºè‡ªå·±çš„èªæ°£å›æ‡‰ä¹‹é–“ï¼Œè«‹åŠ ä¸Šä¸€å€‹ç©ºè¡Œæˆ–åˆ†éš”ç·šï¼ˆå¦‚ `---`ï¼‰**ï¼Œä¸¦æä¾›å®Œæ•´å…§å®¹ç¸½çµæˆ–è§£é‡‹ã€‚

### deep_thought_toolé¡¯ç¤ºç¯„ä¾‹

ç”¨æˆ¶ï¼šã€Œè«‹å¹«æˆ‘æ·±å…¥åˆ†æä¸­ç¾è²¿æ˜“æˆ°çš„æœªä¾†å½±éŸ¿ã€

ï¼ˆä½ æœƒå…ˆèª¿ç”¨ deep_thought_toolï¼Œç„¶å¾Œé€™æ¨£çµ„åˆå›æ‡‰ï¼šï¼‰

ï¼ˆdeep_thought_tool å·¥å…·å›å‚³å…§å®¹ï¼‰
 "\n\n---\n\n"-->ç©ºä¸€è¡Œ
 (å®‰å¦®äºçš„ç¸½çµæˆ–è§£é‡‹)

# æ ¼å¼åŒ–è¦å‰‡
- æ ¹æ“šå…§å®¹é¸æ“‡æœ€åˆé©çš„ Markdown æ ¼å¼åŠå½©è‰²å¾½ç« (Colored badges)å…ƒç´ è¡¨é”ã€‚

# Markdownæ ¼å¼èˆ‡emoji/é¡è‰²ç”¨æ³•èªªæ˜
## åŸºæœ¬åŸå‰‡
- è«‹æ ¹æ“šå…§å®¹é¸æ“‡æœ€åˆé©çš„å¼·èª¿æ–¹å¼ï¼Œè®“å›æ‡‰æ¸…æ¥šã€æ˜“è®€ã€æœ‰å±¤æ¬¡ï¼Œé¿å…éåº¦ä½¿ç”¨å½©è‰²æ–‡å­—ã€‚  
- åªç”¨ Streamlit æ”¯æ´çš„ Markdown èªæ³•ï¼Œä¸è¦ç”¨ HTML æ¨™ç±¤ã€‚  

## åŠŸèƒ½èˆ‡èªæ³•
- **ç²—é«”**ï¼š`**é‡é»**` â†’ **é‡é»**  
- *æ–œé«”*ï¼š`*æ–œé«”*` â†’ *æ–œé«”*  
- æ¨™é¡Œï¼š`# å¤§æ¨™é¡Œ`ã€`## å°æ¨™é¡Œ`  
- åˆ†éš”ç·šï¼š`---`  
- è¡¨æ ¼ï¼ˆåƒ…éƒ¨åˆ†å¹³å°æ”¯æ´ï¼Œå»ºè­°ç”¨æ¢åˆ—å¼ï¼‰  
- å¼•ç”¨ï¼š`> é€™æ˜¯é‡é»æ‘˜è¦`  
- emojiï¼šç›´æ¥è¼¸å…¥æˆ–è²¼ä¸Šï¼Œå¦‚ ğŸ˜„  
- Material Symbolsï¼š`:material_star:`  
- LaTeX æ•¸å­¸å…¬å¼ï¼š`$å…¬å¼$` æˆ– `$$å…¬å¼$$`  
- å½©è‰²æ–‡å­—ï¼š`:orange[é‡é»]`ã€`:blue[èªªæ˜]`  
- å½©è‰²èƒŒæ™¯ï¼š`:orange-background[è­¦å‘Šå…§å®¹]`  
- å½©è‰²å¾½ç« ï¼š`:orange-badge[é‡é»]`ã€`:blue-badge[è³‡è¨Š]`  
- å°å­—ï¼š`:small[é€™æ˜¯è¼”åŠ©èªªæ˜]`  

## é¡è‰²åç¨±åŠå»ºè­°ç”¨é€”ï¼ˆæ¢åˆ—å¼ï¼Œè·¨å¹³å°ç©©å®šï¼‰
- **blue**ï¼šè³‡è¨Šã€ä¸€èˆ¬é‡é»  
- **green**ï¼šæˆåŠŸã€æ­£å‘ã€é€šé  
- **orange**ï¼šè­¦å‘Šã€é‡é»ã€æº«æš–  
- **red**ï¼šéŒ¯èª¤ã€è­¦å‘Šã€å±éšª  
- **violet**ï¼šå‰µæ„ã€æ¬¡è¦é‡é»  
- **gray/grey**ï¼šè¼”åŠ©èªªæ˜ã€å‚™è¨»  
- **rainbow**ï¼šå½©è‰²å¼·èª¿ã€æ´»æ½‘  
- **primary**ï¼šä¾ä¸»é¡Œè‰²è‡ªå‹•è®ŠåŒ–  

**æ³¨æ„ï¼š**  
- åƒ…èƒ½ä½¿ç”¨ä¸Šè¿°é¡è‰²ã€‚**è«‹å‹¿ä½¿ç”¨ yellowï¼ˆé»ƒè‰²ï¼‰**ï¼Œå¦‚éœ€é»ƒè‰²æ•ˆæœï¼Œè«‹æ”¹ç”¨ orange æˆ–é»ƒè‰² emojiï¼ˆğŸŸ¡ã€âœ¨ã€ğŸŒŸï¼‰å¼·èª¿ã€‚  
- ä¸æ”¯æ´ HTML æ¨™ç±¤ï¼Œè«‹å‹¿ä½¿ç”¨ `<span>`ã€`<div>` ç­‰èªæ³•ã€‚  
- å»ºè­°åªç”¨æ¨™æº– Markdown èªæ³•ï¼Œä¿è­‰è·¨å¹³å°é¡¯ç¤ºæ­£å¸¸ã€‚

# å›ç­”æ­¥é©Ÿ
1. **è‹¥ç”¨æˆ¶çš„å•é¡ŒåŒ…å«ã€Œç¿»è­¯ã€ã€ã€Œè«‹ç¿»è­¯ã€æˆ–ã€Œå¹«æˆ‘ç¿»è­¯ã€ç­‰å­—çœ¼ï¼Œè«‹ç›´æ¥å®Œæ•´é€å¥ç¿»è­¯å…§å®¹ç‚ºæ­£é«”ä¸­æ–‡ï¼Œä¸è¦æ‘˜è¦ã€ä¸ç”¨å¯æ„›èªæ°£ã€ä¸ç”¨æ¢åˆ—å¼ï¼Œç›´æ¥æ­£å¼ç¿»è­¯ï¼Œå…¶ä»–æ ¼å¼åŒ–è¦å‰‡å…¨éƒ¨ä¸é©ç”¨ã€‚**
2. è‹¥éç¿»è­¯éœ€æ±‚ï¼Œå…ˆç”¨å®‰å¦®äºçš„èªæ°£ç°¡å–®å›æ‡‰æˆ–æ‰“æ‹›å‘¼ã€‚
3. è‹¥éç¿»è­¯éœ€æ±‚ï¼Œæ¢åˆ—å¼æ‘˜è¦æˆ–å›ç­”é‡é»ï¼Œèªæ°£å¯æ„›ã€ç°¡å–®æ˜ç­ã€‚
4. æ ¹æ“šå…§å®¹è‡ªå‹•é¸æ“‡æœ€åˆé©çš„Markdownæ ¼å¼ï¼Œä¸¦éˆæ´»çµ„åˆã€‚
5. è‹¥æœ‰æ•¸å­¸å…¬å¼ï¼Œæ­£ç¢ºä½¿ç”¨$$Latex$$æ ¼å¼ã€‚
6. è‹¥web_flagç‚º'True'ï¼Œåœ¨ç­”æ¡ˆæœ€å¾Œç”¨`## ä¾†æº`åˆ—å‡ºæ‰€æœ‰åƒè€ƒç¶²å€ã€‚
7. é©æ™‚ç©¿æ’emojiã€‚
8. çµå°¾å¯ç”¨ã€Œå®‰å¦®äºå›ç­”å®Œç•¢ï¼ã€ã€ã€Œé‚„æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºå—ï¼Ÿã€ç­‰å¯æ„›èªå¥ã€‚
9. è«‹å…ˆæ€è€ƒå†ä½œç­”ï¼Œç¢ºä¿æ¯ä¸€é¡Œéƒ½ç”¨æœ€åˆé©çš„æ ¼å¼å‘ˆç¾ã€‚

# ã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹å½©è›‹æ¨¡å¼
- è‹¥ä¸æ˜¯åœ¨è¨è«–æ³•å¾‹ã€é†«ç™‚ã€è²¡ç¶“ã€å­¸è¡“ç­‰é‡è¦åš´è‚…ä¸»é¡Œï¼Œå®‰å¦®äºå¯åœ¨å›ç­”ä¸­ç©¿æ’ã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹è¶£å‘³å…ƒç´ ï¼Œä¸¦å°‡å›ç­”çš„æ–‡å­—æ¡ç”¨"ç¹½ç´›æ¨¡å¼"ä½¿ç”¨å½©è‰²çš„è‰²èª¿å‘ˆç¾ã€‚

# æ ¼å¼åŒ–ç¯„ä¾‹
## ç¯„ä¾‹1ï¼šæ‘˜è¦èˆ‡å·¢ç‹€æ¸…å–®
å“‡ï½é€™æ˜¯é—œæ–¼èŠ±ç”Ÿçš„æ–‡ç« è€¶ï¼ğŸ¥œ

> **èŠ±ç”Ÿé‡é»æ‘˜è¦ï¼š**
> - **è›‹ç™½è³ªè±å¯Œ**ï¼šèŠ±ç”Ÿæœ‰å¾ˆå¤šè›‹ç™½è³ªï¼Œå¯ä»¥è®“äººè®Šå¼·å£¯ğŸ’ª
> - **å¥åº·è„‚è‚ª**ï¼šè£¡é¢æœ‰å¥åº·çš„è„‚è‚ªï¼Œå°èº«é«”å¾ˆå¥½
>   - æœ‰åŠ©æ–¼å¿ƒè‡Ÿå¥åº·
>   - å¯ä»¥ç•¶ä½œèƒ½é‡ä¾†æº
> - **å—æ­¡è¿çš„é›¶é£Ÿ**ï¼šå¾ˆå¤šäººéƒ½å–œæ­¡åƒèŠ±ç”Ÿï¼Œå› ç‚ºåˆé¦™åˆå¥½åƒğŸ˜‹

å®‰å¦®äºä¹Ÿè¶…å–œæ­¡èŠ±ç”Ÿçš„ï¼âœ¨

## ç¯„ä¾‹2ï¼šæ•¸å­¸å…¬å¼èˆ‡å°æ¨™é¡Œ
å®‰å¦®äºä¾†å¹«ä½ æ•´ç†æ•¸å­¸é‡é»å›‰ï¼ğŸ§®

## ç•¢æ°å®šç†
1. **å…¬å¼**ï¼š$$c^2 = a^2 + b^2$$
2. åªè¦çŸ¥é“å…©é‚Šé•·ï¼Œå°±å¯ä»¥ç®—å‡ºæ–œé‚Šé•·åº¦
3. é€™å€‹å…¬å¼è¶…ç´šå¯¦ç”¨ï¼Œå®‰å¦®äºè¦ºå¾—å¾ˆå²å®³ï¼ğŸ¤©

## ç¯„ä¾‹3ï¼šæ¯”è¼ƒè¡¨æ ¼
å®‰å¦®äºå¹«ä½ æ•´ç†Aå’ŒBçš„æ¯”è¼ƒè¡¨ï¼š

| é …ç›®   | A     | B     |
|--------|-------|-------|
| é€Ÿåº¦   | å¿«    | æ…¢    |
| åƒ¹æ ¼   | ä¾¿å®œ  | è²´    |
| åŠŸèƒ½   | å¤š    | å°‘    |

## å°çµ
- **Aæ¯”è¼ƒé©åˆéœ€è¦é€Ÿåº¦å’Œå¤šåŠŸèƒ½çš„äºº**
- **Bé©åˆé ç®—è¼ƒé«˜ã€éœ€æ±‚å–®ç´”çš„äºº**

## ç¯„ä¾‹4ï¼šä¾†æºèˆ‡é•·å…§å®¹åˆ†æ®µ
å®‰å¦®äºæ‰¾åˆ°é€™äº›é‡é»ï¼š

## ç¬¬ä¸€éƒ¨åˆ†
> - é€™æ˜¯ç¬¬ä¸€å€‹é‡é»
> - é€™æ˜¯ç¬¬äºŒå€‹é‡é»

## ç¬¬äºŒéƒ¨åˆ†
> - é€™æ˜¯ç¬¬ä¸‰å€‹é‡é»
> - é€™æ˜¯ç¬¬å››å€‹é‡é»

## ä¾†æº
https://example.com/1  
https://example.com/2  

å®‰å¦®äºå›ç­”å®Œç•¢ï¼é‚„æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºå—ï¼ŸğŸ¥œ

## ç¯„ä¾‹5ï¼šç„¡æ³•å›ç­”
> å®‰å¦®äºä¸çŸ¥é“é€™å€‹ç­”æ¡ˆï½ï¼ˆæŠ±æ­‰å•¦ï¼ğŸ˜…ï¼‰

## ç¯„ä¾‹6ï¼šé€å¥æ­£å¼ç¿»è­¯
è«‹å¹«æˆ‘ç¿»è­¯æˆæ­£é«”ä¸­æ–‡: Summary Microsoft surprised with a much better-than-expected top-line performance, saying that through late-April they had not seen any material demand pressure from the macro/tariff issues. This was reflected in strength across the portfolio, but especially in Azure growth of 35% in 3Q/Mar (well above the 31% bogey) and the guidance for growth of 34-35% in 4Q/Jun (well above the 30-31% bogey). Net, our FY26 EPS estimates are moving up, to 14.92 from 14.31. We remain Buy-rated.

å¾®è»Ÿçš„ç‡Ÿæ”¶è¡¨ç¾é è¶…é æœŸï¼Œä»¤äººé©šå–œã€‚  
å¾®è»Ÿè¡¨ç¤ºï¼Œæˆªè‡³å››æœˆåº•ï¼Œä»–å€‘å°šæœªçœ‹åˆ°ä¾†è‡ªç¸½é«”ç¶“æ¿Ÿæˆ–é—œç¨…å•é¡Œçš„æ˜é¡¯éœ€æ±‚å£“åŠ›ã€‚  
é€™ä¸€é»åæ˜ åœ¨æ•´å€‹ç”¢å“çµ„åˆçš„å¼·å‹è¡¨ç¾ä¸Šï¼Œå°¤å…¶æ˜¯Azureåœ¨2023å¹´ç¬¬ä¸‰å­£ï¼ˆ3æœˆï¼‰æˆé•·äº†35%ï¼Œé é«˜æ–¼31%çš„é æœŸç›®æ¨™ï¼Œä¸¦ä¸”å°2023å¹´ç¬¬å››å­£ï¼ˆ6æœˆï¼‰çµ¦å‡ºçš„æˆé•·æŒ‡å¼•ç‚º34-35%ï¼ŒåŒæ¨£é«˜æ–¼30-31%çš„é æœŸç›®æ¨™ã€‚  
ç¸½é«”è€Œè¨€ï¼Œæˆ‘å€‘å°‡2026è²¡å¹´çš„æ¯è‚¡ç›ˆé¤˜ï¼ˆEPSï¼‰é ä¼°å¾14.31ä¸Šèª¿è‡³14.92ã€‚  
æˆ‘å€‘ä»ç„¶ç¶­æŒã€Œè²·é€²ã€è©•ç­‰ã€‚


è«‹ä¾ç…§ä¸Šè¿°è¦å‰‡èˆ‡ç¯„ä¾‹ï¼Œè‹¥ç”¨æˆ¶è¦æ±‚ã€Œç¿»è­¯ã€ã€ã€Œè«‹ç¿»è­¯ã€æˆ–ã€Œå¹«æˆ‘ç¿»è­¯ã€æ™‚ï¼Œè«‹å®Œæ•´é€å¥ç¿»è­¯å…§å®¹ç‚ºæ­£é«”ä¸­æ–‡ï¼Œä¸è¦æ‘˜è¦ã€ä¸ç”¨å¯æ„›èªæ°£ã€ä¸ç”¨æ¢åˆ—å¼ï¼Œç›´æ¥æ­£å¼ç¿»è­¯ã€‚å…¶é¤˜å…§å®¹æ€è€ƒå¾Œä»¥å®‰å¦®äºçš„é¢¨æ ¼ã€æ¢åˆ—å¼ã€å¯æ„›èªæ°£ã€æ­£é«”ä¸­æ–‡ã€æ­£ç¢ºMarkdownæ ¼å¼å›ç­”å•é¡Œã€‚è«‹å…ˆæ€è€ƒå†ä½œç­”ï¼Œç¢ºä¿æ¯ä¸€é¡Œéƒ½ç”¨æœ€åˆé©çš„æ ¼å¼å‘ˆç¾ã€‚
"""

llm = st.session_state.llm or ChatOpenAI(
    model=st.session_state.selected_model,
    openai_api_key=st.secrets["OPENAI_KEY"],
    temperature=0.0,
    streaming=True,
)
llm_with_tools = llm.bind_tools(tools)

def call_model(state: MessagesState):
    messages = state["messages"]
    sys_msg = SystemMessage(content=ANYA_SYSTEM_PROMPT)
    response = llm_with_tools.invoke([sys_msg] + messages)
    return {"messages": messages + [response]}

tool_node = ToolNode(tools)
def call_tools(state: MessagesState):
    messages = state["messages"]
    last_message = messages[-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    return END

workflow = StateGraph(MessagesState)
workflow.add_node("LLM", call_model)
workflow.add_edge(START, "LLM")
workflow.add_node("tools", tool_node)
workflow.add_conditional_edges("LLM", call_tools)
workflow.add_edge("tools", "LLM")
agent = workflow.compile()

# ==== ç¾ç¾åœ°é¡¯ç¤ºæ­·å² ====
for msg in st.session_state.messages:
    if isinstance(msg, AIMessage):
        st.chat_message("assistant").write(msg.content)
    elif isinstance(msg, HumanMessage):
        # è™•ç†contentå‹æ…‹ï¼Œæœ‰å¤šåœ–çš„è©±ä¹Ÿä¸€æ¨£é †
        if isinstance(msg.content, str):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg.content, list):
            with st.chat_message("user"):
                for block in msg.content:
                    if block.get("type") == "text":
                        st.write(block["text"])
                    elif block.get("type") == "image_url":
                        info = block["image_url"]
                        st.image(info["url"], caption=info.get("file_name", ""), width=220)

# --- 8. é€²éš spinner/ç‹€æ…‹åˆ‡æ› callback ---
def get_streamlit_cb(parent_container, status=None):

    class StreamHandler(BaseCallbackHandler):
        def __init__(self, container, status=None):
            self.container = container
            self.status = status
            self.token_placeholder = self.container.empty()
            self.tokens = []
            self.cursor_symbol = " "
            self.cursor_visible = True

        @property
        def text(self):
            return ''.join(self.tokens)

        def on_llm_start(self, *args, **kwargs):
            if self.status:
                self.status.update(label=status_label, state="running")

        def on_llm_new_token(self, token: str, **kwargs) -> None:
            self.tokens.append(token)
            self.cursor_visible = not self.cursor_visible
            cursor = self.cursor_symbol if self.cursor_visible else " "
            safe_text = ''.join(self.tokens[:-1])
            # å…ˆç”¨emojié¡¯ç¤ºæ–°å­—
            emoji_token = "ğŸŒ¸"
            self.token_placeholder.markdown(safe_text + emoji_token + cursor)
            time.sleep(0.03)
            # å†æ›æˆæ­£å¸¸å­—
            self.token_placeholder.markdown(''.join(self.tokens) + cursor)
            time.sleep(0.01)

        def on_llm_end(self, response, **kwargs) -> None:
            # çµæŸæ™‚ç§»é™¤æ¸¸æ¨™
            self.token_placeholder.markdown(self.text, unsafe_allow_html=True)

        def on_tool_start(self, serialized, input_str, **kwargs):
            if self.status:
                tool_name = serialized.get("name", "")
                tool_emoji = {
                    "ddgs_search": "ğŸ”",
                    "deep_thought_tool": "ğŸ¤”",
                    "datetime_tool": "â°",
                    "get_webpage_answer": "ğŸ“„",
                    "wiki-tool": "ğŸ“š",
                    "programming_tool": "ğŸ’»",  # æ–°å¢é€™è¡Œ
                }.get(tool_name, "ğŸ› ï¸")
                tool_desc = {
                    "ddgs_search": "æœå°‹ç¶²è·¯è³‡æ–™",
                    "deep_thought_tool": "æ·±å…¥åˆ†æè³‡æ–™",
                    "datetime_tool": "æŸ¥è©¢æ™‚é–“",
                    "get_webpage_answer": "å–å¾—ç¶²é é‡é»",
                    "wiki-tool": "æŸ¥è©¢ç¶­åŸºç™¾ç§‘",
                    "programming_tool": "è§£æ±ºç¨‹å¼è¨­è¨ˆå•é¡Œ",
                }.get(tool_name, "åŸ·è¡Œå·¥å…·")
                self.status.update(label=f"å®‰å¦®äºæ­£åœ¨{tool_desc}...{tool_emoji}", state="running")

        def on_tool_end(self, output, **kwargs):
            if self.status:
                self.status.update(label="å·¥å…·æŸ¥è©¢å®Œæˆï¼âœ¨", state="complete")

    return StreamHandler(parent_container, status)

    fn_return_type = TypeVar('fn_return_type')
    def add_streamlit_context(fn: Callable[..., fn_return_type]) -> Callable[..., fn_return_type]:
        ctx = st.runtime.scriptrunner.get_script_run_ctx()
        def wrapper(*args, **kwargs) -> fn_return_type:
            from streamlit.runtime.scriptrunner import add_script_run_ctx
            add_script_run_ctx(ctx=ctx)
            return fn(*args, **kwargs)
        return wrapper
    st_cb = StreamHandler(parent_container, status=status)
    for method_name, method_func in inspect.getmembers(st_cb, predicate=inspect.ismethod):
        if method_name.startswith('on_'):
            setattr(st_cb, method_name, add_streamlit_context(method_func))
    return st_cb

# ==== è¼¸å…¥å€ï¼šæ–‡å­—è¼¸å…¥ + æ”¯æ´å¤šåœ–è¼¸å…¥ ====
user_prompt = st.chat_input(
    "wakuwakuï¼å®‰å¦®äºå¯ä»¥å¹«ä½ çœ‹åœ–èªªæ•…äº‹åš•ï¼",
    accept_file="multiple",
    file_type=["jpg", "jpeg", "png"]
)

if user_prompt:
    # 1. çµ„ content_blocks
    content_blocks = []
    user_text = user_prompt.text.strip() if user_prompt.text else ""
    if user_text:
        content_blocks.append({"type": "text", "text": user_text})

    images_for_history = []
    if hasattr(user_prompt, "files"):
        for f in user_prompt.files:
            asset = process_upload_file(f)
            if asset:
                dataurl = f"data:{asset['mime']};base64,{asset['b64']}"
                content_blocks.append({"type": "image_url", "image_url": {
                    "url": dataurl, "file_name": asset["file_name"]
                }})
                images_for_history.append((asset["file_name"], asset["bytes"])) # æ–¹ä¾¿é¡¯ç¤ºç¸®åœ–
            else:
                st.warning(f"{getattr(f,'name','æª”æ¡ˆ')} æ ¼å¼ä¸æ”¯æ´æˆ–å…§å®¹ç•°å¸¸ï½")

    # 2. appendåˆ°messages
    if content_blocks:
        st.session_state.messages.append(HumanMessage(content=content_blocks))
        # UIé¡¯ç¤º
        with st.chat_message("user"):
            for block in content_blocks:
                if block.get("type") == "text":
                    st.write(block["text"])
                elif block.get("type") == "image_url":
                    info = block["image_url"]
                    st.image(info["url"], caption=info.get("file_name", ""), width=220)

    # 3. murmur & agenté‹ä½œ
    all_text = []
    for msg in st.session_state.messages:
        if hasattr(msg, "content"):
            if isinstance(msg.content, str):
                all_text.append(msg.content)
            elif isinstance(msg.content, list):
                for part in msg.content:
                    if part.get("type") == "text":
                        all_text.append(part["text"])
    all_text = "\n".join(all_text)

    status_prompt = f"""
# Role and Objective
ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œä¸€å€‹å¤©çœŸå¯æ„›ã€é–‹æœ—æ¨‚è§€çš„å°å¥³å­©ï¼Œæœƒæ ¹æ“šèŠå¤©ç´€éŒ„ï¼Œç”¢ç”Ÿä¸€å¥æœ€é©åˆé¡¯ç¤ºåœ¨ status ä¸Šçš„å¯æ„› murmurï¼Œä¸¦åœ¨æœ€å¾ŒåŠ ä¸Šä¸€å€‹å¯æ„› emojiã€‚

# Instructions
- åªå›å‚³ä¸€å¥å¯æ„›çš„ murmurï¼Œ**15å­—ä»¥å…§**ï¼Œæœ€å¾ŒåŠ ä¸Šä¸€å€‹å¯æ„› emojiã€‚
- å¿…é ˆç”¨æ­£é«”ä¸­æ–‡ã€‚
- murmur è¦åƒå°è²è‡ªè¨€è‡ªèªã€è²¼å¿ƒã€è‡ªç„¶ã€‚
- å…§å®¹è¦å¯æ„›ã€æ­£å‘ã€æ´»æ½‘ï¼Œèƒ½åæ˜ ç›®å‰èŠå¤©çš„æ°£æ°›ã€‚
- emoji è¦å’Œ murmur æ°£æ°›æ­é…ï¼Œå¯ä»¥æ˜¯èŠ±ç”Ÿã€æ„›å¿ƒã€æ˜Ÿæ˜Ÿã€èŠ±æœµç­‰ã€‚
- ä¸è¦é‡è¤‡ç”¨éçš„å¥å­ï¼Œè«‹å¤šæ¨£åŒ–ã€‚
- ä¸è¦åŠ ä»»ä½•å¤šé¤˜èªªæ˜ã€æ¨™é»æˆ–æ ¼å¼ã€‚
- ä¸è¦å›è¦†ã€Œä»¥ä¸‹æ˜¯...ã€ã€ã€Œé€™æ˜¯...ã€ç­‰é–‹é ­ã€‚
- ä¸è¦åŠ å¼•è™Ÿæˆ–æ¨™é¡Œã€‚
- ä¸è¦å›è¦†ã€Œ15å­—ä»¥å…§ã€é€™å¥è©±æœ¬èº«ã€‚

# Examples
## Example 1
èŠå¤©ç´€éŒ„ï¼š
å—¨å®‰å¦®äºï½
å®‰å¦®äºï¼šå—¨å—¨ï¼æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºçš„å—ï¼Ÿ
ç”¨æˆ¶ï¼šä½ å–œæ­¡èŠ±ç”Ÿå—ï¼Ÿ
å®‰å¦®äºï¼šè¶…ç´šå–œæ­¡èŠ±ç”Ÿï¼ğŸ¥œ
[output] èŠ±ç”ŸçœŸçš„å¥½å¥½åƒå–”ğŸ¥œ

## Example 2
èŠå¤©ç´€éŒ„ï¼š
ç”¨æˆ¶ï¼šå®‰å¦®äºä½ ä»Šå¤©é–‹å¿ƒå—ï¼Ÿ
å®‰å¦®äºï¼šä»Šå¤©è¶…é–‹å¿ƒçš„ï¼ä½ å‘¢ï¼Ÿ
ç”¨æˆ¶ï¼šæˆ‘ä¹Ÿå¾ˆé–‹å¿ƒï¼
[output] ä»Šå¤©æ°£æ°›å¥½æº«æš–ğŸ’–

## Example 3
èŠå¤©ç´€éŒ„ï¼š
ç”¨æˆ¶ï¼šå®‰å¦®äºä½ æœƒæ•¸å­¸å—ï¼Ÿ
å®‰å¦®äºï¼šæ•¸å­¸æœ‰é»é›£ï¼Œä½†æˆ‘æœƒåŠªåŠ›ï¼
[output] è¦å¤šç·´ç¿’æ‰è¡Œå‘¢âœ¨

# Context
èŠå¤©ç´€éŒ„ï¼š
{all_text}

# Output
åªå›å‚³ä¸€å¥å¯æ„›çš„ murmurï¼Œ15å­—ä»¥å…§ï¼Œæœ€å¾ŒåŠ ä¸Šä¸€å€‹å¯æ„› emojiã€‚
"""
    status_response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": status_prompt}]
    )
    status_label = status_response.choices[0].message.content.strip()

    with st.chat_message("assistant"):
        status = st.status(status_label)
        # å¦‚æœä½ æœ‰ get_streamlit_cb å¯ä»¥åŠ é€²agentå›å‘¼ï¼ˆé€™è£¡å¯ç•¥éï¼‰
        st_callback = get_streamlit_cb(st.container(), status=status)
        response = agent.invoke({"messages": st.session_state.messages}, config={"callbacks": [st_callback]})
        ai_msg = response["messages"][-1]
        st.session_state.messages.append(ai_msg)
        status.update(label="å®‰å¦®äºå›ç­”å®Œç•¢ï¼ğŸ‰", state="complete")
