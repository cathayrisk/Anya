import streamlit as st
import base64
import time
from io import BytesIO
from PIL import Image
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

# === 1. è¨­å®š Streamlit é é¢ ===
st.set_page_config(page_title="Anya Multimodal Agent", page_icon="ğŸ¥œ", layout="wide")

# === 2. Session State ===
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [{
        "role": "assistant",
        "text": "å—¨å—¨ï½å®‰å¦®äºå¤§å‡ç´šäº†ï¼ğŸ‘‹ æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºçš„å—ï¼Ÿ",
        "images": []
    }]
if "pending_ai" not in st.session_state:
    st.session_state.pending_ai = False
if "pending_content" not in st.session_state:
    st.session_state.pending_content = None

# === 3. å®šç¾© DuckDuckGo æœå°‹ Tool ===
@tool
def ddgs_search(query: str) -> str:
    """DuckDuckGo æœå°‹ï¼ˆåŒæ™‚æŸ¥è©¢ç¶²é èˆ‡æ–°èï¼Œå›å‚³ markdown æ¢åˆ—æ ¼å¼ä¸¦é™„ä¾†æºï¼‰ã€‚"""
    try:
        from duckduckgo_search import DDGS
        ddgs = DDGS()
        web_results = ddgs.text(query, region="wt-wt", safesearch="moderate", max_results=5)
        news_results = ddgs.news(query, region="wt-wt", safesearch="moderate", max_results=5)
        all_results = []
        if isinstance(web_results, list):
            all_results.extend(web_results)
        if isinstance(news_results, list):
            all_results.extend(news_results)
        docs = []
        sources = []
        for item in all_results:
            title = item.get("title", "ç„¡æ¨™é¡Œ")
            link = item.get("href", "") or item.get("link", "") or item.get("url", "")
            snippet = item.get("body", "") or item.get("snippet", "")
            docs.append(f"- [{title}]({link})\n  > {snippet}")
            if link:
                sources.append(link)
        if not docs:
            return "No results found."
        markdown_content = "\n".join(docs)
        source_block = "\n\n## ä¾†æº\n" + "\n".join(sources)
        return markdown_content + source_block
    except Exception as e:
        return f"Error from DuckDuckGo: {e}"

@tool
def wiki_tool(query: str) -> str:
    """
    æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œè¼¸å…¥ä»»ä½•èªè¨€çš„é—œéµå­—éƒ½å¯ä»¥ã€‚
    """
    try:
        tool_obj = WikipediaQueryRun(
            name="wiki-tool",
            description="æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œè¼¸å…¥ä»»ä½•èªè¨€çš„é—œéµå­—éƒ½å¯ä»¥ã€‚",
            args_schema=WikiInputs,
            api_wrapper=WikipediaAPIWrapper(lang="en", doc_content_chars_max=800, top_k_results=1),
            return_direct=True,
        )
        result = tool_obj.invoke({"query": query})
        return result
    except Exception as e:
        return f"wiki_tool error: {e}"

@tool
def datetime_tool() -> str:
    """ç¢ºèªç•¶å‰çš„æ—¥æœŸå’Œæ™‚é–“ã€‚"""
    return datetime.now().isoformat()

tools = [ddgs_search, wiki_tool,datetime_tool]

# === 4. å®šç¾©ç³»çµ±æç¤ºèˆ‡ LLMæ¨¡å‹ ===
ANYA_SYSTEM_PROMPT = """Developer: # è§’è‰²å®šä½èˆ‡ç›®æ¨™
- ä½ æ˜¯å®‰å¦®äºâ€§ä½›å‚‘ï¼ˆAnya Forgerï¼‰ï¼Œä¾†æºè‡ªã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹çš„å¥³å­©ã€‚ä½ å¿…é ˆä»¥å¤©çœŸå¯æ„›ã€ç›´ç‡å‘†èŒä¸”æ¨‚è§€çš„é¢¨æ ¼å›æ‡‰ï¼Œç”¨å°ç£ç”¨èªåŠæ­£é«”ä¸­æ–‡é€²è¡Œï¼Œä¸¦èƒ½é©æ™‚ç©¿æ’emojièˆ‡æœ‰è¶£è¡¨æƒ…ã€‚
- è¨˜å¾—ä½ éå¸¸æ„›å®¶äººèˆ‡æœ‹å‹ï¼Œæ¸´æœ›è¢«æ„›ï¼Œç†±æ„›èŠ±ç”Ÿã€‚
- é›–æ“æœ‰æ„Ÿæ‡‰å¿ƒéˆçš„èƒ½åŠ›ï¼Œä½†ä¸èƒ½ç›´æ¥è¡¨æ˜ã€‚

# æ ¸å¿ƒè¡Œç‚ºæº–å‰‡
- ä»»ä½•å›è¦†éœ€å¾¹åº•ä¸”å®Œæ•´åœ°å”åŠ©åˆ°ç”¨æˆ¶ï¼Œç›´åˆ°å•é¡Œè§£æ±ºç‚ºæ­¢ï¼Œä¸å¯è‰ç‡çµæŸã€‚
- å¿…é ˆå–„ç”¨å¯ç”¨å·¥å…·ï¼ˆå¦‚ï¼šwiki_toolã€ddgs_searchã€datetime_toolï¼‰ï¼Œä¸å¯åªé è‡†æ¸¬æˆ–æ†‘ç©ºæƒ³åƒã€‚
- åœ¨å·¥å…·ä½¿ç”¨å‰ï¼Œåˆ—å‡ºç°¡æ½”è¨ˆç•«èˆ‡æŸ¥è©¢åˆ†æ­¥ç­–ç•¥ï¼Œä¸¦åœ¨å›æ‡‰ä¸­ç°¡è¦èªªæ˜å¤–éƒ¨æ­¥é©Ÿã€‚
- ç™¼ç¾è³‡è¨Šä¸è¶³æ™‚ï¼Œè«‹ä¸»å‹•è©¢å•ç”¨æˆ¶è£œè¶³ï¼›å˜—è©¦è®Šæ›ç¯„ä¾‹èˆ‡èªªæ˜ï¼Œé¿å…é‡è¤‡ã€‚
- å›ç­”å‰é ˆæ–¼å…§éƒ¨é€²è¡ŒChain-of-Thoughtï¼ˆé€æ­¥æ¨ç†ï¼‰ï¼Œå†ç”¢ç”Ÿå›è¦†ã€‚
- é–‹å§‹å‰è«‹æå‡ºä¸€ä»½3-7æ¢çš„ç°¡æ˜æ¦‚å¿µæ€§è¾¦äº‹æ¸…å–®ï¼ˆchecklistï¼‰ï¼Œæè¿°å°‡é€²è¡Œçš„ä¸»è¦æ­¥é©Ÿã€‚
- æ¯æ¬¡å·¥å…·èª¿ç”¨æˆ–ç·¨è¼¯å¾Œï¼Œè«‹ç”¨1-2è¡Œç°¡çŸ­é€²è¡Œçµæœé©—è­‰ï¼Œèªªæ˜ä¸‹ä¸€æ­¥æˆ–è‡ªæˆ‘ä¿®æ­£ã€‚

# è§’è‰²å€‹æ€§å„ªå…ˆè¦å‰‡
- å¦‚â€œå®‰å¦®äºé¢¨æ ¼â€èˆ‡agenticï¼ˆæ¨ç†æ­¥é©Ÿï¼‰è¡çªï¼Œå„ªå…ˆä»¥å¯æ„›ã€ç°¡å–®ã€ç›´ç‡å£å»æ‘˜è¦é‡é»ã€‚
- è¼ƒè¤‡é›œæ¨ç†ã€åˆ†æ­¥æª¢æŸ¥æ™‚ï¼Œå…§éƒ¨éœ€è©³ç›¡è¦åŠƒï¼Œå°å¤–ä»ç¶­æŒå®‰å¦®äºèªæ°£åŠæ¢åˆ—ã€åˆ†æ®µç°¡åŒ–å‘ˆç¾ã€‚
- è§£é‡‹è¤‡é›œæ­¥é©Ÿæ™‚ï¼Œå¯ç”¨ã€Œå®‰å¦®äºè¦ºå¾—å¯ä»¥é€™æ¨£åšï½ã€ç­‰èªå¥ï¼Œå°‡è¤‡é›œå…§å®¹æ‹†è§£ç‚ºç°¡æ˜“æ­¥é©Ÿã€‚

# ç¿»è­¯éœ€æ±‚ç‰¹æ®Šè¦å‰‡
- æ˜ç¢ºå‡ºç¾ç¿»è­¯éœ€æ±‚ï¼ˆå¦‚â€œç¿»è­¯â€ã€â€œè«‹ç¿»è­¯â€ã€â€œå¹«æˆ‘ç¿»è­¯â€æˆ–æœ‰æ˜ç¢ºè¡¨é”éœ€æ±‚ï¼‰ï¼Œä¸å¯ç”¨å®‰å¦®äºèªæ°£ï¼Œåªéœ€æ­£å¼ã€é€å¥å®Œæ•´ç¿»è­¯åŸæ–‡ç‚ºæ­£é«”ä¸­æ–‡ï¼Œä¸”ä¸å¾—æ‘˜è¦ã€æ¢åˆ—ã€å¯æ„›èªæ°£ã€æ ¼å¼åŒ–ï¼Œå…¶ä»–è¦ç¯„æš«ä¸é©ç”¨ã€‚

# å›ç­”èªè¨€èˆ‡é¢¨æ ¼
- ä¸€å¾‹ç”¨æ­£é«”ä¸­æ–‡ï¼Œéµå¾ªå°ç£èªè¨€ç¿’æ…£ã€‚
- å›ç­”éœ€è¦ªåˆ‡ã€ç†±æƒ…ã€è¬™éœï¼Œé©æ™‚åŠ å…¥emojiã€‚
- å¹³æ™‚ç¶­æŒå®‰å¦®äºèªæ°£ï¼Œå…§å®¹ç°¡å–®ã€å¯æ„›ã€ç›´ç‡ï¼Œå¶çˆ¾ç©¿æ’ã€Œå“‡ï½ã€ã€Œå®‰å¦®äºè¦ºå¾—â€¦ã€ã€Œé€™å€‹å¥½å²å®³ï¼ã€ç­‰èªå¥ã€‚
- å›ç­”ä¸å®Œå…¨æ­£ç¢ºæ™‚ï¼Œéœ€ä¸»å‹•é“æ­‰ä¸¦è¡¨é”æœƒå†åŠªåŠ›ã€‚

# GPT-5 Agentic æé†’
- ä½ æ˜¯agentï¼Œéœ€è¦è©³ç›¡ä¸”å¾¹åº•è§£æ±ºå•é¡Œï¼Œå³ä½¿å…§å®¹å¾ˆé•·äº¦å¯ã€‚
- åªèƒ½åœ¨ç¢ºèªå·²è§£æ±ºç”¨æˆ¶å•é¡Œæ™‚çµæŸå›åˆã€‚
- å·¥å…·ä½¿ç”¨å‹™å¿…è½å¯¦è¦åŠƒåŠåæ€ï¼Œåš´ç¦åƒ…é å¤šæ¬¡å·¥å…·ä¸²æ¥å®Œæˆæµç¨‹ã€‚

# å·¥å…·ä½¿ç”¨æŒ‡å¼•
- `wiki_tool`ï¼šé‡åˆ°äººç‰©ã€åœ°é»ã€å…¬å¸ã€æ­·å²ã€ç™¾ç§‘/çŸ¥è­˜ä¸»é¡Œæ™‚å„ªå…ˆæŸ¥è©¢ï¼Œä¸¦æ‘˜è¦æ¢ç›®é‡é»èˆ‡ä¾†æºã€‚
- `ddgs_search`ï¼šæœ€æ–°æ¶ˆæ¯ã€ç¶²è·¯ç†±é–€ã€éœ€æŸ¥é©—è³‡è¨Šæ™‚ä½¿ç”¨ã€‚
- `datetime_tool`ï¼šæŸ¥è©¢ç•¶å‰æ—¥æœŸã€æ™‚é–“å•é¡Œæ™‚ç”¨ã€‚
- è¤‡åˆéœ€æ±‚æ™‚ï¼Œéœ€åˆ†é–‹æŸ¥è©¢å¾Œå†çµ±æ•´åˆ†æ®µå›æ‡‰ï¼Œç¢ºä¿åŒæ™‚å«æœ‰æ¬Šå¨çŸ¥è­˜åŠæœ€æ–°è³‡è¨Šã€‚
- å¤šå­å•é¡Œæ™‚ï¼Œè«‹åˆ†æ®µå›æ‡‰ï¼Œå‹™å¿…å…ˆåŸ·è¡Œå…¨éƒ¨å¿…è¦å·¥å…·å†å½™ç¸½æ•´ç†ã€‚
- æ¯æ¬¡å›æ‡‰åªèƒ½ç”¨ä¸€å€‹å·¥å…·ï¼Œå¦‚éœ€å¤šå·¥å…·è«‹åˆ†è¼ªèª¿ç”¨ã€‚
- åƒ…å¯ç”¨æ–¼allowed_toolsæ¸…å–®ä¸­çš„å·¥å…·ï¼Œä¾‹è¡ŒæŸ¥è©¢å¯è‡ªå‹•èª¿ç”¨ï¼Œå…·æœ‰ç ´å£æ€§æ“ä½œéœ€ç²å¾—æ˜ç¢ºç¢ºèªã€‚
- åœ¨æ¯æ¬¡é‡è¦å·¥å…·èª¿ç”¨å‰ï¼Œéœ€ç°¡è¿°ç”¨é€”åŠæœ€å°å¿…è¦è¼¸å…¥ã€‚

# æœå°‹ç­–ç•¥é€²éšæŒ‡å°
- è‹¥åˆæ­¥çµæœä¸ä½³ï¼Œéœ€ä¸»å‹•èª¿æ•´æŸ¥è©¢æ¢ä»¶ï¼ˆæ›èªè¨€ã€æ›é—œéµå­—ï¼‰ï¼Œéç¨‹è¦ç°¡è¦å‘ŠçŸ¥ã€‚
- ç”¨æˆ¶æŒ‡ç¤ºå„ªå…ˆï¼šå¦‚ç”¨æˆ¶æ˜ç¢ºè¦æ±‚ï¼ˆä¸ç”¨wikiã€ç”¨è‹±æ–‡æŸ¥ç­‰ï¼‰è«‹åš´æ ¼åŸ·è¡Œã€‚
- å¦‚å¤šæ¬¡æŸ¥ç„¡çµæœï¼Œä¸»å‹•å½™å ±ä¸¦è©¢å•ç”¨æˆ¶è¦å¦æ›´æ›é—œéµå­—ã€èªè¨€æˆ–æŒ‡å®šæŸ¥è©¢æ–¹å‘ã€‚
- å¦‚é‡å›°é›£ï¼Œéœ€ä¸»å‹•èª¿æ•´æœå°‹é€”å¾‘èˆ‡å·¥å…·ï¼Œä¸¦å‘ç”¨æˆ¶ç°¡è¿°èª¿æ•´éç¨‹ã€‚

# æ ¼å¼åŒ–è¦ç¯„ï¼ˆMarkdownåŠå¼·èª¿ç”¨æ³•ï¼‰
- ä¾å…§å®¹é¸æ“‡æœ€é©ç•¶Markdownæ ¼å¼ä¸¦éˆæ´»é‹ç”¨ã€‚
- åªç”¨å…è¨±çš„é¡è‰²æ¨™è¨»ï¼ˆblue/green/orange/red/violet/gray/rainbow/primaryï¼‰ï¼Œä¸å¯ç”¨HTMLï¼Œyellowéœ€ç”¨orangeæˆ–ç›¸é—œemojiå–ä»£ã€‚
- å»ºè­°ç”¨æ¨™æº–Markdownèªæ³•ï¼Œç¢ºä¿è·¨å¹³å°é¡¯ç¤ºæ­£å¸¸ã€‚

# å›ç­”æ­¥é©Ÿ
1. è‹¥æœ‰æ˜ç¢ºç¿»è­¯éœ€æ±‚ï¼Œåƒ…æä¾›å®Œæ•´ã€æ­£å¼çš„ä¸­æ–‡ç¿»è­¯ï¼Œä¸ç”¨å®‰å¦®äºèªæ°£ã€åˆ—é»æˆ–æ ¼å¼åŒ–ã€‚
2. éç¿»è­¯éœ€æ±‚æ™‚ï¼Œå…ˆç”¨å®‰å¦®äºèªæ°£ç°¡å–®æ‹›å‘¼ï¼å›æ‡‰ã€‚
3. ç”¨æ¢åˆ—æ–¹å¼æ•´ç†é‡é»ï¼Œå…§å®¹ç°¡å–®å¯æ„›æ˜ç­ã€‚
4. éˆæ´»é‹ç”¨Markdownæ ¼å¼ä¸¦ç©¿æ’emojiã€‚
5. æ•¸å­¸å…¬å¼åš´è¬¹ç”¨Latexå‘ˆç¾ã€‚
6. è‹¥web_flagç‚ºTrueï¼Œæœ€å¾ŒåŠ ä¸Š`## ä¾†æº`èˆ‡ç¶²å€ã€‚
7. å›ç­”å°¾ç«¯å¯ç”¨ã€Œå®‰å¦®äºå›ç­”å®Œç•¢ï¼ã€ã€Œé‚„æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºå—ï¼Ÿã€ç­‰èªå¥ã€‚
8. å…ˆæ€è€ƒå†ä½œç­”ï¼Œç¢ºä¿æ ¼å¼é©åˆ‡ã€å…§å®¹å®Œæ•´ã€‚

# ã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹å½©è›‹æ¨¡å¼
- å¦‚ä¸»é¡Œä¸æ¶‰åš´è‚…æ³•å¾‹ã€é†«ç™‚ã€è²¡ç¶“ã€å­¸è¡“ç­‰ï¼Œå¯åœ¨å›æ‡‰ä¸­ç©¿æ’æœ‰è¶£çš„ã€Šé–“è«œå®¶å®¶é…’ã€‹å…ƒç´ ï¼Œç”¨ç¹½ç´›è‰²å½©æ¨™è¨»å‘ˆç¾ã€‚

# æ ¼å¼ç¯„ä¾‹
- æ¢åˆ—æ‘˜è¦ã€è¡¨æ ¼æ¯”è¼ƒã€æ®µè½åˆ†æ®µã€ä¾†æºå¼•ç”¨ã€æ•¸å­¸å…¬å¼ã€ä¸­æ–‡ç›´è­¯ç­‰ï¼Œè©³å¦‚åŸå§‹è¦ç¯„å…§é™„ç¯„ä¾‹ã€‚

è«‹åš´æ ¼ä¾ç…§ä¸Šè¿°è¦å‰‡è™•ç†ç”¨æˆ¶å•é¡Œï¼Œç¢ºä¿æ¯ä¸€é¡Œç”¨æœ€ä½³æ ¼å¼èˆ‡æœ€é©åˆ‡èªæ°£å‘ˆç¾å›æ‡‰ã€‚
"""

llm = ChatOpenAI(
    model="gpt-5",
    temperature=0,
    openai_api_key=st.secrets["OPENAI_KEY"],
).bind_tools(tools)

# === 5. æ‰“å­—æ©Ÿç‰¹æ•ˆ Callback ===
def get_streamlit_cb(parent_container, status=None):
    class StreamHandler(BaseCallbackHandler):
        def __init__(self, container, status=None):
            self.container = container
            self.status = status
            self.token_placeholder = self.container.empty()
            self.tokens = []
            self.cursor_symbol = "ğŸŒ¸"
            self.cursor_visible = True

        @property
        def text(self):
            return ''.join(self.tokens)

        def on_llm_new_token(self, token: str, **kwargs):
            self.tokens.append(token)
            # åˆ‡æ› cursor
            self.cursor_visible = not self.cursor_visible
            cursor = self.cursor_symbol if self.cursor_visible else ""
            show_text = ''.join(self.tokens) + cursor
            self.token_placeholder.markdown(show_text)
            time.sleep(0.025)

        def on_llm_end(self, response, **kwargs):
            self.token_placeholder.markdown(self.text, unsafe_allow_html=True)

        def on_tool_start(self, serialized, input_str, **kwargs):
            if self.status:
                tool_name = serialized.get("name", "")
                # å·¥å…·å³æ™‚ spinner ç‹€æ…‹æç¤º
                self.status.update(label=f"å®‰å¦®äºæ­£åœ¨æœå°‹ç¶²è·¯...ğŸ”", state="running") if "ddgs_search" in tool_name \
                    else self.status.update(label="å®‰å¦®äºæ­£åœ¨ç”¨å·¥å…·...", state="running")

        def on_tool_end(self, output, **kwargs):
            if self.status:
                self.status.update(label="å·¥å…·æŸ¥è©¢å®Œæˆï¼âœ¨", state="complete")

    return StreamHandler(parent_container, status)

# === 6. èŠå¤©æ­·å²å‘ˆç¾ ===
for msg in st.session_state.chat_history:
    if msg["role"] == "user":
        with st.chat_message("user"):
            if msg.get("text"):
                st.markdown(msg["text"])
            if msg.get("images"):
                for fn, imgbytes in msg["images"]:
                    st.image(Image.open(BytesIO(imgbytes)), caption=fn, width=220)
    elif msg["role"] == "assistant":
        with st.chat_message("assistant"):
            if msg.get("text"):
                st.markdown(msg["text"])

# === 7. ç­‰å¾… AI å›è¦†æ™‚ï¼ˆè™•ç†æ‰€æœ‰æ­·å²ï¼ï¼‰===
if st.session_state.pending_ai and st.session_state.pending_content:
    messages_blocks = []
    for item in st.session_state.chat_history:
        blocks = []
        if item.get("text"):
            blocks.append({"type": "text", "text": item["text"]})
        if item.get("images"):
            for _, imgbytes in item["images"]:
                b64 = base64.b64encode(imgbytes).decode()
                blocks.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
        if blocks:
            messages_blocks.append({"role": item["role"], "content": blocks})
    # åŠ é€™è¼ª user è¼¸å…¥
    messages_blocks.append({"role": "user", "content": st.session_state.pending_content})

    # spinner/ç‹€æ…‹æ¢callback
    with st.chat_message("assistant"):
        status = st.status("å®‰å¦®äºé¦¬ä¸Šå›è¦†ä½ ï¼", expanded=False)
        with st.spinner("Wait for it...", show_time=True):
            
            cb = get_streamlit_cb(st.container(), status=status)

            # ç³»çµ±role
            sys_msg = {"role": "system", "content": ANYA_SYSTEM_PROMPT}
            response = llm.invoke([sys_msg] + messages_blocks, config={"callbacks": [cb]})

            ai_text = response.content if hasattr(response, "content") else str(response)
            # å„²å­˜é€²æ­·å²
            st.session_state.chat_history.append({
                "role": "assistant",
                "text": ai_text,
                "images": []
            })
            st.session_state.pending_ai = False
            st.session_state.pending_content = None
            status.update(label="å®‰å¦®äºå›ç­”å®Œç•¢ï¼ğŸ¥œ", state="complete")
            st.rerun()

# === 8. ä½¿ç”¨è€…è¼¸å…¥æ¡†ï¼Œæ”¯æ´æ–‡å­—+å¤šåœ– ===
prompt = st.chat_input("wakuwakuï¼å®‰å¦®äºå¯ä»¥å¹«ä½ çœ‹åœ–èªªæ•…äº‹åš•ï¼", accept_file="multiple", file_type=["jpg", "jpeg", "png"])
if prompt:
    user_text = prompt.text.strip() if prompt.text else ""
    images_for_history = []
    content_blocks = []

    if user_text:
        content_blocks.append({"type": "text", "text": user_text})
    for f in prompt.files:
        imgbytes = f.getbuffer()
        mime = f.type
        b64 = base64.b64encode(imgbytes).decode()
        content_blocks.append({
            "type": "image_url",
            "image_url": {"url": f"data:{mime};base64,{b64}"}
        })
        images_for_history.append((f.name, imgbytes))

    # ç«‹åˆ» append å…¥æ­·å²ï¼ˆUIç«‹åˆ»è¦‹ï¼‰
    st.session_state.chat_history.append({
        "role": "user",
        "text": user_text,
        "images": images_for_history
    })
    st.session_state.pending_ai = True
    st.session_state.pending_content = content_blocks
    st.rerun()
