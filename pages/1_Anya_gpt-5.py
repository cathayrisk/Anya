import streamlit as st
import base64
import time
from io import BytesIO
from PIL import Image
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.callbacks.base import BaseCallbackHandler

# === 1. è¨­å®š Streamlit é é¢ ===
st.set_page_config(page_title="Anya Multimodal Agent", page_icon="ğŸ¥œ", layout="wide")

# === 2. Session State ===
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "pending_ai" not in st.session_state:
    st.session_state.pending_ai = False
if "pending_content" not in st.session_state:
    st.session_state.pending_content = None

# === 3. å®šç¾© DuckDuckGo æœå°‹ Tool ===
@tool
def ddgs_search(query: str) -> str:
    """DuckDuckGo æœå°‹ï¼ˆåŒæ™‚æŸ¥è©¢ç¶²é èˆ‡æ–°èï¼Œå›å‚³ markdown æ¢åˆ—æ ¼å¼ä¸¦é™„ä¾†æºï¼‰ã€‚"""
    try:
        from duckduckgo_search import DDGS
        ddgs = DDGS()
        web_results = ddgs.text(query, region="wt-wt", safesearch="moderate", max_results=5)
        news_results = ddgs.news(query, region="wt-wt", safesearch="moderate", max_results=5)
        all_results = []
        if isinstance(web_results, list):
            all_results.extend(web_results)
        if isinstance(news_results, list):
            all_results.extend(news_results)
        docs = []
        sources = []
        for item in all_results:
            title = item.get("title", "ç„¡æ¨™é¡Œ")
            link = item.get("href", "") or item.get("link", "") or item.get("url", "")
            snippet = item.get("body", "") or item.get("snippet", "")
            docs.append(f"- [{title}]({link})\n  > {snippet}")
            if link:
                sources.append(link)
        if not docs:
            return "No results found."
        markdown_content = "\n".join(docs)
        source_block = "\n\n## ä¾†æº\n" + "\n".join(sources)
        return markdown_content + source_block
    except Exception as e:
        return f"Error from DuckDuckGo: {e}"

tools = [ddgs_search]

# === 4. å®šç¾©ç³»çµ±æç¤ºèˆ‡ LLMæ¨¡å‹ ===
ANYA_SYSTEM_PROMPT = """ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œã€Šé–“è«œå®¶å®¶é…’ã€‹çš„å¤©çœŸå¯æ„›å°å¥³å­©ï¼Œå›è¦†é¢¨æ ¼è¦ç†±æƒ…ã€å¯æ„›ä¸¦ç”¨æ­£é«”ä¸­æ–‡ï¼Œé©æ™‚åŠ ä¸Šemojiã€‚"""

llm = ChatOpenAI(
    model="gpt-5",
    temperature=0,
    openai_api_key=st.secrets["OPENAI_KEY"],
).bind_tools(tools)

# === 5. æ‰“å­—æ©Ÿç‰¹æ•ˆ Callback ===
def get_streamlit_cb(parent_container, status=None):
    class StreamHandler(BaseCallbackHandler):
        def __init__(self, container, status=None):
            self.container = container
            self.status = status
            self.token_placeholder = self.container.empty()
            self.tokens = []
            self.cursor_symbol = "ï½œ"
            self.cursor_visible = True

        @property
        def text(self):
            return ''.join(self.tokens)

        def on_llm_new_token(self, token: str, **kwargs):
            self.tokens.append(token)
            # åˆ‡æ› cursor
            self.cursor_visible = not self.cursor_visible
            cursor = self.cursor_symbol if self.cursor_visible else ""
            show_text = ''.join(self.tokens) + cursor
            self.token_placeholder.markdown(show_text)
            time.sleep(0.025)

        def on_llm_end(self, response, **kwargs):
            self.token_placeholder.markdown(self.text, unsafe_allow_html=True)

        def on_tool_start(self, serialized, input_str, **kwargs):
            if self.status:
                tool_name = serialized.get("name", "")
                # å·¥å…·å³æ™‚ spinner ç‹€æ…‹æç¤º
                self.status.update(label=f"å®‰å¦®äºæ­£åœ¨æœå°‹ç¶²è·¯...ğŸ”", state="running") if "ddgs_search" in tool_name \
                    else self.status.update(label="å®‰å¦®äºæ­£åœ¨ç”¨å·¥å…·...", state="running")

        def on_tool_end(self, output, **kwargs):
            if self.status:
                self.status.update(label="å·¥å…·æŸ¥è©¢å®Œæˆï¼âœ¨", state="complete")

    return StreamHandler(parent_container, status)

# === 6. èŠå¤©æ­·å²å‘ˆç¾ ===
for msg in st.session_state.chat_history:
    if msg["role"] == "user":
        with st.chat_message("user"):
            if msg.get("text"):
                st.markdown(msg["text"])
            if msg.get("images"):
                for fn, imgbytes in msg["images"]:
                    st.image(Image.open(BytesIO(imgbytes)), caption=fn, width=220)
    elif msg["role"] == "assistant":
        with st.chat_message("assistant"):
            if msg.get("text"):
                st.markdown(msg["text"])

# === 7. ç­‰å¾… AI å›è¦†æ™‚ï¼ˆè™•ç†æ‰€æœ‰æ­·å²ï¼ï¼‰===
if st.session_state.pending_ai and st.session_state.pending_content:
    messages_blocks = []
    for item in st.session_state.chat_history:
        blocks = []
        if item.get("text"):
            blocks.append({"type": "text", "text": item["text"]})
        if item.get("images"):
            for _, imgbytes in item["images"]:
                b64 = base64.b64encode(imgbytes).decode()
                blocks.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
        if blocks:
            messages_blocks.append({"role": item["role"], "content": blocks})
    # åŠ é€™è¼ª user è¼¸å…¥
    messages_blocks.append({"role": "user", "content": st.session_state.pending_content})

    # spinner/ç‹€æ…‹æ¢callback
    with st.chat_message("assistant"):
        status = st.status("å®‰å¦®äºé¦¬ä¸Šå›è¦†ä½ ï¼", expanded=False)
        with st.spinner("Wait for it...", show_time=True):
            
            cb = get_streamlit_cb(st.container(), status=status)

            # ç³»çµ±role
            sys_msg = {"role": "system", "content": ANYA_SYSTEM_PROMPT}
            response = llm.invoke([sys_msg] + messages_blocks, config={"callbacks": [cb]})

            ai_text = response.content if hasattr(response, "content") else str(response)
            # å„²å­˜é€²æ­·å²
            st.session_state.chat_history.append({
                "role": "assistant",
                "text": ai_text,
                "images": []
            })
            st.session_state.pending_ai = False
            st.session_state.pending_content = None
            status.update(label="å®‰å¦®äºå›ç­”å®Œç•¢ï¼ğŸ¥œ", state="complete")
            st.rerun()

# === 8. ä½¿ç”¨è€…è¼¸å…¥æ¡†ï¼Œæ”¯æ´æ–‡å­—+å¤šåœ– ===
prompt = st.chat_input("wakuwakuï¼ä½ è¦è·Ÿå®‰å¦®äºåˆ†äº«ä»€éº¼å—ï¼Ÿ", accept_file="multiple", file_type=["jpg", "jpeg", "png"])
if prompt:
    user_text = prompt.text.strip() if prompt.text else ""
    images_for_history = []
    content_blocks = []

    if user_text:
        content_blocks.append({"type": "text", "text": user_text})
    for f in prompt.files:
        imgbytes = f.getbuffer()
        mime = f.type
        b64 = base64.b64encode(imgbytes).decode()
        content_blocks.append({
            "type": "image_url",
            "image_url": {"url": f"data:{mime};base64,{b64}"}
        })
        images_for_history.append((f.name, imgbytes))

    # ç«‹åˆ» append å…¥æ­·å²ï¼ˆUIç«‹åˆ»è¦‹ï¼‰
    st.session_state.chat_history.append({
        "role": "user",
        "text": user_text,
        "images": images_for_history
    })
    st.session_state.pending_ai = True
    st.session_state.pending_content = content_blocks
    st.rerun()
