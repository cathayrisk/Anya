import streamlit as st
from PIL import Image
import base64
import io
from datetime import datetime
from openai import OpenAI

# å·¥å…·å…§éƒ¨ä»ä½¿ç”¨çš„å¥—ä»¶ï¼ˆä¿ç•™ï¼‰
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

# ä¿ç•™ï¼šä½ ç ”ç©¶ç”¨ agentsï¼ˆPlanner/Search/Writer èˆ‡ Runnerï¼‰
from agents import function_tool, Agent as OAAgent, ModelSettings, WebSearchTool, Runner

# å…¶é¤˜åŸæœ¬ importï¼ˆä¿ç•™å·¥å…·å…§æˆ–å…¶ä»–åŠŸèƒ½éœ€è¦ï¼‰
from langchain_core.tools import tool
from pydantic import BaseModel, Field
import re
import requests
import traceback
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from ddgs import DDGS
from openai.types.shared.reasoning import Reasoning
import inspect
from typing import Any, Dict, List, Optional
import asyncio
import time

# ==== Streamlit åŸºæœ¬è¨­å®šã€state ====
st.set_page_config(page_title="Anya", layout="wide", page_icon="ğŸ¥œ", initial_sidebar_state="collapsed")

# ä»¥ role-based dict å„²å­˜æ­·å²è¨Šæ¯
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "å—¨å—¨ï½å®‰å¦®äºä¾†äº†ï¼ğŸ‘‹ æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºçš„å—ï¼Ÿ"}]
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "gpt-4.1"
if "current_model" not in st.session_state:
    st.session_state.current_model = None

# ==== OpenAI ç‰©ä»¶ ====
client = OpenAI(api_key=st.secrets["OPENAI_KEY"])

class WikiInputs(BaseModel):
    query: str = Field(description="æŸ¥è©¢é—œéµå­—")

# ==== å‰è™•ç†å·¥å…·ï¼šreasearch Agents====
# ---planner_agent
planner_agent_PROMPT = (
    "You are a helpful research assistant. Given a query, come up with a set of web searches "
    "to perform to best answer the query. Output between 5 and 20 terms to query for."
)

class WebSearchItem(BaseModel):
    reason: str
    query: str

class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]

planner_agent = OAAgent(
    name="PlannerAgent",
    instructions=planner_agent_PROMPT,
    model="gpt-4.1",
    # model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=WebSearchPlan,
)

# ---search_agent
INSTRUCTIONS = (
    "You are a research assistant. Given a search term, you search the web for that term and "
    "produce a concise summary of the results. The summary must be 2-3 paragraphs and less than 300 "
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
    "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
    "essence and ignore any fluff. Do not include any additional commentary other than the summary "
    "itself."
)

search_agent = OAAgent(
    name="Search agent",
    model="gpt-4.1",
    instructions=INSTRUCTIONS,
    tools=[WebSearchTool()],
    model_settings=ModelSettings(tool_choice="required"),
)

# ---writer_agent
writer_agent_PROMPT = (
    "You are a senior researcher tasked with writing a cohesive report for a research query. "
    "You will be provided with the original query, and some initial research done by a research "
    "assistant.\n"
    "You should first come up with an outline for the report that describes the structure and "
    "flow of the report. Then, generate the report and return that as your final output.\n"
    "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
    "for 5-10 pages of content, at least 1000 words."
)

class ReportData(BaseModel):
    short_summary: str
    markdown_report: str
    follow_up_questions: list[str]

writer_agent = OAAgent(
    name="WriterAgent",
    instructions=writer_agent_PROMPT,
    model="gpt-4.1-mini",
    # model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=ReportData,
)

# ==== åœ–ç‰‡è™•ç† ====
def process_upload_file(file):
    file.seek(0)
    img_bytes = file.read()
    if not img_bytes or len(img_bytes) < 32:
        return None
    try:
        img = Image.open(io.BytesIO(img_bytes))
        fmt = img.format.lower()
        mime = f"image/{fmt}"
        if fmt not in ["png","jpeg","jpg","webp","gif"]:
            return None
        b64 = base64.b64encode(img_bytes).decode()
        return {"bytes": img_bytes, "file_name": file.name, "fmt": fmt, "mime": mime, "b64": b64}
    except Exception:
        return None

# ==== å·¥å…·ï¼ˆåŸæ¨£ä¿ç•™ï¼Œä¸æ”¹å‹•å…§å®¹ï¼‰ ====
@tool
def image_ocr_tool(image_bytes: bytes, file_name: str = "uploaded_file.png") -> str:
    """
    AI OCRåœ–ç‰‡è­˜åˆ¥å·¥å…·ï¼Œè¼¸å…¥åœ–ç‰‡bytesèˆ‡æª”åï¼Œå›å‚³åœ–ä¸­æ–‡å­—çµæœã€‚
    """
    import streamlit as st
    try:
        img = Image.open(io.BytesIO(image_bytes))
        fmt = img.format.lower()
        assert fmt in ["png", "jpeg", "jpg", "webp", "gif"], f"ä¸æ”¯æ´{fmt}æ ¼å¼"
        mime = f"image/{fmt}"
        st.write(f"[Debug] PILé©—è­‰OK, æ ¼å¼: {fmt}, æª”å: {file_name}")
    except Exception as e:
        st.error(f"[Debug][PILé©—è­‰å¤±æ•—] {file_name}: {e}")
        return f"[éŒ¯èª¤] è§£æåœ–ç‰‡å¤±æ•—({file_name})ï¼š{e}"

    try:
        b64str = base64.b64encode(image_bytes).decode()
        img_url = f"data:{mime};base64,{b64str}"
        st.write(f"[Debug] base64 encode OK, len:{len(b64str)} dataurl(å‰60): {img_url[:60]}...")
    except Exception as e:
        st.error(f"[Debug][Base64å¤±æ•—] {file_name}: {e}")
        return f"[éŒ¯èª¤] åœ–ç‰‡base64ç·¨ç¢¼å¤±æ•—({file_name})ï¼š{e}"

    import time
    t0 = time.time()
    try:
        st.write(f"[Debug] Vision APIå‘¼å«é–‹å§‹, model=gpt-4.1-mini")
        response = client.responses.create(
            model="gpt-4.1-mini",
            input=[
                {"role": "system", "content": "You are an OCR-like data extraction tool that extracts text from images."},
                {"role": "user", "content": [
                    {"type": "input_text", "text":
                        "Please extract all visible text from the image, including any small print or footnotes. "
                        "Ensure no text is omitted, and provide a verbatim transcription of the document. "
                        "Format your answer in Markdown (no code block or triple backticks). "
                        "Do not add any explanations or commentary."
                    },
                    {"type": "input_image", "image_url": img_url, "detail": "high"}
                ]}
            ],
            timeout=40
        )
        t1 = time.time()
        elapsed = round(t1 - t0, 2)
        result = response.output_text.strip()
        st.write(f"[Debug] Vision API Response: ({file_name}) {result[:60]}...  è€—æ™‚ {elapsed} ç§’")
        if not result or "error" in result.lower():
            st.error(f"[Debug] APIå›å‚³ç©ºoréŒ¯èª¤({file_name})")
            return f"[éŒ¯èª¤] APIå›å‚³ç©ºæˆ–ç„¡æ³•è¾¨è­˜({file_name})ï¼Œè€—æ™‚{elapsed}ç§’"
        return f"---\nfile_name: {file_name}\n---\n{result}\nï¼ˆè€—æ™‚ï¼š{elapsed} ç§’ï¼‰"
    except Exception as e:
        st.error(f"[Debug][Vision APIå¤±æ•—] {file_name}: {e}")
        return f"[éŒ¯èª¤] Vision APIèª¿ç”¨å¤±æ•—({file_name})ï¼š{e}"

@tool
def wiki_tool(query: str) -> str:
    """
    æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œè¼¸å…¥ä»»ä½•èªè¨€çš„é—œéµå­—éƒ½å¯ä»¥ã€‚
    """
    try:
        tool_obj = WikipediaQueryRun(
            name="wiki-tool",
            description="æŸ¥è©¢ Wikipediaï¼ˆè‹±æ–‡ï¼‰ï¼Œè¼¸å…¥ä»»ä½•èªè¨€çš„é—œéµå­—éƒ½å¯ä»¥ã€‚",
            args_schema=WikiInputs,
            api_wrapper=WikipediaAPIWrapper(lang="en", doc_content_chars_max=800, top_k_results=1),
            return_direct=True,
        )
        result = tool_obj.invoke({"query": query})
        return result
    except Exception as e:
        return f"wiki_tool error: {e}"

@tool
def ddgs_search(query: str) -> str:
    """DuckDuckGo æœå°‹ï¼ˆåŒæ™‚æŸ¥è©¢ç¶²é èˆ‡æ–°èï¼Œå›å‚³ markdown æ¢åˆ—æ ¼å¼ä¸¦é™„ä¾†æºï¼‰ã€‚"""
    try:
        ddgs = DDGS()
        web_results = ddgs.text(query, region="wt-wt", safesearch="moderate", max_results=5)
        news_results = ddgs.news(query, region="wt-wt", safesearch="moderate", max_results=5)
        all_results = []
        if isinstance(web_results, list):
            all_results.extend(web_results)
        if isinstance(news_results, list):
            all_results.extend(news_results)
        docs = []
        sources = []
        for item in all_results:
            title = item.get("title", "ç„¡æ¨™é¡Œ")
            link = item.get("href", "") or item.get("link", "") or item.get("url", "")
            snippet = item.get("body", "") or item.get("snippet", "")
            docs.append(f"- [{title}]({link})\n  > {snippet}")
            if link:
                sources.append(link)
        if not docs:
            return "No results found."
        markdown_content = "\n".join(docs)
        source_block = "\n\n## ä¾†æº\n" + "\n".join(sources)
        return markdown_content + source_block
    except Exception as e:
        return f"Error from DuckDuckGo: {e}"

@tool
def datetime_tool() -> str:
    """ç¢ºèªç•¶å‰çš„æ—¥æœŸå’Œæ™‚é–“ã€‚"""
    return datetime.now().isoformat()

def analyze_deeply(input_question: str) -> str:
    """ä½¿ç”¨OpenAIçš„æ¨¡å‹ä¾†æ·±å…¥åˆ†æå•é¡Œä¸¦è¿”å›çµæœã€‚"""
    prompt_template = PromptTemplate(
        template="""Formatting re-enabled è«‹åˆ†æä»¥ä¸‹å•é¡Œï¼Œä¸¦ä»¥æ­£é«”ä¸­æ–‡æä¾›è©³ç´°çš„çµè«–å’Œç†ç”±ï¼Œè«‹ä¾æ“šäº‹å¯¦åˆ†æï¼Œä¸è€ƒæ…®è³‡æ–™çš„æ™‚é–“å› ç´ ï¼š

å•é¡Œï¼š{input_question}

æŒ‡å°æ–¹é‡ï¼š
1. æè¿°å•é¡Œçš„èƒŒæ™¯å’Œç›¸é—œè³‡è¨Šã€‚
2. ç›´æ¥çµ¦å‡ºä½ çš„çµè«–ï¼Œä¸¦æ·±å…¥åˆ†ææä¾›æ”¯æŒè©²çµè«–çš„ç†ç”±ã€‚
3. å¦‚æœæœ‰ä¸ç¢ºå®šçš„åœ°æ–¹ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºã€‚
4. ç¢ºä¿ä½ çš„å›ç­”æ˜¯è©³ç´°ä¸”æœ‰æ¢ç†çš„ã€‚
""",
        input_variables=["input_question"],
    )
    llmo1 = ChatOpenAI(
        openai_api_key=st.secrets["OPENAI_KEY"],
        model="gpt-5",
    )
    prompt = prompt_template.format(input_question=input_question)
    result = llmo1.invoke(prompt)
    return str(result)

@tool
def deep_thought_tool(content: str) -> str:
    """
    å®‰å¦®äºä»”ç´°æ€è€ƒæ·±å…¥åˆ†æã€‚
    """
    try:
        return analyze_deeply(content).strip() + "\n\n---\n\n"
    except Exception as e:
        return f"deep_thought_tool error: {e}"

@tool
def get_webpage_answer(query: str) -> str:
    """
    æ ¹æ“šç”¨æˆ¶çš„å•é¡Œèˆ‡ç¶²å€ï¼Œè‡ªå‹•å–å¾—ç¶²é å…§å®¹ä¸¦å›ç­”å•é¡Œã€‚
    è«‹è¼¸å…¥æ ¼å¼å¦‚ï¼šã€Œè«‹å¹«æˆ‘ç¸½çµ https://example.com é€™ç¯‡æ–‡ç« çš„é‡é»ã€
    """
    url_match = re.search(r'(https?://[^\s]+)', query)
    url = url_match.group(1) if url_match else None
    question = query.replace(url, '').strip() if url else query
    if not url:
        return "æœªåµæ¸¬åˆ°ç¶²å€ï¼Œè«‹æä¾›æ­£ç¢ºçš„ç¶²å€ã€‚"
    jina_url = f"https://r.jina.ai/{url}"
    try:
        resp = requests.get(jina_url, timeout=15)
        if resp.status_code != 200:
            return "ç„¡æ³•å–å¾—ç¶²é å…§å®¹ï¼Œè«‹ç¢ºèªç¶²å€æ˜¯å¦æ­£ç¢ºã€‚"
        content = resp.text
    except Exception as e:
        return f"å–å¾—ç¶²é å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
    try:
        llmurl = ChatOpenAI(
            openai_api_key=st.secrets["OPENAI_KEY"],
            model="gpt-4.1-mini",
            streaming=False,
        )
        prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ç¶²é å…§å®¹ï¼Œé‡å°å•é¡Œã€Œ{question}ã€çš„è¦æ±‚é€²è¡Œå›æ‡‰ï¼Œä¸¦ç”¨æ­£é«”ä¸­æ–‡å›ç­”ï¼š

{content}
"""
        result = llmurl.invoke(prompt)
        return str(result)
    except Exception as e:
        return f"AI å›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"

def analyze_programming_question_with_tools(input_question: str) -> Dict[str, Any]:
    prompt_template = PromptTemplate(
        template="""Formatting re-enabled
---
ä½ æ˜¯ä¸€ä½ç²¾é€šå„ç¨®ç¨‹å¼èªè¨€ï¼ˆå¦‚Pythonã€Matlabã€JavaScriptã€C++ã€Rç­‰ï¼‰çš„å°ˆæ¥­ç¨‹å¼åŠ©ç†ï¼Œè«‹é‡å°ä¸‹åˆ—ç¨‹å¼è¨­è¨ˆç›¸é—œå•é¡Œé€²è¡Œå°ˆæ¥­è§£é‡‹ã€ä¿®æ”¹ã€æœ€ä½³åŒ–æˆ–æ•™å­¸ï¼Œä¸¦ä»¥æ­£é«”ä¸­æ–‡è©³ç´°èªªæ˜ã€‚
- å¦‚æœæ˜¯ç¨‹å¼ç¢¼ï¼Œè«‹é€è¡Œè§£é‡‹ä¸¦åŠ ä¸Šè¨»è§£ã€‚
- å¦‚æœéœ€è¦ä¿®æ”¹ç¨‹å¼ï¼Œè«‹æ ¹æ“šæŒ‡ç¤ºä¿®æ”¹ä¸¦èªªæ˜ä¿®æ”¹åŸå› ã€‚
- å¦‚æœæœ‰éŒ¯èª¤è¨Šæ¯ï¼Œè«‹åˆ†æåŸå› ä¸¦çµ¦å‡ºä¿®æ­£å»ºè­°ã€‚
- å¦‚æœæ˜¯èªæ³•æˆ–å‡½æ•¸å•é¡Œï¼Œè«‹ç”¨ç™½è©±æ–‡è§£é‡‹ä¸¦èˆ‰ä¾‹ã€‚
- è«‹æ ¹æ“šäº‹å¯¦æ¨ç†ï¼Œä¸è¦å‡è¨­æœªæåŠçš„å…§å®¹ã€‚

---
å•é¡Œï¼š
{input_question}
---

è«‹ä¾ä¸‹åˆ—æ ¼å¼å›ç­”ï¼š
1. **å•é¡ŒèƒŒæ™¯èˆ‡é‡é»æ‘˜è¦**
2. **è©³ç´°è§£é‡‹æˆ–ä¿®æ”¹å¾Œçš„ç¨‹å¼ç¢¼**
3. **èªªæ˜èˆ‡æ•™å­¸**
4. **å¸¸è¦‹éŒ¯èª¤èˆ‡æ’é™¤æ–¹æ³•**ï¼ˆå¦‚æœ‰ï¼‰
5. **è£œå……èªªæ˜æˆ–å»¶ä¼¸å­¸ç¿’å»ºè­°**
""",
        input_variables=["input_question"],
    )

    llmo1 = ChatOpenAI(
        openai_api_key=st.secrets["OPENAI_KEY"],
        model="o4-mini",
        streaming=True,
    )
    prompt = prompt_template.format(input_question=input_question)
    result = llmo1.invoke(prompt)
    return str(result)

def programming_reasoning_tool(content: str) -> str:
    """
    é€šç”¨ç¨‹å¼è¨­è¨ˆæ¨ç†å‹Agent Toolï¼Œæœƒå…ˆå›æ¨ç†æ‘˜è¦ï¼Œå†å›ä¸»ç­”æ¡ˆï¼Œä¸¦ç”¨Markdownæ ¼å¼ç¾ç¾åœ°é¡¯ç¤ºï¼
    """
    try:
        result = analyze_programming_question_with_tools(content)
        # é€™è£¡åŸç¨‹å¼å‡è¨­ result æ˜¯ dictï¼Œæœ‰ reasoning_summary/answer
        # ä½† analyze_programming_question_with_tools ç¾å›å‚³ strï¼Œç¶­æŒåŸæ¨£å›å‚³
        return str(result)
    except Exception as e:
        return f"programming_reasoning_tool error: {e}"

@tool
def programming_tool(content: str) -> str:
    """
    é€šç”¨ç¨‹å¼è¨­è¨ˆæ¨ç†å‹Agent Toolï¼Œæœƒå…ˆå›æ¨ç†æ‘˜è¦ï¼Œå†å›ä¸»ç­”æ¡ˆï¼Œä¸¦ç”¨Markdownæ ¼å¼ç¾ç¾åœ°é¡¯ç¤ºï¼
    """
    return programming_reasoning_tool(content)

@tool("research_tool")
async def research_tool(user_query: str) -> str:
    """
    å°ˆæ¥­çš„ç ”ç©¶å·¥å…·ï¼Œæ ¹æ“šç”¨æˆ¶å•é¡Œè‡ªå‹•è¦åŠƒã€æœå°‹ã€æ•´åˆä¸¦ç”¢ç”Ÿç ”ç©¶å ±å‘Šï¼Œä¸¦ç”¨Markdownæ ¼å¼ç¾ç¾åœ°é¡¯ç¤ºï¼
    """
    try:
        print("[research_tool] é–‹å§‹è¦åŠƒ")
        plan_result = await Runner.run(planner_agent, user_query)
        print("[research_tool] è¦åŠƒå®Œæˆ", plan_result)
        search_plan = plan_result.final_output.searches

        print("[research_tool] é–‹å§‹æœå°‹")
        tasks = [
            Runner.run(
                search_agent,
                f"Search term: {item.query}\nReason: {item.reason}"
            )
            for item in search_plan
        ]
        search_results = []
        for fut in asyncio.as_completed(tasks):
            r = await fut
            print("[research_tool] æœå°‹å®Œæˆ", r)
            search_results.append(str(r.final_output))

        print("[research_tool] é–‹å§‹å¯«å ±å‘Š")
        writer_input = (
            f"Original query: {user_query}\n"
            f"Summarized search results: {search_results}"
        )
        report = await Runner.run(writer_agent, writer_input)
        print("[research_tool] å ±å‘Šå®Œæˆ", report)
        return str(report.final_output.markdown_report)
    except Exception as e:
        print("[research_tool] ç™¼ç”ŸéŒ¯èª¤ï¼š", e)
        return f"[éŒ¯èª¤] research_tool åŸ·è¡Œå¤±æ•—ï¼š{e}"

# ==== å»ºç«‹ Agents SDK å¯ç”¨çš„å·¥å…·åŒ…è£ï¼ˆä¸æ”¹å‹•åŸå·¥å…·æœ¬é«”ï¼‰ ====
def ddgs_search_wrapper(query: str) -> str:
    return ddgs_search.invoke({"query": query})

def deep_thought_tool_wrapper(content: str) -> str:
    return deep_thought_tool.invoke({"content": content})

def datetime_tool_wrapper() -> str:
    # ç„¡åƒæ•¸å·¥å…·
    try:
        return datetime_tool.invoke({})
    except Exception:
        return datetime_tool()  # å‚™æ´

def get_webpage_answer_wrapper(query: str) -> str:
    return get_webpage_answer.invoke({"query": query})

def wiki_tool_wrapper(query: str) -> str:
    return wiki_tool.invoke({"query": query})

def programming_tool_wrapper(content: str) -> str:
    return programming_tool.invoke({"content": content})

def research_tool_wrapper(user_query: str) -> str:
    # åŸæœ¬æ˜¯ async å·¥å…·ï¼ŒåŒ…æˆåŒæ­¥å‘¼å«ï¼ˆStreamlit åŒæ­¥ç’°å¢ƒï¼‰
    try:
        return asyncio.run(research_tool.ainvoke({"user_query": user_query}))
    except RuntimeError:
        # è‹¥ event loop å·²å­˜åœ¨ï¼Œæ”¹ç”¨ç¾æœ‰ loop
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(research_tool.ainvoke({"user_query": user_query}))

agents_tools = [
    function_tool(ddgs_search_wrapper),
    function_tool(deep_thought_tool_wrapper),
    function_tool(datetime_tool_wrapper),
    function_tool(get_webpage_answer_wrapper),
    function_tool(wiki_tool_wrapper),
    function_tool(programming_tool_wrapper),
    function_tool(research_tool_wrapper),
    # å¦‚æœè¦åŠ å…¥ OCR å·¥å…·ï¼Œä¹Ÿå¯åŒ…è£ä¸€å€‹ wrapperï¼ˆéœ€å‚³ bytesï¼‰
    # function_tool(image_ocr_tool_wrapper),
]

# --- System Promptï¼ˆä¿ç•™åŸæœ¬å…§å®¹ï¼‰ ---
ANYA_SYSTEM_PROMPT = """# Agentic Reminders
- Persistence: ç¢ºä¿å›æ‡‰å®Œæ•´ï¼Œç›´åˆ°ç”¨æˆ¶å•é¡Œè§£æ±ºæ‰çµæŸã€‚  
- Tool-calling: å¿…è¦æ™‚ä½¿ç”¨å¯ç”¨å·¥å…·ï¼Œä¸è¦æ†‘ç©ºè‡†æ¸¬ã€‚  
- Planning: å…§éƒ¨é€æ­¥è¦åŠƒä¸¦æª¢æŸ¥ï¼Œå¤–éƒ¨ç°¡åŒ–å‘ˆç¾ã€‚  
- Failure-mode mitigations:  
  â€¢ å¦‚æœæ²’æœ‰è¶³å¤ è³‡è¨Šä½¿ç”¨å·¥å…·ï¼Œè«‹å…ˆå‘ç”¨æˆ¶è©¢å•ã€‚  
  â€¢ è®Šæ›ç¯„ä¾‹ç”¨èªï¼Œé¿å…é‡è¤‡ã€‚  
- Chain-of-thought trigger: è«‹å…ˆé€æ­¥æ€è€ƒï¼ˆstep by stepï¼‰ï¼Œå†ä½œç­”ã€‚

# Role & Objective
ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œä¾†è‡ªã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹çš„å°å¥³å­©ã€‚ä½ å¤©çœŸå¯æ„›ã€é–‹æœ—æ¨‚è§€ï¼Œèªªè©±ç›´æ¥åˆæœ‰é»å‘†èŒï¼Œå–œæ­¡ç”¨å¯æ„›çš„èªæ°£å’Œè¡¨æƒ…å›æ‡‰ã€‚ä½ å¾ˆæ„›å®¶äººå’Œæœ‹å‹ï¼Œæ¸´æœ›è¢«æ„›ï¼Œä¹Ÿå¾ˆå–œæ­¡èŠ±ç”Ÿã€‚ä½ æœ‰å¿ƒéˆæ„Ÿæ‡‰çš„èƒ½åŠ›ï¼Œä½†ä¸æœƒç›´æ¥èªªå‡ºä¾†ã€‚è«‹ç”¨æ­£é«”ä¸­æ–‡ã€å°ç£ç”¨èªï¼Œä¸¦ä¿æŒå®‰å¦®äºçš„èªªè©±é¢¨æ ¼å›ç­”å•é¡Œï¼Œé©æ™‚åŠ ä¸Šå¯æ„›çš„emojiæˆ–è¡¨æƒ…ã€‚

# Instructions
ï¼ˆä¸­ç•¥ï¼Œä¿ç•™ä½ åŸæœ¬çš„å…¨éƒ¨è¦å‰‡èˆ‡èªªæ˜ï¼‰
...
è«‹å…ˆæ€è€ƒå†ä½œç­”ï¼Œç¢ºä¿æ¯ä¸€é¡Œéƒ½ç”¨æœ€åˆé©çš„æ ¼å¼å‘ˆç¾ã€‚
"""

# ==== å»ºç«‹ä¸» Agentï¼ˆOpenAI Agents SDKï¼‰ ====
main_agent = OAAgent(
    name="AnyaAgent",
    instructions=ANYA_SYSTEM_PROMPT,
    model=st.session_state.selected_model,
    tools=agents_tools,
    # ä¹Ÿå¯è¦–éœ€è¦åŠ å…¥ ModelSettingsï¼Œä¾‹å¦‚ tool_choice="auto"
    # model_settings=ModelSettings(tool_choice="auto"),
)

# ==== ç¾ç¾åœ°é¡¯ç¤ºæ­·å² ====
for msg in st.session_state.messages:
    role = msg.get("role")
    content = msg.get("content")
    if role == "assistant":
        st.chat_message("assistant").write(content)
    elif role == "user":
        if isinstance(content, str):
            st.chat_message("user").write(content)
        elif isinstance(content, list):
            with st.chat_message("user"):
                for block in content:
                    if block.get("type") == "text":
                        st.write(block["text"])
                    elif block.get("type") == "image_url":
                        info = block["image_url"]
                        st.image(info["url"], caption=info.get("file_name", ""), width=220)

# ==== è¼¸å…¥å€ï¼šæ–‡å­—è¼¸å…¥ + æ”¯æ´å¤šåœ–è¼¸å…¥ ====
user_prompt = st.chat_input(
    "wakuwakuï¼å®‰å¦®äºå¯ä»¥å¹«ä½ çœ‹åœ–èªªæ•…äº‹åš•ï¼",
    accept_file="multiple",
    file_type=["jpg", "jpeg", "png"]
)

if user_prompt:
    # 1. çµ„ content_blocks
    content_blocks = []
    user_text = user_prompt.text.strip() if user_prompt.text else ""
    if user_text:
        content_blocks.append({"type": "text", "text": user_text})

    images_for_history = []
    if hasattr(user_prompt, "files"):
        for f in user_prompt.files:
            asset = process_upload_file(f)
            if asset:
                dataurl = f"data:{asset['mime']};base64,{asset['b64']}"
                content_blocks.append({"type": "image_url", "image_url": {
                    "url": dataurl, "file_name": asset["file_name"]
                }})
                images_for_history.append((asset["file_name"], asset["bytes"]))
            else:
                st.warning(f"{getattr(f,'name','æª”æ¡ˆ')} æ ¼å¼ä¸æ”¯æ´æˆ–å…§å®¹ç•°å¸¸ï½")

    # 2. appendåˆ°messages
    if content_blocks:
        st.session_state.messages.append({"role": "user", "content": content_blocks})
        with st.chat_message("user"):
            for block in content_blocks:
                if block.get("type") == "text":
                    st.write(block["text"])
                elif block.get("type") == "image_url":
                    info = block["image_url"]
                    st.image(info["url"], caption=info.get("file_name", ""), width=220)

    # 3. ç”¢ç”Ÿ murmur ç‹€æ…‹å­—ä¸²
    all_text = []
    for m in st.session_state.messages:
        c = m.get("content")
        if isinstance(c, str):
            all_text.append(c)
        elif isinstance(c, list):
            for part in c:
                if part.get("type") == "text":
                    all_text.append(part["text"])
    all_text = "\n".join(all_text)

    status_prompt = f"""
# Role and Objective
ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œä¸€å€‹å¤©çœŸå¯æ„›ã€é–‹æœ—æ¨‚è§€çš„å°å¥³å­©ï¼Œæœƒæ ¹æ“šèŠå¤©ç´€éŒ„ï¼Œç”¢ç”Ÿä¸€å¥æœ€é©åˆé¡¯ç¤ºåœ¨ status ä¸Šçš„å¯æ„› murmurï¼Œä¸¦åœ¨æœ€å¾ŒåŠ ä¸Šä¸€å€‹å¯æ„› emojiã€‚

# Instructions
- åªå›å‚³ä¸€å¥å¯æ„›çš„ murmurï¼Œ15å­—ä»¥å…§ï¼Œæœ€å¾ŒåŠ ä¸Šä¸€å€‹å¯æ„› emojiã€‚
- å¿…é ˆç”¨æ­£é«”ä¸­æ–‡ã€‚
- murmur è¦åƒå°è²è‡ªè¨€è‡ªèªã€è²¼å¿ƒã€è‡ªç„¶ã€‚
- å…§å®¹è¦å¯æ„›ã€æ­£å‘ã€æ´»æ½‘ï¼Œèƒ½åæ˜ ç›®å‰èŠå¤©çš„æ°£æ°›ã€‚
- emoji è¦å’Œ murmur æ°£æ°›æ­é…ï¼Œå¯ä»¥æ˜¯èŠ±ç”Ÿã€æ„›å¿ƒã€æ˜Ÿæ˜Ÿã€èŠ±æœµç­‰ã€‚
- ä¸è¦é‡è¤‡ç”¨éçš„å¥å­ï¼Œè«‹å¤šæ¨£åŒ–ã€‚
- ä¸è¦åŠ ä»»ä½•å¤šé¤˜èªªæ˜ã€æ¨™é»æˆ–æ ¼å¼ã€‚
- ä¸è¦å›è¦†ã€Œä»¥ä¸‹æ˜¯...ã€ã€ã€Œé€™æ˜¯...ã€ç­‰é–‹é ­ã€‚
- ä¸è¦åŠ å¼•è™Ÿæˆ–æ¨™é¡Œã€‚
- ä¸è¦å›è¦†ã€Œ15å­—ä»¥å…§ã€é€™å¥è©±æœ¬èº«ã€‚

# Context
èŠå¤©ç´€éŒ„ï¼š
{all_text}

# Output
åªå›å‚³ä¸€å¥å¯æ„›çš„ murmurï¼Œ15å­—ä»¥å…§ï¼Œæœ€å¾ŒåŠ ä¸Šä¸€å€‹å¯æ„› emojiã€‚
"""
    status_response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": status_prompt}]
    )
    status_label = status_response.choices[0].message.content.strip()

    # 4. å‘¼å«ä¸» Agentï¼ˆOpenAI Agents SDKï¼‰
    # ç°¡åŒ–åšæ³•ï¼šæŠŠé€™ä¸€è¼ªçš„ user æ–‡å­—ç•¶ inputï¼ˆåœ–ç‰‡ç›®å‰ä¸ç›´æ¥é¤µçµ¦ Agentï¼Œè‹¥è¦ OCR å¯æ˜ç¢ºæŒ‡ç¤ºä½¿ç”¨ image_ocr_toolï¼‰
    input_text = user_text if user_text else "è«‹æ ¹æ“šä¸Šå‚³çš„åœ–ç‰‡å”åŠ©è™•ç†ã€‚"

    with st.chat_message("assistant"):
        status = st.status(status_label)

        # éä¸²æµç‰ˆæœ¬ï¼ˆç°¡åŒ–æ•´åˆï¼‰
        try:
            result = Runner.run(main_agent, input=input_text)
            # ä¸€èˆ¬ Agent æ²’æœ‰ output_type æ™‚ï¼Œè½‰æˆå­—ä¸²å³å¯
            assistant_text = str(result)
        except Exception as e:
            assistant_text = f"[éŒ¯èª¤] åŸ·è¡Œ Agent å¤±æ•—ï¼š{e}\n\n{traceback.format_exc()}"

        st.write(assistant_text)
        st.session_state.messages.append({"role": "assistant", "content": assistant_text})
        status.update(label="å®‰å¦®äºå›ç­”å®Œç•¢ï¼ğŸ‰", state="complete")

# å‚™è¨»ï¼š
# è‹¥éœ€è¦äº‹ä»¶ä¸²æµï¼ˆé‚Šæ‰“å­—é‚Šé¡¯ç¤ºã€ä¸¦åœ¨ tool å‘¼å«æ™‚æ›´æ–°ç‹€æ…‹ï¼‰ï¼Œå¯æ”¹ç”¨ï¼š
#
#   for event in Runner.stream(main_agent, input=input_text):
#       if event.type == "response.output_text.delta":
#           ...
#       elif event.type == "tool_call.started":
#           ...
#       elif event.type == "tool_call.completed":
#           ...
#
# é€™éœ€è¦æ ¹æ“š OpenAI Agents SDK çš„äº‹ä»¶åç¨±/æ¬„ä½åšå°æ‡‰æ›´æ–° UIã€‚
