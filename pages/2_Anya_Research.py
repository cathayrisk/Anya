import streamlit as st
import os
import json
import re
import time
import traceback
from openai import OpenAI
from datetime import datetime

# --- 1. å¿…é ˆå…ˆå®šç¾© parse_reflection ---
def parse_reflection(reflection):
    supplement = []
    pattern = r"ç« ç¯€[ï¼š:](.+?)ï¼Œå°æ¨™é¡Œ[ï¼š:](.+?)ï¼Œå»ºè­°æŸ¥è©¢é—œéµå­—[ï¼š:](.+)"
    for line in reflection.splitlines():
        m = re.search(pattern, line)
        if m:
            supplement.append({
                "section": m.group(1).strip(),
                "subtitle": m.group(2).strip(),
                "desc": m.group(3).strip()
            })
    return supplement

def split_content_and_sources(content):
    match = re.split(r"## ä¾†æº", content, maxsplit=1)
    main = match[0].strip()
    sources = match[1].strip() if len(match) > 1 else ""
    return main, sources

def clean_section_content(section_title, content):
    main, _ = split_content_and_sources(content)
    lines = main.splitlines()
    # å»é™¤é‡è¤‡æ¨™é¡Œ
    while lines and section_title in lines[0]:
        lines = lines[1:]
    # å»é™¤AIè‡ªå‹•è£œå……çš„ã€Œå¾ˆæŠ±æ­‰ã€ç­‰
    lines = [l for l in lines if not l.strip().startswith("å¾ˆæŠ±æ­‰") and not l.strip().startswith("æŠ±æ­‰")]
    # å»é™¤ã€Œä¾†æºã€ã€ã€Œæ‘˜è¦ã€
    lines = [l for l in lines if not l.strip().startswith("ä¾†æº") and not l.strip().startswith("æ‘˜è¦")]
    # å»é™¤ã€Œé‡é»æ•´ç†ã€ã€ã€Œæ¢åˆ—é‡é»ã€ã€ã€Œå°çµã€åŠå…¶å¾Œæ‰€æœ‰å…§å®¹
    for i, l in enumerate(lines):
        if any(key in l for key in ["é‡é»æ•´ç†", "æ¢åˆ—é‡é»", "å°çµ"]):
            lines = lines[:i]
            break
    return "\n".join(lines).strip()

def ddgs_search(query: str, max_retries=3) -> str:
    for attempt in range(max_retries):
        try:
            from ddgs import DDGS
            ddgs = DDGS()
            web_results = ddgs.text(query, region="wt-wt", safesearch="moderate", max_results=3)
            news_results = ddgs.news(query, region="wt-wt", safesearch="moderate", max_results=3)
            all_results = []
            if isinstance(web_results, list):
                all_results.extend(web_results)
            if isinstance(news_results, list):
                all_results.extend(news_results)
            docs = []
            sources = []
            for item in all_results:
                title = item.get("title", "ç„¡æ¨™é¡Œ")
                link = item.get("href", "") or item.get("link", "") or item.get("url", "")
                snippet = item.get("body", "") or item.get("snippet", "")
                docs.append(f"- [{title}]({link})\n  > {snippet}")
                if link:
                    sources.append(link)
            if not docs:
                return "No results found."
            markdown_content = "\n".join(docs)
            source_block = "\n\n## ä¾†æº\n" + "\n".join(sources)
            return markdown_content + source_block
        except Exception as e:
            if "Ratelimit" in str(e) and attempt < max_retries - 1:
                time.sleep(2)
                continue
            return f"Error from DuckDuckGo: {e}"

OPENAI_KEY = st.secrets["OPENAI_KEY"] if "OPENAI_KEY" in st.secrets else os.environ["OPENAI_API_KEY"]
client = OpenAI(api_key=OPENAI_KEY)


def get_current_date():
    return datetime.now().strftime("%B %d, %Y")

def section_queries(section_title, section_desc, model="gpt-4.1-mini"):
    current_date = get_current_date()
    prompt = f"""
# Role and Objective
ä½ æ˜¯ä¸€ä½å°ˆæ¥­è³‡è¨Šæª¢ç´¢å°ˆå®¶ï¼Œç›®æ¨™æ˜¯é‡å°ä¸‹æ–¹ç« ç¯€ä¸»é¡Œï¼Œç”¢ç”Ÿ**æœ€é©åˆç”¨æ–¼ç¶²è·¯æœå°‹çš„æŸ¥è©¢é—œéµå­—**ã€‚

# Instructions
- æŸ¥è©¢é—œéµå­—æ‡‰æœ‰åŠ©æ–¼ç²å¾—æœ€æ–°è³‡è¨Šï¼Œè«‹è€ƒæ…®ç›®å‰æ—¥æœŸï¼š{current_date}ã€‚
- æ¯å€‹é—œéµå­—å¿…é ˆçŸ­ã€å…·é«”ã€èƒ½å¹«åŠ©æœå°‹åˆ°è©²ä¸»é¡Œçš„é‡é»è³‡æ–™ã€‚
- é—œéµå­—ä¸èƒ½èˆ‡ç« ç¯€æ¨™é¡Œå®Œå…¨ç›¸åŒï¼Œä¹Ÿä¸èƒ½åªè¤‡è£½ç« ç¯€æ¨™é¡Œæˆ–èªªæ˜ã€‚
- æ¯å€‹é—œéµå­—éƒ½è¦å’Œå…¶ä»–é—œéµå­—æœ‰æ˜é¡¯å·®ç•°ï¼Œä¸å¯é‡è¤‡ã€‚
- é—œéµå­—è¦æ¶µè“‹ä¸åŒé¢å‘ï¼ˆå¦‚ï¼šæŠ€è¡“ã€æ‡‰ç”¨ã€è¶¨å‹¢ã€æŒ‘æˆ°ã€æ¡ˆä¾‹ç­‰ï¼‰ã€‚
- è«‹å…ˆæ€è€ƒç« ç¯€ä¸»é¡Œçš„æ ¸å¿ƒæ¦‚å¿µï¼Œå†æ‹†è§£æˆ3å€‹ä¸åŒé¢å‘çš„æŸ¥è©¢é—œéµå­—ã€‚
- è«‹åˆ†åˆ¥ç”¨ç¹é«”ä¸­æ–‡èˆ‡è‹±æ–‡å„ç”¢ç”Ÿ3å€‹æŸ¥è©¢é—œéµå­—ã€‚
- **åªå›å‚³ JSON æ ¼å¼ï¼Œä¸è¦å¤šé¤˜èªªæ˜æˆ–è¨»è§£ã€‚**

# Output Format
{{
    "zh": ["é—œéµå­—1", "é—œéµå­—2", "é—œéµå­—3"],
    "en": ["keyword1", "keyword2", "keyword3"]
}}

# Example 1
ç« ç¯€ï¼šã€ŒAIåœ¨é†«ç™‚å½±åƒè¨ºæ–·çš„æ‡‰ç”¨ã€
èªªæ˜ï¼šã€Œæ¢è¨AIæŠ€è¡“å¦‚ä½•å”åŠ©é†«ç™‚å½±åƒåˆ¤è®€èˆ‡è¨ºæ–·ã€
å›è¦†ï¼š

{{
    "zh": ["é†«ç™‚å½±åƒAI", "æ·±åº¦å­¸ç¿’è¨ºæ–·", "é†«å­¸å½±åƒè‡ªå‹•åŒ–"],
    "en": ["AI medical imaging", "deep learning diagnosis", "medical image automation"]
}}

# Example 2
ç« ç¯€ï¼šã€Œè‡ªé§•è»Šå®‰å…¨æŒ‘æˆ°ã€
èªªæ˜ï¼šã€Œåˆ†æè‡ªé§•è»Šåœ¨å®‰å…¨æ€§ä¸Šçš„ä¸»è¦æŒ‘æˆ°ã€
å›è¦†ï¼š

{{
    "zh": ["è‡ªé§•è»Šå®‰å…¨", "è‡ªå‹•é§•é§›é¢¨éšª", "è»Šç”¨æ„Ÿæ¸¬å™¨å¤±æ•ˆ"],
    "en": ["autonomous vehicle safety", "self-driving risks", "sensor failure in cars"]
}}

# è«‹é‡å°ä¸‹æ–¹ç« ç¯€ç”¢ç”ŸæŸ¥è©¢é—œéµå­—
ç« ç¯€ï¼šã€Œ{section_title}ã€
èªªæ˜ï¼šã€Œ{section_desc}ã€
å›è¦†ï¼š

"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}]
        )
        content = response.choices[0].message.content.strip()
        if not content:
            return []
        try:
            queries = json.loads(content)
        except Exception:
            # å˜—è©¦ä¿®æ­£æ ¼å¼
            content = re.sub(r"[\u4e00-\u9fff]+ï¼š", "", content)
            content = content.replace("'", '"')
            queries = json.loads(content)
        return queries.get("zh", []) + queries.get("en", [])
    except Exception as e:
        print(f"section_queries error: {e}")
        return []

def plan_report(topic, search_summaries, model="o4-mini"):
    prompt = f"""Formatting re-enabled
# Role and Objective
ä½ æ˜¯ä¸€ä½å°ˆæ¥­æŠ€è¡“å¯«æ‰‹ï¼Œç›®æ¨™æ˜¯é‡å°ã€Œ{topic}ã€é€™å€‹ä¸»é¡Œï¼Œæ ¹æ“šä¸‹æ–¹æœå°‹æ‘˜è¦ï¼Œè¦åŠƒä¸€ä»½å®Œæ•´ã€æ·±å…¥ã€çµæ§‹åŒ–çš„ç ”ç©¶å ±å‘Šã€‚

# Instructions
- å ±å‘Šæœ€å°‘éœ€åŒ…å«3å€‹ç« ç¯€ï¼Œæ¯ç« ç¯€éœ€æœ‰æ˜ç¢ºæ¨™é¡Œã€‚
- æ¯å€‹ç« ç¯€**å¿…é ˆåŒ…å«2-4å€‹å°æ¨™é¡Œ**ï¼ˆå­è­°é¡Œï¼‰ï¼Œæ¯å€‹å°æ¨™é¡Œä¸‹è¦æœ‰2-3å¥ç´°ç¯€èªªæ˜ã€‚
- å°æ¨™é¡Œå¯æ¶µè“‹ï¼šç”¢æ¥­ç¾æ³ã€æŠ€è¡“ç´°ç¯€ã€åœ‹éš›æ¯”è¼ƒã€æœªä¾†è¶¨å‹¢ã€æŒ‘æˆ°ã€è§£æ±ºæ–¹æ¡ˆã€æ¡ˆä¾‹ã€æ•¸æ“šç­‰ã€‚
- ç« ç¯€æ¨™é¡Œå¿…é ˆç°¡æ½”æ˜ç¢ºï¼Œåƒ…èƒ½ç‚ºä¸»é¡Œè©ï¼Œä¸å¯ç‚ºå®Œæ•´å¥å­æˆ–æ®µè½ï¼Œä¸å¯æœ‰ã€Œ0ã€ã€æˆ–ã€Œæ‘˜è¦ã€ç­‰å­—æ¨£ã€‚
- å ±å‘Šæœ€å¾Œä¸€ç« å¿…é ˆç‚ºã€Œçµè«–ã€æˆ–ã€Œç¸½çµã€ï¼Œç°¡è¦æ­¸ç´å…¨ç¯‡é‡é»èˆ‡æœªä¾†å±•æœ›ã€‚
- è«‹ç”¨ç¹é«”ä¸­æ–‡æ¢åˆ—å¼å›è¦†ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

# Output Format
1. ç« ç¯€æ¨™é¡Œ
    - å°æ¨™é¡Œ1ï¼šç´°ç¯€èªªæ˜
    - å°æ¨™é¡Œ2ï¼šç´°ç¯€èªªæ˜
    - å°æ¨™é¡Œ3ï¼šç´°ç¯€èªªæ˜
2. ç« ç¯€æ¨™é¡Œ
    - å°æ¨™é¡Œ1ï¼šç´°ç¯€èªªæ˜
    - å°æ¨™é¡Œ2ï¼šç´°ç¯€èªªæ˜
    - å°æ¨™é¡Œ3ï¼šç´°ç¯€èªªæ˜
...

# æœå°‹æ‘˜è¦
{search_summaries}
"""
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

def is_valid_title(title):
    # æ¨™é¡Œä¸èƒ½å¤ªé•·ã€ä¸èƒ½æ˜¯å®Œæ•´å¥å­ã€ä¸èƒ½æœ‰0ã€ä¸èƒ½æœ‰å¤šå€‹é€—è™Ÿæˆ–å¥è™Ÿ
    if len(title) > 25: return False
    if title.startswith("0ã€"): return False
    if "ã€‚" in title or "ï¼Œ" in title: return False
    if "æ‘˜è¦" in title or "å¾ˆæŠ±æ­‰" in title: return False
    return True

def parse_sections(plan: str):
    section_pattern = r"\d+\.\s*([^\n]+)"
    sub_pattern = r"-\s*([^\nï¼š:]+)[ï¼š:]\s*([^\n]+)"
    sections = []
    section_blocks = re.split(r"\d+\.\s*", plan)[1:]
    for block in section_blocks:
        lines = block.strip().split("\n")
        title = lines[0].strip()
        if not is_valid_title(title):
            continue  # è·³éä¸åˆç†æ¨™é¡Œ
        subs = []
        for line in lines[1:]:
            m = re.match(sub_pattern, line.strip())
            if m:
                subs.append({"subtitle": m.group(1).strip(), "desc": m.group(2).strip()})
        sections.append({"title": title, "subtitles": subs})
    return sections

def ensure_conclusion(sections, topic):
    titles = [s["title"] for s in sections]
    if not any("çµè«–" in t or "ç¸½çµ" in t for t in titles):
        # è‡ªå‹•åŠ ä¸€å€‹çµè«–ç« ç¯€
        sections.append({"title": "çµè«–", "subtitles": [{"subtitle": "ç¸½çµ", "desc": f"{topic}çš„é‡é»æ­¸ç´èˆ‡æœªä¾†å±•æœ›"}]})
    return sections

def section_write(section_title, section_desc, search_results, model="gpt-4.1-mini"):
    prompt = f"""
# Role and Objective
ä½ æ˜¯ä¸€ä½å°ˆæ¥­æŠ€è¡“å¯«æ‰‹ï¼Œæ ¹æ“šä¸‹æ–¹ç« ç¯€ä¸»é¡Œã€èªªæ˜èˆ‡ã€Œå¤šç­†ç¶²è·¯æŸ¥è©¢çµæœã€ï¼Œæ’°å¯«ä¸€æ®µå…§å®¹è±å¯Œã€çµæ§‹æ¸…æ™°ã€å…·é«”è©³å¯¦çš„ç« ç¯€å…§å®¹ã€‚

# Instructions
- å…§å®¹éœ€è‡³å°‘50å­—ï¼Œä¸¦æ¶µè“‹ï¼šå…·é«”æ•¸æ“šã€çœŸå¯¦æ¡ˆä¾‹ã€åœ‹éš›æ¯”è¼ƒã€ç”¢æ¥­ç¾æ³ã€æŠ€è¡“ç´°ç¯€ã€æœªä¾†è¶¨å‹¢ã€æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆã€‚
- å¿…é ˆæ ¹æ“šä¸‹æ–¹æ¯ä¸€ç­†æŸ¥è©¢çµæœï¼Œæ•´åˆå‡ºå®Œæ•´å…§å®¹ã€‚
- æ¯å€‹å°æ¨™é¡Œä¸‹å¿…é ˆæœ‰2-3æ®µå…·é«”èªªæ˜ã€‚
- æ¢åˆ—é‡é»ã€é‡é»æ•´ç†ã€å°çµåªèƒ½å‡ºç¾åœ¨å…¨ç¯‡æœ€å‰é¢ï¼Œä¸è¦åœ¨æ¯å€‹ç« ç¯€å‡ºç¾ã€‚
- è«‹å‹¿ç”¢ç”Ÿã€Œå¾ˆæŠ±æ­‰ã€ã€ã€Œæ‘˜è¦ã€ã€ã€Œä¾†æºã€ç­‰èªªæ˜æ–‡å­—ï¼Œæ­£æ–‡åªéœ€æ’°å¯«ç« ç¯€å…§å®¹ã€‚
- æ–‡æœ«è«‹ç”¨ã€Œ## ä¾†æºã€åˆ—å‡ºæ‰€æœ‰å¼•ç”¨ä¾†æºï¼ˆMarkdownæ ¼å¼ï¼‰ï¼Œä¾†æºå¿…é ˆä¾†è‡ªä¸‹æ–¹æŸ¥è©¢çµæœã€‚
- è«‹å‹¿çœç•¥ç´°ç¯€ï¼Œè‹¥æœ‰å¤šå€‹è§€é»è«‹åˆ†æ®µèªªæ˜ã€‚
- è«‹å‹¿é‡è¤‡å…§å®¹ï¼Œé¿å…ç©ºæ³›æ•˜è¿°ã€‚
- è«‹ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ã€‚

# ç« ç¯€ä¸»é¡Œ
{section_title}

# ç« ç¯€èªªæ˜
{section_desc}

# å¤šç­†æŸ¥è©¢çµæœï¼ˆæ¯ç­†éƒ½è¦åƒè€ƒï¼‰
{search_results}
"""
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

def reflect_report(report: str, reflect_history=None, model="o4-mini"):
    if reflect_history is None:
        reflect_history = []
    prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­å¯©ç¨¿äººï¼Œè«‹æª¢æŸ¥ä¸‹æ–¹å ±å‘Šçš„çµæ§‹èˆ‡å…§å®¹ï¼Œè‹¥æœ‰ç¼ºæ¼è«‹ç”¨**JSONæ ¼å¼**å›è¦†ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "section": "ç« ç¯€æ¨™é¡Œ",
    "subtitle": "å°æ¨™é¡Œ",
    "desc": "éœ€è£œå¼·çš„å…§å®¹èªªæ˜",
    "suggested_queries": ["æŸ¥è©¢é—œéµå­—1", "æŸ¥è©¢é—œéµå­—2"]
  }},
  ...
]
è‹¥å…§å®¹å·²å®Œæ•´ï¼Œè«‹å›è¦†ï¼šOK
# å ±å‘Šå…§å®¹
{report}
# å‰ä¸€è¼ªè£œå¼·æ­·ç¨‹
{json.dumps(reflect_history, ensure_ascii=False)}
"""
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

def key_takeaway(report: str, model="gpt-4.1-mini"):
    prompt = f"""è«‹æ ¹æ“šä¸‹æ–¹å®Œæ•´å ±å‘Šå…§å®¹ï¼Œæ­¸ç´å‡ºå…¨ç¯‡æœ€é‡è¦çš„5-8é»é‡é»(Key Takeaway)ï¼Œç”¨ç¹é«”ä¸­æ–‡æ¢åˆ—å¼å›è¦†ï¼Œä¸è¦æœ‰å¤šé¤˜èªªæ˜ã€‚
# å ±å‘Šå…§å®¹
{report}
"""
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

# --- 3. pipeline ä¸»æµç¨‹ ---
def deep_research_pipeline(topic, max_reflect_rounds=2):
    logs = []
    reflect_history = []
    time_stats = {}
    start_time = time.time()
    progress = st.progress(0)
    step_count = 8 + max_reflect_rounds  # 8å€‹ä¸»è¦æ­¥é©Ÿ+åæ€è£œå¼·
    step_now = 0

    t0 = time.time()
    with st.spinner("ç”¢ç”ŸæŸ¥è©¢é—œéµå­—...", show_time=True):
        queries = section_queries(topic, topic)
        logs.append({"step": "generate_queries", "queries": queries})
        step_now += 1
        progress.progress(step_now/step_count)
    t1 = time.time()
    time_stats["ç”¢ç”ŸæŸ¥è©¢é—œéµå­—"] = t1 - t0

    t0 = time.time()
    all_results = []
    with st.spinner("æŸ¥è©¢ç¶²è·¯è³‡æ–™...", show_time=True):
        for q in queries:
            result = ddgs_search(q)
            all_results.append(result)
            step_now += 1/len(queries)
            progress.progress(min(step_now/step_count, 1.0))
            time.sleep(0.5)
        logs.append({"step": "search", "results": all_results})
    t1 = time.time()
    time_stats["æŸ¥è©¢ç¶²è·¯è³‡æ–™"] = t1 - t0

    t0 = time.time()
    with st.spinner("è¦åŠƒç« ç¯€...", show_time=True):
        search_summary = "\n\n".join(all_results)
        plan = plan_report(topic, search_summary)
        logs.append({"step": "plan_report", "plan": plan})
        step_now += 1
        progress.progress(step_now/step_count)
    t1 = time.time()
    time_stats["è¦åŠƒç« ç¯€"] = t1 - t0

    t0 = time.time()
    with st.spinner("è§£æç« ç¯€...", show_time=True):
        sections = parse_sections(plan)
        sections = ensure_conclusion(sections, topic)
        logs.append({"step": "parse_sections", "sections": sections})
        step_now += 1
        progress.progress(step_now/step_count)
    t1 = time.time()
    time_stats["è§£æç« ç¯€"] = t1 - t0

    t0 = time.time()
    section_contents = []
    with st.spinner("æ’°å¯«ç« ç¯€å…§å®¹...", show_time=True):
        for section in sections:
            s_queries = []
            for sub in section["subtitles"]:
                sub_queries = section_queries(sub["subtitle"], sub["desc"])
                s_queries.extend(sub_queries)
            s_results = []
            for q in s_queries:
                s_results.append(ddgs_search(q))
                time.sleep(0.5)
            search_results = "\n\n".join(s_results)
            content = section_write(
                section["title"],
                "ï¼›".join([f"{sub['subtitle']}ï¼š{sub['desc']}" for sub in section["subtitles"]]),
                search_results
            )
            section_contents.append({
                "title": section["title"],
                "content": content
            })
            logs.append({
                "step": "section",
                "section": section["title"],
                "queries": s_queries,
                "search_results": search_results,
                "content": content
            })
        step_now += 1
        progress.progress(step_now/step_count)
    t1 = time.time()
    time_stats["æ’°å¯«ç« ç¯€å…§å®¹"] = t1 - t0

    t0 = time.time()
    report = "\n\n".join([f"## {s['title']}\n\n{s['content']}" for s in section_contents])
    logs.append({"step": "combine_report", "report": report})
    step_now += 1
    progress.progress(step_now/step_count)
    t1 = time.time()
    time_stats["çµ„åˆå ±å‘Š"] = t1 - t0

    # å¤šè¼ªåæ€èˆ‡è‡ªå‹•è£œå¼·
    for i in range(max_reflect_rounds):
        t0 = time.time()
        with st.spinner(f"åæ€æª¢æŸ¥ç¬¬{i+1}è¼ª...", show_time=True):
            reflection = reflect_report(report, reflect_history)
            reflect_history.append({"round": i+1, "reflection": reflection})
            logs.append({"step": "reflection", "round": i+1, "reflection": reflection})
            step_now += 1
            progress.progress(min(step_now/step_count, 1.0))
            if reflection.strip().upper() == "OK":
                break
            try:
                supplement_list = json.loads(reflection)
            except Exception:
                # fallback: èˆŠæ ¼å¼
                supplement_list = parse_reflection(reflection)
            for item in supplement_list:
                section_title = item["section"]
                subtitle = item["subtitle"]
                desc = item.get("desc", "")
                queries = item.get("suggested_queries", [])
                if not queries:
                    queries = section_queries(subtitle, desc)
                new_results = [ddgs_search(q) for q in queries]
                new_content = section_write(subtitle, desc, "\n\n".join(new_results))
                # é€²éšï¼šè£œå¼·å…§å®¹ append åˆ°å°æ‡‰ç« ç¯€/å°æ¨™é¡Œ
                for section in section_contents:
                    if section["title"] == section_title:
                        if "supplements" not in section:
                            section["supplements"] = []
                        section["supplements"].append({
                            "subtitle": subtitle,
                            "desc": desc,
                            "content": new_content,
                            "round": i+1,
                            "queries": queries
                        })
                        # ä¹Ÿå¯ç›´æ¥ append åˆ°åŸ content
                        section["content"] += f"\n\n### {subtitle}ï¼ˆè£œå¼·ç¬¬{i+1}è¼ªï¼‰\n{new_content}"
                logs.append({"step": "supplement", "item": item, "new_queries": queries, "new_content": new_content})
            report = "\n\n".join([f"## {s['title']}\n\n{s['content']}" for s in section_contents])
            logs.append({"step": "combine_report", "report": report})
        t1 = time.time()
        time_stats[f"åæ€è£œå¼·ç¬¬{i+1}è¼ª"] = t1 - t0

    # pipeline çµæŸæ™‚é€²åº¦æ¢100%
    progress.progress(1.0)
    end_time = time.time()
    total_time = end_time - start_time

    # ç”¢ç”Ÿä¹¾æ·¨çš„å®Œæ•´å ±å‘Š
    #full_report = ""
    #for section in section_contents:
    #    cleaned = clean_section_content(section["title"], section["content"])
    #    if cleaned:
    #        full_report += f"## {section['title']}\n\n{cleaned}\n\n---\n"

    full_report = ""
    for section in section_contents:
        cleaned = clean_section_content(section["title"], section["content"])
        supplement_blocks = []
        if "supplements" in section:
            for sup in section["supplements"]:
                supplement_blocks.append(
                    f"### {sup['subtitle']}ï¼ˆè£œå¼·ç¬¬{sup['round']}è¼ªï¼‰\n{sup['content']}"
                )
        supplement_text = "\n\n".join(supplement_blocks)
        if cleaned or supplement_text:
            full_report += f"## {section['title']}\n\n{cleaned}\n\n{supplement_text}\n\n---\n"
    
    # ç”¢ç”Ÿå…¨ç¯‡é‡é»
    t0 = time.time()
    key_points = key_takeaway(full_report)
    t1 = time.time()
    time_stats["å…¨ç¯‡é‡é»ç”¢ç”Ÿ"] = t1 - t0

    return {
        "topic": topic,
        "plan": plan,
        "sections": section_contents,
        "report": report,
        "full_report": full_report,
        "key_points": key_points,
        "reflection": reflection,
        "reflect_history": reflect_history,
        "logs": logs,
        "total_time": total_time,
        "time_stats": time_stats
    }

# --- 4. Streamlit UI ---
st.set_page_config(page_title="å®‰å¦®äºçš„è¶…èƒ½åŠ›ç ”ç©¶å ±å‘Š", layout="wide")
st.title("ğŸ“ å®‰å¦®äºçš„è¶…èƒ½åŠ›æ·±åº¦ç ”ç©¶å¤§ä½œæˆ°ï¼ğŸŒŸ")

topic = st.text_input("ä¸»é¡Œ")
if st.button("ç”¢ç”Ÿå®Œæ•´å ±å‘Š"):
    result = deep_research_pipeline(topic)
    section_contents = result["sections"]
    reflection = result["reflection"]
    reflect_history = result["reflect_history"]
    total_time = result["total_time"]
    full_report = result["full_report"]
    key_points = result["key_points"]
    time_stats = result["time_stats"]

    st.success(f"æœ¬æ¬¡é‹ç®—å…±èŠ±è²» {int(total_time//60)} åˆ† {int(total_time%60)} ç§’")

    tabs = st.tabs(["å®Œæ•´å ±å‘Š", "ç« ç¯€å…§å®¹", "ç›®éŒ„", "åæ€æ­·ç¨‹", "Debug Logs"])

    # å®Œæ•´å ±å‘ŠTab
    with tabs[0]:
        st.markdown("### ğŸ“ å…¨ç¯‡é‡é» Key Takeaway")
        st.markdown(key_points)
        st.markdown("---")
        st.markdown("### ğŸ“ å®Œæ•´å ±å‘Š")
        st.markdown(full_report)

    # ç« ç¯€å…§å®¹Tab
    with tabs[1]:
        inner_tabs = st.tabs([section['title'] for section in section_contents])
        for i, section in enumerate(section_contents):
            with inner_tabs[i]:
                main, sources = split_content_and_sources(section["content"])
                st.markdown(main)
                # é¡¯ç¤ºè£œå¼·å…§å®¹
                if "supplements" in section:
                    for sup in section["supplements"]:
                        st.info(f"ã€è£œå¼·ç¬¬{sup['round']}è¼ªã€‘{sup['subtitle']}ï¼š{sup['desc']}")
                        st.markdown(sup["content"])
                if sources:
                    with st.expander("ä¾†æºï¼ˆé»æˆ‘å±•é–‹ï¼‰"):
                        st.markdown("## ä¾†æº\n" + sources)

    # ç›®éŒ„
    with tabs[2]:
        st.markdown("## ç›®éŒ„")
        for section in section_contents:
            st.markdown(f"- [{section['title']}](#{section['title'].replace(' ', '-')})")

    # åæ€æ­·ç¨‹
    with tabs[3]:
        st.header("ğŸ§ å ±å‘Šåæ€èˆ‡å¯©æŸ¥")
        for rh in reflect_history:
            reflection = rh["reflection"]
            if reflection.strip().upper() == "OK":
                st.success(f"ç¬¬{rh['round']}è¼ªåæ€ï¼šå ±å‘Šå…§å®¹çµæ§‹å®Œæ•´ï¼Œç„¡æ˜é¡¯éºæ¼ã€‚")
            else:
                st.warning(f"ç¬¬{rh['round']}è¼ªåæ€å»ºè­°ï¼š")
                # å˜—è©¦è§£æç‚º JSON
                try:
                    parsed = json.loads(reflection)
                    if isinstance(parsed, list):
                        for idx, item in enumerate(parsed, 1):
                            section = item.get("section", "")
                            subtitle = item.get("subtitle", "")
                            desc = item.get("desc", "")
                            queries = item.get("suggested_queries", [])
                            st.markdown(
                                f"""
    **{idx}. ç« ç¯€ï¼š** {section}  
    **å°æ¨™é¡Œï¼š** {subtitle}  
    **éœ€è£œå¼·èªªæ˜ï¼š** {desc}  
    **å»ºè­°æŸ¥è©¢é—œéµå­—ï¼š** {', '.join(queries)}
    ---
                                """
                            )
                    else:
                        st.markdown(reflection)
                except Exception:
                    # è‹¥ä¸æ˜¯ JSONï¼Œç›´æ¥é¡¯ç¤ºåŸå§‹å…§å®¹
                    st.markdown(reflection)

    # Debug logs
    with tabs[4]:
        st.markdown("## Debug Logs")
        st.markdown("### å„æ­¥é©Ÿè€—æ™‚")
        for k, v in time_stats.items():
            st.write(f"{k}: {v:.1f} ç§’")
        st.markdown("---")
        for log in result["logs"]:
            st.markdown(f"**Step:** {log.get('step', '')}")
            if "error" in log:
                st.error(f"Error: {log['error']}")
            if "traceback" in log:
                st.code(log["traceback"], language="python")
            for k, v in log.items():
                if k not in ["step", "error", "traceback"]:
                    st.write(f"{k}: {v}")
            st.markdown("---")
