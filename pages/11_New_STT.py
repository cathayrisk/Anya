# -*- coding: utf-8 -*-
# æœƒè­°éŒ„éŸ³ â†’ ç›´æ’­é€å­—ï¼‹æ‘˜è¦ï¼ˆç„¡ OpenCC ç‰ˆï¼šrefine ä¸€å¾‹è¼¸å‡ºæ­£é«”ä¸­æ–‡-å°ç£ç”¨èªï¼‰
# è®Šæ›´é‡é»ï¼š
# - ä¸ä½¿ç”¨ OpenCCã€‚æ”¹ä»¥ã€Œå…©æ®µå¼ LLM ä¿éšªã€ï¼šå…ˆ refineï¼Œå†å¼·åˆ¶ç¹é«”åŒ–ï¼ˆä¿æŒè¡Œæ•¸èˆ‡åˆ†éš”ç¬¦ï¼‰ã€‚
# - å¼·åŒ– system/dev æç¤ºï¼šåš´ç¦ç°¡é«”å­—ï¼Œä¿ç•™æ•¸å­—/ç¶²å€/emoji/ç¨‹å¼ç‰‡æ®µã€‚
# - è¡Œæ•¸ä¸€è‡´æ€§æª¢æŸ¥èˆ‡å¤±æ•—å›é€€ï¼Œé¿å…èµ°ä½ã€‚
# - ä¿ç•™å››åˆ†é ï¼šè½‰éŒ„çµæœï¼é‡é»æ‘˜è¦ï¼å…§å®¹è§£æï¼åŸå§‹å…§å®¹ã€‚
# - æœªåŠ å…¥ä»»ä½•ã€Œå³æ™‚é‡é»ï¼ˆMap streamingï¼‰ã€UI æˆ–æµç¨‹ã€‚

import os
import re
import json
import difflib
import hashlib
import tempfile
import multiprocessing
from typing import List, Dict, Any

import streamlit as st
from openai import OpenAI
from pydub import AudioSegment, silence
from pydub.utils import which

# ========== åŸºæœ¬è¨­å®š ==========
st.set_page_config(page_title="æœƒè­°éŒ„éŸ³ â†’ ç›´æ’­é€å­—ï¼‹æ‘˜è¦", page_icon="ğŸ“", layout="wide")

# è‡ªè¨‚æ¨£å¼ï¼ˆåŠ å¤§é ‚éƒ¨å…§è·é¿å…æ¨™é¡Œè¢«åˆ‡åˆ°ã€Tabs è¦–è¦ºã€å…§æ–‡å¯è®€æ€§ï¼‰
st.markdown("""
<style>
:root { --brand:#9c2b2f; --brand-weak:#9c2b2fcc; --bg:#FFF6F6; --border:#f2d9d9; }
.main .block-container{padding-top:2.2rem}
.pink-card{background:var(--bg);border:1px solid var(--border);padding:16px 22px;border-radius:12px;margin-bottom:12px;overflow:visible;}
.header-pill{display:flex;align-items:center;gap:12px;font-size:22px;font-weight:700;color:#2f2f2f;line-height:1.35;min-height:48px;}
.header-pill .emoji{font-size:22px;display:inline-block;transform:translateY(1px);}
.stTabs [data-baseweb="tab-list"]{gap:24px;border-bottom:1px solid #f0e2e2;margin-bottom:8px}
.stTabs [data-baseweb="tab"]{padding:10px 2px;color:var(--brand-weak);font-weight:600}
.stTabs [aria-selected="true"]{color:var(--brand);border-bottom:3px solid var(--brand)}
.stMarkdown p{line-height:1.8}
.transcript-readable{font-size:1.02rem;line-height:1.9;letter-spacing:0.02em;}
</style>
""", unsafe_allow_html=True)

# é ‚éƒ¨å¡ç‰‡æ¨™é¡Œ
st.markdown('<div class="pink-card header-pill"><span class="emoji">âœï¸</span> å®‰å¦®äºé–‹æœƒä¸æ¼æ¥ï¼šé€å­— Ã— æ‘˜è¦</div>', unsafe_allow_html=True)

# æª¢æŸ¥ FFmpeg
AudioSegment.converter = which("ffmpeg")
AudioSegment.ffprobe = which("ffprobe")
if not AudioSegment.converter or not AudioSegment.ffprobe:
    st.error("æ‰¾ä¸åˆ° ffmpeg/ffprobeï¼Œè«‹å…ˆæ–¼ç³»çµ±å®‰è£å¾Œå†è©¦ã€‚")
    st.stop()

# è®€å– API Key
OPENAI_KEY = st.secrets.get("OPENAI_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_KEY:
    st.error("æ‰¾ä¸åˆ° API Keyï¼Œè«‹åœ¨ Streamlit Secrets è¨­å®š OPENAI_KEY æˆ–ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEYã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_KEY)

# ========== åƒæ•¸ ==========
MODEL_STT = "gpt-4o-mini-transcribe"  # STT å¿ å¯¦è½‰éŒ„åŸèªè¨€
MODEL_MAP = "gpt-5-mini"              # åˆ†æ®µæ‘˜è¦
MODEL_REDUCE = "gpt-4.1"              # ç¸½æ•´/æ½¤é£¾ï¼ˆrefine èˆ‡å¼·åˆ¶ç¹é«”åŒ–ä¹Ÿç”¨é€™é¡†ï¼‰

# åˆ‡æ®µåƒæ•¸
MIN_SILENCE_LEN_MS = 700
KEEP_SILENCE_MS = 300
SILENCE_DB_OFFSET = 16
OVERLAP_MS = 1200

# ç‰‡æ®µé•·åº¦ä¿è­·èˆ‡å›é€€
MAX_CHUNK_MS = 30_000   # å–®æ®µæœ€é•· 30 ç§’
MIN_CHUNK_MS = 2_000    # å–®æ®µæœ€çŸ­ 2 ç§’
FALLBACK_WINDOW_MS = 20_000  # æ‰¾ä¸åˆ°éœéŸ³æ™‚ï¼Œå›ºå®šåˆ‡ 20 ç§’

DEFAULT_MAP_CHUNK_SIZE = 40
MAX_STREAM_WORKERS = min(4, multiprocessing.cpu_count())

CACHE_DIR = ".stt_cache"
os.makedirs(CACHE_DIR, exist_ok=True)

# ========== å·¥å…·å‡½å¼ ==========
def _hash_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()

def cache_get_text(key: str) -> str | None:
    path = os.path.join(CACHE_DIR, key + ".txt")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    return None

def cache_set_text(key: str, value: str):
    path = os.path.join(CACHE_DIR, key + ".txt")
    with open(path, "w", encoding="utf-8") as f:
        f.write(value)

def convert_to_wav(input_path: str, output_path: str, target_sr=16000):
    audio = AudioSegment.from_file(input_path)
    audio = audio.set_frame_rate(target_sr).set_channels(1)
    audio.export(output_path, format="wav")
    return output_path

def normalize_loudness(audio: AudioSegment, target_dbfs: float = -20.0) -> AudioSegment:
    gain = target_dbfs - audio.dBFS
    return audio.apply_gain(gain)

def trim_leading_silence(audio: AudioSegment, silence_threshold_db: float = -30.0, chunk_ms: int = 10) -> AudioSegment:
    trim_ms = 0
    while trim_ms < len(audio) and audio[trim_ms:trim_ms+chunk_ms].dBFS < silence_threshold_db:
        trim_ms += chunk_ms
    return audio[trim_ms:]

def apply_filters(audio: AudioSegment, use_high_pass: bool = False, hp_hz: int = 100,
                  use_low_pass: bool = False, lp_hz: int = 9500) -> AudioSegment:
    out = audio
    if use_high_pass:
        out = out.high_pass_filter(hp_hz)
    if use_low_pass:
        out = out.low_pass_filter(lp_hz)
    return out

def split_audio_on_silence_safe(audio: AudioSegment) -> List[AudioSegment]:
    silence_thresh = audio.dBFS - SILENCE_DB_OFFSET
    raw_chunks = silence.split_on_silence(
        audio,
        min_silence_len=MIN_SILENCE_LEN_MS,
        silence_thresh=silence_thresh,
        keep_silence=KEEP_SILENCE_MS
    )

    if not raw_chunks:
        chunks = []
        i = 0
        while i < len(audio):
            end = min(i + FALLBACK_WINDOW_MS, len(audio))
            chunks.append(audio[i:end])
            i = end
    else:
        filtered = []
        for c in raw_chunks:
            if len(c) < 250:
                if filtered:
                    filtered[-1] = filtered[-1] + c
                else:
                    filtered.append(c)
            else:
                filtered.append(c)
        if not filtered:
            filtered = raw_chunks

        chunks = []
        for i, c in enumerate(filtered):
            if i == 0:
                chunks.append(c)
            else:
                prev = filtered[i - 1]
                safe_overlap = min(OVERLAP_MS, len(prev))
                if safe_overlap > 0:
                    overlap = prev[-safe_overlap:]
                    chunks.append(overlap + c)
                else:
                    chunks.append(c)

    normalized = []
    for seg in chunks:
        if len(seg) <= MAX_CHUNK_MS:
            normalized.append(seg)
        else:
            start = 0
            while start < len(seg):
                end = min(start + MAX_CHUNK_MS, len(seg))
                normalized.append(seg[start:end])
                start = end

    final_chunks = []
    for seg in normalized:
        if final_chunks and len(seg) < MIN_CHUNK_MS:
            final_chunks[-1] = final_chunks[-1] + seg
        else:
            final_chunks.append(seg)

    return final_chunks

def split_sentences(text: str) -> List[str]:
    parts = re.split(r'([ã€‚ï¼ï¼Ÿï¼›;.!?\n])', text)
    result = []
    for i in range(0, len(parts) - 1, 2):
        s = (parts[i] + parts[i + 1]).strip()
        if s:
            result.append(s)
    if len(parts) % 2 != 0:
        tail = parts[-1].strip()
        if tail:
            result.append(tail)
    return result

def dedupe_against_prev(curr: List[str], prev: List[str], threshold=0.80) -> List[str]:
    out = []
    for s in curr:
        if all(difflib.SequenceMatcher(None, s, p).ratio() <= threshold for p in prev):
            out.append(s)
    return out

def add_cjk_spacing(text: str) -> str:
    text = re.sub(r'([\u4e00-\u9fff])([A-Za-z0-9$%#@&])', r'\1 \2', text)
    text = re.sub(r'([A-Za-z0-9$%#@&])([\u4e00-\u9fff])', r'\1 \2', text)
    return text

def normalize_symbols(text: str) -> str:
    text = text.replace("ï¼…", "%").replace("ï¼„", "$")
    text = text.replace("â€“", "-").replace("â€”", "-")
    text = text.replace("\u200b", "").replace("\u200c", "")
    return text

def pretty_format_sentences(sentences: List[str]) -> List[str]:
    pretty = []
    for s in sentences:
        s2 = add_cjk_spacing(s)
        s2 = normalize_symbols(s2)
        pretty.append(s2)
    return pretty

# ========== é¡¯ç¤ºå±¤ï¼šé€è¡Œã€æ½¤é£¾ï¼‹å¿…è¦æ™‚ç¿»è­¯ã€ç‚ºæ­£é«”ï¼ˆå°ç£ç”¨èªï¼‰ ==========
def refine_zh_tw_via_prompt(lines: List[str]) -> List[str]:
    """
    å°‡å¤šè¡Œå¥å­é€è¡Œã€æ½¤é£¾ï¼‹å¿…è¦æ™‚ç¿»è­¯ã€ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚
    - æ‰¹æ¬¡è™•ç†ï¼‹åˆ†éš”ç¬¦é˜²èµ°ä½ï¼›å–®æ‰¹å¤±æ•—åªå›é€€è©²æ‰¹ï¼Œä¸å½±éŸ¿å…¶ä»–æ‰¹ã€‚
    - äºŒéšæ®µ LLM ä¿éšªï¼šç¬¬ä¸€éšæ®µæ½¤é£¾ï¼Œç¬¬äºŒéšæ®µå¼·åˆ¶ç¹é«”åŒ–ï¼ˆç¶­æŒè¡Œæ•¸èˆ‡åˆ†éš”ç¬¦ âï¼‰ã€‚
    """
    if not lines:
        return lines

    SEP = "\u241E"  # â æ¥µå°‘è¦‹çš„å¯è¦–åˆ†éš”ç¬¦
    MAX_BATCH_CHARS = 9000  # å–®æ‰¹æœ€å¤§å­—æ•¸ï¼ˆä¿å®ˆï¼‰
    MAX_BATCH_LINES = 120   # å–®æ‰¹æœ€å¤šè¡Œæ•¸ï¼ˆä¿å®ˆï¼‰

    sys_rule_stage1 = (
        "è«‹å‹™å¿…ä»¥ã€æ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€è¼¸å‡ºæ¯ä¸€è¡Œï¼›åš´ç¦å‡ºç¾ä»»ä½•ç°¡é«”å­—æˆ–å¤§é™¸ç”¨èªã€‚"
        "è‹¥è¼¸å…¥å«è‹±æ–‡æˆ–æ··èªï¼Œè«‹ç¿»è­¯ç‚ºæ­£é«”ä¸­æ–‡ï¼›ä¿ç•™æ•¸å­—ã€å–®ä½ã€ç¶²å€ã€emojiã€ç¨‹å¼ç‰‡æ®µã€‚"
        "ä¸å¯åˆä½µã€åˆªé™¤æˆ–æ–°å¢è¡Œï¼›è¼¸å…¥å¹¾è¡Œå°±è¼¸å‡ºå¹¾è¡Œï¼Œä¸¦ä»¥ â åˆ†éš”ã€‚"
        "å¸¸è¦‹ç”¨å­—ï¼šè³‡è¨Š/é¢¨éšª/é ç®—/é‡Œç¨‹ç¢‘/ç’°è©•/æ»¯æ´ª/æŠ½æ°´ç«™ï¼ˆé¿å…ï¼šä¿¡æ¯/é£é™©/é¢„ç®—/é‡Œç¨‹ç¢‘(ç°¡å­—)/ç¯è¯„/æ»æ´ª(ç°¡å­—)/æŠ½æ°´ç«™(ç°¡å­—)ï¼‰ã€‚"
    )

    sys_rule_stage2 = (
        "å°‡ä½¿ç”¨è€…æä¾›çš„æ–‡æœ¬é€è¡Œã€è½‰æ›ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰å­—å½¢èˆ‡ç”¨è©ã€ã€‚"
        "åš´æ ¼è¦å‰‡ï¼š\n"
        "1) åªè®Šæ›å­—å½¢èˆ‡ç”¨è©ç‚ºå°ç£æ…£ç”¨ï¼Œä¸å¾—æ”¹å‹•èªæ„ã€æ•¸å­—ã€æ¨™é»ã€ç¶²å€ã€emojiã€‚\n"
        "2) ä¸å¾—å¢åˆªæˆ–åˆä½µä»»ä½•ä¸€è¡Œï¼›è¼¸å…¥å¹¾è¡Œè¼¸å‡ºå¹¾è¡Œï¼›ä»¥ â ä½œç‚ºè¡Œåˆ†éš”ï¼Œå‹™å¿…ä¿ç•™ç›¸åŒæ•¸é‡çš„åˆ†éš”ç¬¦ã€‚\n"
        "3) åš´ç¦è¼¸å‡ºç°¡é«”å­—æˆ–å¤§é™¸åœ°å€ç”¨èªã€‚"
    )

    def _stage1_refine(batch: List[str]) -> List[str]:
        blob = SEP.join(batch)
        dev_msg = (
            "ä½ å°‡æ”¶åˆ°å¤šè¡Œé€å­—ç¨¿ï¼Œè«‹é€è¡Œã€æ½¤é£¾ï¼‹å¿…è¦æ™‚ç¿»è­¯ã€ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚\n"
            "è¦æ±‚ï¼š\n"
            "1) ä¿ç•™åŸæ„ï¼Œåªåšèªå¥æ½¤é£¾èˆ‡æ­£é«”ç¿»è­¯ï¼Œä¸å¾—æé€ è³‡è¨Šã€‚\n"
            "2) è‹¥è©²è¡Œæ˜¯è‹±æ–‡æˆ–æ··é›œèªè¨€ï¼Œç¿»è­¯ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚\n"
            "3) åš´ç¦åˆä½µ/æ‹†åˆ†è¡Œï¼›åš´ç¦æ’å…¥æˆ–åˆªé™¤ç©ºè¡Œï¼›è¼¸å…¥å¹¾è¡Œå°±è¼¸å‡ºå¹¾è¡Œã€‚\n"
            "4) ä¿ç•™æ•¸å­—ã€å–®ä½ã€æ™‚é–“ã€é‡‘é¡ã€emojiã€ç¶²å€ã€ç°¡çŸ­ä»£ç¢¼ç‰‡æ®µç­‰éèªæ„å…§å®¹ã€‚\n"
            "5) ç”¨è©æ¡å°ç£æ…£ç”¨ã€å£å»ç°¡æ½”å°ˆæ¥­è‡ªç„¶ã€‚\n"
            "6) è¡Œèˆ‡è¡Œç”±ç‰¹æ®Šåˆ†éš”ç¬¦ âï¼ˆU+241Eï¼‰é€£æ¥ï¼›è«‹å‹™å¿…ä¿ç•™ç›¸åŒæ•¸é‡çš„åˆ†éš”ç¬¦ï¼Œä¸å¯æ–°å¢æˆ–ç§»é™¤ã€‚\n"
            "åªè¼¸å‡ºæœ€çµ‚æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡‹ã€‚"
        )
        try:
            resp = client.responses.create(
                model=MODEL_REDUCE,
                input=[
                    {"role": "system", "content": [{"type": "input_text", "text": sys_rule_stage1}]},
                    {"role": "developer", "content": [{"type": "input_text", "text": dev_msg}]},
                    {"role": "user", "content": [{"type": "input_text", "text": blob}]},
                ],
                text={"format": {"type": "text"}},
                tools=[],
            )
            out = (resp.output_text or "").rstrip("\n")
            out_lines = out.split(SEP) if SEP in out else out.split("\n")
            return out_lines if len(out_lines) == len(batch) else batch
        except Exception:
            return batch

    def _stage2_force_tw(batch: List[str]) -> List[str]:
        """
        ç¬¬äºŒéšï¼šåƒ…å°‡å­—å½¢/ç”¨èªçµ±ä¸€ç‚ºå°ç£æ­£é«”ï¼›ä¸å‹•è¡Œæ•¸ã€ä¸å‹•çµæ§‹ã€‚
        """
        blob = SEP.join(batch)
        try:
            resp = client.responses.create(
                model=MODEL_REDUCE,
                input=[
                    {"role": "system", "content": [{"type": "input_text", "text": sys_rule_stage2}]},
                    {"role": "user", "content": [{"type": "input_text", "text": blob}]},
                ],
                text={"format": {"type": "text"}},
                tools=[],
            )
            out = (resp.output_text or "").rstrip("\n")
            out_lines = out.split(SEP) if SEP in out else out.split("\n")
            return out_lines if len(out_lines) == len(batch) else batch
        except Exception:
            return batch

    # åˆ†æ‰¹è™•ç†ï¼ˆå…©éšæ®µï¼‰
    refined_all: List[str] = []
    batch: List[str] = []
    size = 0
    for s in lines:
        if (len(batch) >= MAX_BATCH_LINES) or (size + len(s) + 1 > MAX_BATCH_CHARS):
            first = _stage1_refine(batch)
            second = _stage2_force_tw(first)
            refined_all.extend(second)
            batch, size = [], 0
        batch.append(s)
        size += len(s) + 1
    if batch:
        first = _stage1_refine(batch)
        second = _stage2_force_tw(first)
        refined_all.extend(second)

    return refined_all if refined_all else lines

# Promptï¼ˆè‹¥ç«¯é»æ”¯æ´å°±ç”¨ã€ä¸æ”¯æ´è‡ªå‹•å›é€€ï¼‰
def build_prompt(prev_text: str, glossary: str, style_seed: str, max_tokens: int = 220) -> str:
    parts = []
    parts.append("è«‹å…¨ç¨‹ä½¿ç”¨æ­£é«”ä¸­æ–‡ï¼ˆç¹é«”ï¼Œå°ç£ç”¨èªï¼‰ã€‚")
    if style_seed and style_seed.strip():
        parts.append(style_seed.strip())
    if glossary and glossary.strip():
        words = [w.strip() for w in glossary.splitlines() if w.strip()]
        if words:
            parts.append("Glossary: " + ", ".join(words))
    if prev_text and prev_text.strip():
        tail = prev_text.strip()
        if len(tail) > 1200:
            tail = tail[-1200:]
        parts.append(tail)

    prompt = "\n".join(parts).strip()
    toks = prompt.split()
    if len(toks) > max_tokens:
        prompt = " ".join(toks[-max_tokens:])
    return prompt

def stream_transcribe_all(
    chunks: List[AudioSegment],
    container,
    progress_bar,
    use_prompting: bool = False,
    glossary: str = "",
    style_seed: str = ""
):
    import time
    all_text = ""
    rolling_context = ""
    last_flush = 0.0
    FLUSH_INTERVAL = 0.15

    for i, chunk in enumerate(chunks):
        chunk_hash = _hash_bytes(chunk.raw_data)
        cache_key = f"stt_{MODEL_STT}_{chunk_hash}"
        cached = cache_get_text(cache_key)
        if cached:
            all_text += cached + "\n"
            rolling_context = (rolling_context + " " + cached).strip()
            if len(rolling_context) > 5000:
                rolling_context = rolling_context[-5000:]
            progress_bar.progress((i + 1) / len(chunks))
            container.markdown(all_text)
            continue

        full_text = ""
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                tmp_path = tmp.name
                chunk.export(tmp_path, format="wav", parameters=["-ac", "1", "-ar", "16000"])
            with open(tmp_path, "rb") as audio_file:
                extra_kwargs = {}
                if use_prompting:
                    prompt_str = build_prompt(rolling_context, glossary, style_seed, max_tokens=220)
                    if prompt_str:
                        extra_kwargs["prompt"] = prompt_str

                try:
                    stream = client.audio.transcriptions.create(
                        model=MODEL_STT,
                        file=audio_file,
                        response_format="text",
                        prompt=(
                            "This audio contains a discussion or presentation. "
                            "Always preserve the original language of each sentence. "
                            "If a sentence is in English, output it in English; "
                            "if in Chinese, output it in Traditional Chinese; "
                            "if mixed, output the original mixed-language sentence. "
                            "Do not translate or alter the language. "
                            "The audio may cover various topics such as updates, feedback, or informative lectures."
                        ),
                        stream=True,
                        **extra_kwargs
                    )
                except Exception:
                    try:
                        stream = client.audio.transcriptions.create(
                            model=MODEL_STT,
                            file=audio_file,
                            response_format="text",
                            prompt=(
                                "This audio contains a discussion or presentation. "
                                "Always preserve the original language of each sentence. "
                                "If a sentence is in English, output it in English; "
                                "if in Chinese, output it in Traditional Chinese; "
                                "if mixed, output the original mixed-language sentence. "
                                "Do not translate or alter the language. "
                                "The audio may cover various topics such as updates, feedback, or informative lectures."
                            ),
                            stream=True
                        )
                        container.warning("æ­¤è½‰éŒ„ç«¯é»ä¸æ”¯æ´ promptï¼Œå¼•å°å·²è‡ªå‹•åœç”¨ï¼ˆæœ¬æ¬¡ï¼‰ã€‚")
                    except Exception as e2:
                        container.error(f"API è½‰éŒ„å¤±æ•—ï¼š{e2}")
                        stream = None

                if stream is not None:
                    for event in stream:
                        delta = getattr(event, "delta", None)
                        final_text = getattr(event, "text", None)
                        if delta:
                            full_text += delta
                            now = time.time()
                            if now - last_flush > FLUSH_INTERVAL:
                                container.markdown(all_text + full_text)
                                last_flush = now
                        elif final_text:
                            full_text = final_text
                            container.markdown(all_text + full_text)
        finally:
            if tmp_path:
                try:
                    os.remove(tmp_path)
                except Exception:
                    pass

        cache_set_text(cache_key, full_text.strip())
        all_text += full_text + "\n"

        rolling_context = (rolling_context + " " + full_text).strip()
        if len(rolling_context) > 5000:
            rolling_context = rolling_context[-5000:]

        progress_bar.progress((i + 1) / len(chunks))
        container.markdown(all_text)

    return all_text.strip()

# ========== Map-Reduceï¼ˆGPTâ€‘5 + Responses APIï¼‰==========
def map_summarize_blocks(flat_sentences: List[str], chunk_size=DEFAULT_MAP_CHUNK_SIZE) -> List[str]:
    blocks = []
    for idx in range(0, len(flat_sentences), chunk_size):
        part = flat_sentences[idx: idx + chunk_size]
        dev_msg = (
            "ä½ æ˜¯ä¸€ä½æœƒè­°è¨˜éŒ„å°å¹«æ‰‹ï¼Œè«‹å°‡ä¸‹åˆ—é€å­—ç¨¿æ•´ç†ç‚ºæ¢åˆ—å¼é‡é»ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚"
            "è¦æ±‚ï¼šæ¯é»å…·é«”ã€é¿å…ç©ºæ³›ï¼›è‹¥æœ‰æ±ºç­–/é¢¨éšª/æœªæ±ºå•é¡Œ/è¡Œå‹•é …ç›®è«‹æ¸…æ¥šæ¨™è¨˜ï¼›"
            "åªè¼¸å‡ºæ¢åˆ—é‡é»ï¼Œä¸è¦é¡å¤–èªªæ˜ã€‚"
        )
        user_msg = "\n".join(part)
        try:
            resp = client.responses.create(
                model=MODEL_MAP,
                input=[
                    {"role": "developer", "content": [{"type": "input_text", "text": dev_msg}]},
                    {"role": "user", "content": [{"type": "input_text", "text": user_msg}]},
                ],
                text={"format": {"type": "text"}},
                tools=[],
            )
            content = resp.output_text or ""
            blocks.append(content.strip())
        except Exception as e:
            blocks.append(f"ã€API æ‘˜è¦å¤±æ•—ï¼š{e}ã€‘")
    return blocks

def reduce_finalize_json(map_blocks: List[str]) -> Dict[str, Any]:
    dev_msg = (
        "ä½ æ˜¯æœƒè­°è¨˜éŒ„ç¸½æ•´å°ˆå®¶ã€‚è«‹å°‡å¤šå€‹åˆ†æ®µæ‘˜è¦åˆä½µæˆçµæ§‹åŒ– JSONï¼ŒåŒ…å«ï¼š\n"
        "- metadata: {title, date, location, participants[], duration}\n"
        "- topics[]: {title, key_points[], decisions[], risks[], open_questions[]}\n"
        "- decisions[]\n"
        "- risks[]\n"
        "- open_questions[]\n"
        "- action_items[]: {description, owner|null, due_date|null, priority|null (P0~P3), status, source_refs[]}\n"
        "- overall_summary: string\n"
        "è¦æ±‚ï¼š\n"
        "1) åš´ç¦æé€ ä¾†æºæ²’æœ‰çš„è³‡è¨Šï¼›æœªçŸ¥æ¬„ä½è«‹ç•™ç©ºæˆ– Unknownã€‚\n"
        "2) å»é‡ã€åˆä½µç›¸è¿‘é‡é»ï¼Œä½†ä¸å¾—æ”¹è®ŠåŸæ„ã€‚\n"
        "3) åªè¼¸å‡º JSON ç‰©ä»¶ï¼Œä¸è¦é¡å¤–èªªæ˜æ–‡å­—ã€‚\n"
        "4) ç¢ºä¿ç‚ºåˆæ³• JSONã€‚\n\n"
        "=== åˆ†æ®µæ‘˜è¦ ===\n"
        + "\n\n".join(f"[Part {i+1}]\n{blk}" for i, blk in enumerate(map_blocks))
    )
    try:
        resp = client.responses.create(
            model=MODEL_REDUCE,
            input=[{"role": "developer", "content": [{"type": "input_text", "text": dev_msg}]}],
            text={"format": {"type": "text"}},
            tools=[],
        )
        s = (resp.output_text or "").strip()
        start = s.find("{")
        end = s.rfind("}")
        if start != -1 and end != -1:
            s = s[start:end+1]
        return json.loads(s)
    except Exception as e:
        return {"overall_summary": f"è§£æ JSON å¤±æ•—ï¼Œè«‹é‡è©¦æˆ–èª¿æ•´æç¤ºã€‚éŒ¯èª¤ï¼š{e}", "raw": ""}

def reduce_finalize_markdown(map_blocks: List[str]) -> str:
    dev_msg = (
        "ä½ æ˜¯æœƒè­°è¨˜éŒ„ç¸½æ•´å°ˆå®¶ã€‚è«‹å°‡å¤šå€‹åˆ†æ®µæ‘˜è¦æ•´ä½µç‚ºã€å–®ä¸€ä»½æœ€çµ‚æœƒè­°è¨˜éŒ„ï¼ˆMarkdownï¼‰ã€ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1) åƒ…æ ¹æ“šæä¾›çš„åˆ†æ®µæ‘˜è¦æ•´ä½µï¼Œåš´ç¦æé€ ä¾†æºæ²’æœ‰çš„è³‡è¨Šã€‚\n"
        "2) ä¸è¼¸å‡º metadataï¼ˆæ¨™é¡Œ/æ—¥æœŸ/åœ°é»/åƒèˆ‡è€…/æ™‚é•·ï¼‰ï¼Œåªè¦å…§å®¹æœ¬é«”ã€‚\n"
        "3) çµæ§‹ï¼š\n"
        "   - ä»¥ä¸€æ®µã€Œç¸½çµã€é–‹å ´ï¼Œ3~6 å¥ï¼Œèªªæ¸…æ¥šæ•´é«”è„ˆçµ¡èˆ‡çµè«–ã€‚\n"
        "   - ä¹‹å¾Œç”¨å¤šå€‹å°ç¯€ï¼ˆ## ä¸»é¡Œåç¨±ï¼‰ï¼Œæ¯ç¯€æ¡ç”¨çŸ­æ®µè½æ•˜è¿°ç‚ºä¸»ï¼Œå¯ç©¿æ’å°‘é‡æ¢åˆ—ã€‚\n"
        "   - è‹¥æœ‰æ±ºç­–/é¢¨éšª/æœªæ±ºå•é¡Œï¼Œæ–¼å°æ‡‰ä¸»é¡Œå…§ä»¥ã€æ±ºç­–ï¼šã€ã€é¢¨éšªï¼šã€ã€æœªæ±ºï¼šã€è¡Œå…§æ¨™ç¤ºã€‚\n"
        "4) åªè¼¸å‡ºç´” Markdown å…§å®¹ï¼Œä¸è¦é¡å¤–èªªæ˜ã€‚"
        "\n\n=== åˆ†æ®µæ‘˜è¦ ===\n"
        + "\n\n".join(f"[Part {i+1}]\n{blk}" for i, blk in enumerate(map_blocks))
    )
    try:
        resp = client.responses.create(
            model=MODEL_REDUCE,
            input=[{"role": "developer", "content": [{"type": "input_text", "text": dev_msg}]}],
            text={"format": {"type": "text"}},
            tools=[],
        )
        return (resp.output_text or "").strip()
    except Exception as e:
        return f"âš ï¸ ç”Ÿæˆæœƒè­°æ‘˜è¦å¤±æ•—ï¼š{e}"

# é¡¯ç¤ºæ¨¡å¼å·¥å…·ï¼šæ®µè½ç¾¤çµ„ï¼ˆåƒ…ä¿ç•™æ®µè½æ¨¡å¼ç”¨ï¼‰
def group_into_paragraphs(sentences: List[str], max_chars: int = 260, max_sents: int = 4) -> List[str]:
    paras, cur, length = [], [], 0
    for s in sentences:
        s = s.strip()
        if not s:
            continue
        if cur and (len(cur) >= max_sents or length + len(s) > max_chars):
            paras.append(" ".join(cur))
            cur, length = [s], len(s)
        else:
            cur.append(s)
            length += len(s)
    if cur:
        paras.append(" ".join(cur))
    return paras

def render_topics_only(md: Dict[str, Any], st):
    st.markdown("#### ä¸»é¡Œ")
    topics = md.get("topics", [])
    for t in topics:
        st.markdown(f"##### {t.get('title','ä¸»é¡Œ')}")
        kp = t.get("key_points", [])
        if kp:
            st.markdown("\n".join(f"- {x}" for x in kp))
        if t.get("decisions"):
            st.markdown("æ±ºç­–ï¼š\n" + "\n".join(f"- {x}" for x in t.get("decisions", [])))
        if t.get("risks"):
            st.markdown("é¢¨éšªï¼š\n" + "\n".join(f"- {x}" for x in t.get("risks", [])))
        if t.get("open_questions"):
            st.markdown("æœªæ±ºå•é¡Œï¼š\n" + "\n".join(f"- {x}" for x in t.get("open_questions", [])))

# ========== ä¸Šå‚³å€ ==========
with st.expander("ä¸Šå‚³æœƒè­°éŒ„éŸ³æª”æ¡ˆ", expanded=True):
    f = st.file_uploader("è«‹ä¸Šå‚³éŸ³æª”ï¼ˆ.wav, .mp3, .m4a, .mp4, .webmï¼‰", type=["wav", "mp3", "m4a", "mp4", "webm"])
    start_btn = st.button("é–‹å§‹ Streaming è½‰éŒ„èˆ‡æ‘˜è¦")

# ========== å–®ä¸€æ•´é«”æ”¶åˆçš„é€²éšèª¿æ•´ ==========
with st.expander("é€²éšèª¿æ•´ï¼ˆå…¨éƒ¨è¨­å®šï¼Œå¯é¸ï¼‰", expanded=False):
    st.caption("å¹³å¸¸ç¶­æŒé è¨­å³å¯ï¼›åªæœ‰éŸ³æª”ç‰¹æ€§ç‰¹æ®Šæ™‚å†é–‹å•Ÿã€‚")

    st.markdown("###### éŸ³è¨Šå‰è™•ç†")
    cols = st.columns(2)
    with cols[0]:
        do_trim_leading = st.checkbox("å»å‰å°éœéŸ³ï¼ˆå»ºè­°é–‹ï¼‰", value=True)
        do_normalize = st.checkbox("éŸ³é‡æ­£è¦åŒ–åˆ° -20 dBFSï¼ˆå»ºè­°é–‹ï¼‰", value=True)
    with cols[1]:
        use_high_pass = st.checkbox("é«˜é€šæ¿¾æ³¢ï¼ˆé™ä½ä½é »å™ªï¼‰", value=False)
        hp_hz = st.slider("é«˜é€šæˆªæ­¢é »ç‡ (Hz)", 60, 300, 100, 10, disabled=not use_high_pass)
        use_low_pass = st.checkbox("ä½é€šæ¿¾æ³¢ï¼ˆé™é«˜é »å™ªï¼‰", value=False)
        lp_hz = st.slider("ä½é€šæˆªæ­¢é »ç‡ (Hz)", 4000, 12000, 9500, 100, disabled=not use_low_pass)

    st.markdown("###### Prompt å¼•å°ï¼ˆè‹¥ç«¯é»ä¸æ”¯æ´æœƒè‡ªå‹•å›é€€ï¼‰")
    use_prompting = st.checkbox("å•Ÿç”¨ Prompt å¼•å°ï¼ˆæ”¹å–„å°ˆæœ‰åè©æ‹¼å¯«èˆ‡é¢¨æ ¼ä¸€è‡´ï¼‰", value=False)
    glossary_input = st.text_area(
        "å°ˆæœ‰åè©æ‹¼å¯«æ¸…å–®ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
        height=120,
        placeholder="ä¾‹ï¼š\nAimee\nShawn\nBBQ\nZyntriQix",
        disabled=not use_prompting
    )
    style_seed = st.text_area(
        "é¢¨æ ¼ç¤ºä¾‹ï¼ˆ1ï½3 å¥ç¤ºä¾‹æ–‡æœ¬ï¼Œä¸æ˜¯æŒ‡ä»¤ï¼‰",
        height=80,
        placeholder="ä¾‹ï¼š\nä¿æŒç°¡æ½”ã€æ¨™é»ä¸€è‡´ã€‚ä¾‹å¥ï¼šwe discuss quarterly outlook and risks.",
        disabled=not use_prompting
    )

if not (f and start_btn):
    st.stop()

# ========== ä¸»æµç¨‹ ==========
raw_bytes = f.read()
st.audio(raw_bytes)

# Tabs
tab1, tab2, tab3, tab4 = st.tabs(["è½‰éŒ„çµæœ", "é‡é»æ‘˜è¦", "å…§å®¹è§£æ", "åŸå§‹å…§å®¹"])

with tab1:
    with st.status("è™•ç†ä¸­...", expanded=True) as status:
        status.update(label="å„²å­˜èˆ‡è½‰æª”...")
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{f.name.split('.')[-1]}") as temp_input:
            temp_input.write(raw_bytes)
            temp_input_path = temp_input.name

        wav_path = temp_input_path
        if not f.name.lower().endswith(".wav"):
            wav_path = temp_input_path + ".wav"
            convert_to_wav(temp_input_path, wav_path)

        status.update(label="è¼‰å…¥éŸ³æª”èˆ‡å‰è™•ç†...")
        audio = AudioSegment.from_file(wav_path, format="wav")
        if do_trim_leading:
            audio = trim_leading_silence(audio, silence_threshold_db=-30.0, chunk_ms=10)
        if do_normalize:
            audio = normalize_loudness(audio, target_dbfs=-20.0)
        if use_high_pass or use_low_pass:
            audio = apply_filters(audio, use_high_pass=use_high_pass, hp_hz=hp_hz, use_low_pass=use_low_pass, lp_hz=lp_hz)

        status.update(label="éœéŸ³åˆ‡æ®µï¼ˆé™„æœ€é•·/æœ€çŸ­ä¿è­·ï¼›æ‰¾ä¸åˆ°éœéŸ³æœƒå›é€€å›ºå®šåˆ‡ï¼‰...")
        chunks = split_audio_on_silence_safe(audio)
        if not chunks:
            st.error("ç„¡æ³•åˆ‡å‡ºæœ‰æ•ˆéŸ³è¨Šæ®µï¼Œè«‹æª¢æŸ¥éŸ³æª”æˆ–èª¿æ•´åƒæ•¸ã€‚")
            st.stop()

        st.markdown("#### è½‰éŒ„çµæœ")
        stream_container = st.empty()
        progress_bar = st.progress(0.0)

        status.update(label="é€æ®µ Streaming è½‰éŒ„ä¸­...")
        all_text = stream_transcribe_all(
            chunks,
            stream_container,
            progress_bar,
            use_prompting=use_prompting,
            glossary=glossary_input if use_prompting else "",
            style_seed=style_seed if use_prompting else ""
        )
        raw_stream_text = all_text.strip()

        status.update(label="åˆ†å¥èˆ‡è·¨æ®µå»é‡...")
        grouped_sentences = []
        for i, txt in enumerate(all_text.split("\n")):
            sents = split_sentences(txt)
            if i == 0:
                grouped_sentences.append(sents)
            else:
                unique = dedupe_against_prev(sents, grouped_sentences[-1], threshold=0.80)
                grouped_sentences.append(unique)
        flat_sentences = [s for group in grouped_sentences for s in group]

        # å¯è®€ç‰ˆï¼šè¼•é‡æ•´ç† â†’ æ½¤é£¾/ç¿»è­¯ç‚ºæ­£é«”ï¼ˆå°ç£ï¼‰â†’ æ®µè½åŒ– â†’ Markdown å‘ˆç¾ï¼ˆç›´æ¥è¦†è“‹ç›´æ’­å®¹å™¨ï¼Œé¿å…ç©ºçª—ï¼‰
        pretty_lines = pretty_format_sentences(flat_sentences)
        refined_lines = refine_zh_tw_via_prompt(pretty_lines)

        paras = group_into_paragraphs(refined_lines, max_chars=280, max_sents=4)
        final_md = "\n\n".join(paras)
        stream_container.markdown(final_md)

        st.success("Transcription complete!")

        status.update(label="æ•´ä½µé‡é»ï¼ˆå…§éƒ¨è¨ˆç®—ï¼‰...")
        map_blocks_text = map_summarize_blocks(flat_sentences)

        status.update(label="ç”Ÿæˆæœ€çµ‚æœƒè­°æ‘˜è¦èˆ‡å…§å®¹è§£æ...")
        final_minutes = reduce_finalize_json(map_blocks_text)
        final_md_summary = reduce_finalize_markdown(map_blocks_text)

        with tab2:
            st.markdown(final_md_summary)
            st.download_button(
                "ä¸‹è¼‰æœƒè­°è¨˜éŒ„ JSON",
                data=json.dumps(final_minutes, ensure_ascii=False, indent=2),
                file_name="meeting_minutes.json",
                mime="application/json"
            )

        with tab3:
            render_topics_only(final_minutes, st)

        with tab4:
            st.markdown("#### åŸå§‹å…§å®¹ï¼ˆæœ€åŸå§‹ä¸²æµè¼¸å‡ºï¼Œæœªåˆ†å¥ï¼æœªå»é‡ï¼‰")
            st.code(raw_stream_text, language="text")

        status.update(label="å…¨éƒ¨å®Œæˆï¼", state="complete", expanded=True)

# æ¸…ç†æš«å­˜
try:
    os.remove(temp_input_path)
    if 'wav_path' in locals() and wav_path != temp_input_path:
        os.remove(wav_path)
except Exception:
    pass
