import os
import re
import json
import difflib
import hashlib
import tempfile
import multiprocessing
from typing import List, Dict, Any

import streamlit as st
from openai import OpenAI
from pydub import AudioSegment, silence
from pydub.utils import which

# ========== åŸºæœ¬è¨­å®š ==========
st.set_page_config(page_title="æœƒè­°éŒ„éŸ³ â†’ ç›´æ’­é€å­—ï¼‹æ‘˜è¦", page_icon="ğŸ“", layout="wide")

# è‡ªè¨‚æ¨£å¼ï¼ˆç²‰ç²‰å¡ç‰‡ã€Tabs è¦–è¦ºï¼‰
st.markdown("""
<style>
:root { --brand:#9c2b2f; --brand-weak:#9c2b2fcc; --bg:#FFF6F6; --border:#f2d9d9; }
.pink-card{background:var(--bg);border:1px solid var(--border);padding:14px 18px;border-radius:12px;}
.header-pill{display:flex;align-items:center;gap:12px;font-size:22px;font-weight:600;color:#2f2f2f;}
.header-pill .emoji{font-size:22px}
.success-card{display:flex;align-items:center;gap:10px;font-weight:600;color:#2f2f2f;}
/* Tabs */
.stTabs [data-baseweb="tab-list"]{gap:24px;border-bottom:1px solid #f0e2e2;margin-bottom:8px}
.stTabs [data-baseweb="tab"]{padding:10px 2px;color:var(--brand-weak);font-weight:600}
.stTabs [aria-selected="true"]{color:var(--brand);border-bottom:3px solid var(--brand)}
/* è®“æ®µè½æ›´å¥½è®€ */
.block-container{padding-top:1.2rem}
.stMarkdown p{line-height:1.75}
</style>
""", unsafe_allow_html=True)

# é ‚éƒ¨å¡ç‰‡æ¨™é¡Œ
st.markdown('<div class="pink-card header-pill"><span class="emoji">ğŸ’‹</span> Speech to text transcription</div>', unsafe_allow_html=True)

# æª¢æŸ¥ FFmpeg
AudioSegment.converter = which("ffmpeg")
AudioSegment.ffprobe = which("ffprobe")
if not AudioSegment.converter or not AudioSegment.ffprobe:
    st.error("æ‰¾ä¸åˆ° ffmpeg/ffprobeï¼Œè«‹å…ˆæ–¼ç³»çµ±å®‰è£å¾Œå†è©¦ã€‚")
    st.stop()

# è®€å– API Key
OPENAI_KEY = st.secrets.get("OPENAI_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_KEY:
    st.error("æ‰¾ä¸åˆ° API Keyï¼Œè«‹åœ¨ Streamlit Secrets è¨­å®š OPENAI_KEY æˆ–ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEYã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_KEY)

# ========== åƒæ•¸ ==========
MODEL_STT = "gpt-4o-mini-transcribe"
MODEL_MAP = "gpt-4.1"
MODEL_REDUCE = "gpt-4.1"
DEFAULT_MAP_CHUNK_SIZE = 40
MIN_SILENCE_LEN_MS = 700
KEEP_SILENCE_MS = 300
SILENCE_DB_OFFSET = 16
OVERLAP_MS = 1200
MAX_STREAM_WORKERS = min(4, multiprocessing.cpu_count())

CACHE_DIR = ".stt_cache"
os.makedirs(CACHE_DIR, exist_ok=True)

# ========== å·¥å…·å‡½å¼ ==========
def _hash_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()

def cache_get_text(key: str) -> str | None:
    path = os.path.join(CACHE_DIR, key + ".txt")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    return None

def cache_set_text(key: str, value: str):
    path = os.path.join(CACHE_DIR, key + ".txt")
    with open(path, "w", encoding="utf-8") as f:
        f.write(value)

def convert_to_wav(input_path: str, output_path: str, target_sr=16000):
    audio = AudioSegment.from_file(input_path)
    audio = audio.set_frame_rate(target_sr).set_channels(1)
    audio.export(output_path, format="wav")
    return output_path

def split_audio_on_silence_safe(audio: AudioSegment) -> List[AudioSegment]:
    silence_thresh = audio.dBFS - SILENCE_DB_OFFSET
    raw_chunks = silence.split_on_silence(
        audio,
        min_silence_len=MIN_SILENCE_LEN_MS,
        silence_thresh=silence_thresh,
        keep_silence=KEEP_SILENCE_MS
    )
    if not raw_chunks:
        return []
    filtered = []
    for c in raw_chunks:
        if len(c) < 250:
            if filtered:
                filtered[-1] = filtered[-1] + c
            else:
                filtered.append(c)
        else:
            filtered.append(c)
    if not filtered:
        return []
    chunks = []
    for i, c in enumerate(filtered):
        if i == 0:
            chunks.append(c)
        else:
            prev = filtered[i - 1]
            safe_overlap = min(OVERLAP_MS, len(prev))
            if safe_overlap > 0:
                overlap = prev[-safe_overlap:]
                chunks.append(overlap + c)
            else:
                chunks.append(c)
    return chunks

def split_sentences(text: str) -> List[str]:
    parts = re.split(r'([ã€‚ï¼ï¼Ÿï¼›\n])', text)
    result = []
    for i in range(0, len(parts) - 1, 2):
        s = (parts[i] + parts[i + 1]).strip()
        if s:
            result.append(s)
    if len(parts) % 2 != 0:
        tail = parts[-1].strip()
        if tail:
            result.append(tail)
    return result

def dedupe_against_prev(curr: List[str], prev: List[str], threshold=0.80) -> List[str]:
    out = []
    for s in curr:
        if all(difflib.SequenceMatcher(None, s, p).ratio() <= threshold for p in prev):
            out.append(s)
    return out

def stream_transcribe_all(chunks: List[AudioSegment], container, progress_bar):
    import time
    all_text = ""
    last_flush = 0.0
    FLUSH_INTERVAL = 0.15  # 150ms ç¯€æµ

    for i, chunk in enumerate(chunks):
        chunk_hash = _hash_bytes(chunk.raw_data)
        cache_key = f"stt_{MODEL_STT}_{chunk_hash}"  # åŒ…å«æ¨¡å‹åï¼Œé¿å…æ±™æŸ“
        cached = cache_get_text(cache_key)
        if cached:
            all_text += cached + "\n"
            progress_bar.progress((i + 1) / len(chunks))
            container.markdown(all_text)
            continue

        full_text = ""
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                tmp_path = tmp.name
                chunk.export(tmp_path, format="wav", parameters=["-ac", "1", "-ar", "16000"])
            with open(tmp_path, "rb") as audio_file:
                try:
                    stream = client.audio.transcriptions.create(
                        model=MODEL_STT,
                        file=audio_file,
                        response_format="text",
                        stream=True
                    )
                    for event in stream:
                        delta = getattr(event, "delta", None)
                        final_text = getattr(event, "text", None)
                        if delta:
                            full_text += delta
                            now = time.time()
                            if now - last_flush > FLUSH_INTERVAL:
                                container.markdown(all_text + full_text)
                                last_flush = now
                        elif final_text:
                            full_text = final_text
                            container.markdown(all_text + full_text)
                except Exception as e:
                    container.error(f"API è½‰éŒ„å¤±æ•—ï¼š{e}")
        finally:
            if tmp_path:
                try:
                    os.remove(tmp_path)
                except Exception:
                    pass

        cache_set_text(cache_key, full_text.strip())
        all_text += full_text + "\n"
        progress_bar.progress((i + 1) / len(chunks))
        container.markdown(all_text)

    return all_text.strip()

def map_summarize_blocks(flat_sentences: List[str], chunk_size=DEFAULT_MAP_CHUNK_SIZE) -> List[str]:
    blocks = []
    for idx in range(0, len(flat_sentences), chunk_size):
        part = flat_sentences[idx: idx + chunk_size]
        prompt = (
            "ä½ æ˜¯ä¸€ä½æœƒè­°è¨˜éŒ„å°å¹«æ‰‹ï¼Œè«‹å°‡ä¸‹åˆ—é€å­—ç¨¿æ•´ç†ç‚ºæ¢åˆ—å¼é‡é»ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ï¼š\n"
            "- æ¯é»ç›¡é‡å…·é«”ï¼Œé¿å…ç©ºæ³›\n"
            "- è‹¥æœ‰æ±ºç­–/é¢¨éšª/æœªæ±ºå•é¡Œ/è¡Œå‹•é …ç›®ï¼Œè«‹æ¸…æ¥šæ¨™è¨˜\n"
            "- åƒ…è¼¸å‡ºæ¢åˆ—é‡é»ï¼Œä¸è¦é¡å¤–èªªæ˜\n\n"
            + "\n".join(part)
        )
        try:
            resp = client.chat.completions.create(
                model=MODEL_MAP,
                messages=[{"role": "user", "content": prompt}]
            )
            content = resp.choices[0].message.content
            blocks.append(content.strip())
        except Exception as e:
            blocks.append(f"ã€API æ‘˜è¦å¤±æ•—ï¼š{e}ã€‘")
    return blocks

def reduce_finalize_json(map_blocks: List[str]) -> Dict[str, Any]:
    prompt = (
        "ä½ æ˜¯æœƒè­°è¨˜éŒ„ç¸½æ•´å°ˆå®¶ã€‚è«‹å°‡å¤šå€‹åˆ†æ®µæ‘˜è¦åˆä½µæˆçµæ§‹åŒ– JSONï¼ŒåŒ…å«ï¼š\n"
        "- metadata: {title, date, location, participants[], duration}\n"
        "- topics[]: {title, key_points[], decisions[], risks[], open_questions[]}\n"
        "- decisions[]\n"
        "- risks[]\n"
        "- open_questions[]\n"
        "- action_items[]: {description, owner|null, due_date|null, priority|null (P0~P3), status, source_refs[]}\n"
        "- overall_summary: string\n"
        "è¦æ±‚ï¼š\n"
        "1) åš´ç¦æé€ ä¾†æºæ²’æœ‰çš„è³‡è¨Šï¼›æœªçŸ¥æ¬„ä½è«‹ç•™ç©ºæˆ– Unknownã€‚\n"
        "2) å»é‡ã€åˆä½µç›¸è¿‘é‡é»ï¼Œä½†ä¸å¾—æ”¹è®ŠåŸæ„ã€‚\n"
        "3) åªè¼¸å‡º JSON ç‰©ä»¶ï¼Œä¸è¦é¡å¤–èªªæ˜æ–‡å­—ã€‚\n"
        "4) è«‹ç¢ºä¿è¼¸å‡ºå…§å®¹ç‚ºåˆæ³• JSONï¼Œä¸èƒ½æœ‰ä»»ä½•èªªæ˜æˆ–å¤šé¤˜æ–‡å­—ã€‚\n\n"
        "=== åˆ†æ®µæ‘˜è¦ ===\n"
        + "\n\n".join(f"[Part {i+1}]\n{blk}" for i, blk in enumerate(map_blocks))
    )
    try:
        resp = client.chat.completions.create(
            model=MODEL_REDUCE,
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        s = resp.choices[0].message.content.strip()
        start = s.find("{")
        end = s.rfind("}")
        if start != -1 and end != -1:
            s = s[start:end+1]
        return json.loads(s)
    except Exception as e:
        return {"overall_summary": f"è§£æ JSON å¤±æ•—ï¼Œè«‹é‡è©¦æˆ–èª¿æ•´æç¤ºã€‚éŒ¯èª¤ï¼š{e}", "raw": ""}

def reduce_finalize_markdown(map_blocks: List[str]) -> str:
    prompt = (
        "ä½ æ˜¯æœƒè­°è¨˜éŒ„ç¸½æ•´å°ˆå®¶ã€‚è«‹å°‡å¤šå€‹åˆ†æ®µæ‘˜è¦æ•´ä½µç‚ºã€å–®ä¸€ä»½æœ€çµ‚æœƒè­°ç´€éŒ„ï¼ˆMarkdownï¼‰ã€ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1) åƒ…æ ¹æ“šæä¾›çš„åˆ†æ®µæ‘˜è¦æ•´ä½µï¼Œåš´ç¦æé€ ä¾†æºæ²’æœ‰çš„è³‡è¨Šã€‚\n"
        "2) ä¸è¼¸å‡º metadataï¼ˆæ¨™é¡Œ/æ—¥æœŸ/åœ°é»/åƒèˆ‡è€…/æ™‚é•·ï¼‰ï¼Œåªè¦å…§å®¹æœ¬é«”ã€‚\n"
        "3) çµæ§‹ï¼š\n"
        "   - ä»¥ä¸€æ®µã€Œç¸½çµã€é–‹å ´ï¼Œ3~6 å¥ï¼Œèªªæ¸…æ¥šæ•´é«”è„ˆçµ¡èˆ‡çµè«–ã€‚\n"
        "   - ä¹‹å¾Œç”¨å¤šå€‹å°ç¯€ï¼ˆ## ä¸»é¡Œåç¨±ï¼‰ï¼Œæ¯ç¯€æ¡ç”¨çŸ­æ®µè½æ•˜è¿°ç‚ºä¸»ï¼Œå¯ç©¿æ’å°‘é‡æ¢åˆ—ã€‚\n"
        "   - è‹¥æœ‰æ±ºç­–/é¢¨éšª/æœªæ±ºå•é¡Œï¼Œæ–¼å°æ‡‰ä¸»é¡Œå…§ä»¥ã€æ±ºç­–ï¼šã€ã€é¢¨éšªï¼šã€ã€æœªæ±ºï¼šã€è¡Œå…§æ¨™ç¤ºã€‚\n"
        "4) åªè¼¸å‡ºç´” Markdown å…§å®¹ï¼Œä¸è¦é¡å¤–èªªæ˜ã€‚\n\n"
        "=== åˆ†æ®µæ‘˜è¦ ===\n"
        + "\n\n".join(f"[Part {i+1}]\n{blk}" for i, blk in enumerate(map_blocks))
    )
    try:
        resp = client.chat.completions.create(
            model=MODEL_REDUCE,
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"âš ï¸ ç”Ÿæˆæœƒè­°æ‘˜è¦å¤±æ•—ï¼š{e}"

def render_topics_only(md: Dict[str, Any], st):
    st.markdown("#### ä¸»é¡Œ")
    topics = md.get("topics", [])
    for t in topics:
        st.markdown(f"##### {t.get('title','ä¸»é¡Œ')}")
        kp = t.get("key_points", [])
        if kp:
            st.markdown("\n".join(f"- {x}" for x in kp))
        if t.get("decisions"):
            st.markdown("æ±ºç­–ï¼š\n" + "\n".join(f"- {x}" for x in t.get("decisions", [])))
        if t.get("risks"):
            st.markdown("é¢¨éšªï¼š\n" + "\n".join(f"- {x}" for x in t.get("risks", [])))
        if t.get("open_questions"):
            st.markdown("æœªæ±ºå•é¡Œï¼š\n" + "\n".join(f"- {x}" for x in t.get("open_questions", [])))

# ========== ä¸Šå‚³å€ ==========
with st.expander("ä¸Šå‚³æœƒè­°éŒ„éŸ³æª”æ¡ˆ", expanded=True):
    f = st.file_uploader("è«‹ä¸Šå‚³éŸ³æª”ï¼ˆ.wav, .mp3, .m4a, .mp4, .webmï¼‰", type=["wav", "mp3", "m4a", "mp4", "webm"])
    start_btn = st.button("é–‹å§‹ Streaming è½‰éŒ„èˆ‡æ‘˜è¦")

# ä¸»ç•«é¢é€²éšèª¿æ•´ï¼ˆåƒ…é¡¯ç¤ºï¼Œé è¨­å³å¯ï¼‰
with st.expander("é€²éšèª¿æ•´ï¼ˆå¯é¸ï¼Œä¸ç”¨ä¹Ÿèƒ½é †è·‘ï¼‰", expanded=False):
    st.caption("ä¸åŒéŒ„éŸ³æƒ…å¢ƒæ‰éœ€è¦å¾®èª¿ï¼Œå¹³å¸¸ç¶­æŒé è¨­å³å¯ã€‚")
    st.text(f"MIN_SILENCE_LEN_MS = {MIN_SILENCE_LEN_MS}")
    st.text(f"KEEP_SILENCE_MS = {KEEP_SILENCE_MS}")
    st.text(f"SILENCE_DB_OFFSET = {SILENCE_DB_OFFSET}")
    st.text(f"OVERLAP_MS = {OVERLAP_MS}")
    st.text(f"MAP_CHUNK_SIZE = {DEFAULT_MAP_CHUNK_SIZE}")

if not (f and start_btn):
    st.stop()

# ========== ä¸»æµç¨‹ ==========
raw_bytes = f.read()
st.audio(raw_bytes)

tab1, tab2, tab3, tab4 = st.tabs(["è½‰éŒ„çµæœ", "é‡é»æ‘˜è¦", "å…§å®¹è§£æ", "åŸå§‹å…§å®¹"])

with st.status("è™•ç†ä¸­...", expanded=True) as status:
    # 0) å„²å­˜èˆ‡è½‰æª”
    status.update(label="å„²å­˜èˆ‡è½‰æª”...")
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{f.name.split('.')[-1]}") as temp_input:
        temp_input.write(raw_bytes)
        temp_input_path = temp_input.name

    wav_path = temp_input_path
    if not f.name.lower().endswith(".wav"):
        wav_path = temp_input_path + ".wav"
        convert_to_wav(temp_input_path, wav_path)
    audio = AudioSegment.from_file(wav_path, format="wav")

    # 1) éœéŸ³åˆ‡æ®µï¼ˆå®‰å…¨é‡ç–Šï¼‰
    status.update(label="éœéŸ³åˆ‡æ®µï¼ˆå®‰å…¨é‡ç–Šï¼‰...")
    chunks = split_audio_on_silence_safe(audio)
    if not chunks:
        st.error("ç„¡æ³•åˆ‡å‡ºæœ‰æ•ˆéŸ³è¨Šæ®µï¼Œè«‹æª¢æŸ¥éŸ³æª”æˆ–èª¿æ•´åƒæ•¸ï¼ˆå¯æé«˜ keep_silence / é™ä½ silence_db_offsetï¼‰ã€‚")
        st.stop()

    # 2) é€æ®µ Streaming è½‰éŒ„ï¼ˆé¡¯ç¤ºåœ¨ Tab1ï¼‰
    with tab1:
        st.markdown("#### è½‰éŒ„çµæœ")
        stream_container = st.empty()
        progress_bar = st.progress(0.0)
        all_text = stream_transcribe_all(chunks, stream_container, progress_bar)
        st.markdown('<div class="pink-card success-card">âœ… Transcription complete!</div>', unsafe_allow_html=True)

    # 3) åˆ†å¥èˆ‡è·¨æ®µå»é‡
    status.update(label="åˆ†å¥èˆ‡è·¨æ®µå»é‡...")
    grouped_sentences = []
    for i, txt in enumerate(all_text.split("\n")):
        sents = split_sentences(txt)
        if i == 0:
            grouped_sentences.append(sents)
        else:
            unique = dedupe_against_prev(sents, grouped_sentences[-1], threshold=0.80)
            grouped_sentences.append(unique)
    flat_sentences = [s for group in grouped_sentences for s in group]

    # 4) åŸå§‹å…§å®¹ï¼ˆTab4ï¼‰
    with tab4:
        st.markdown("#### åŸå§‹å…§å®¹")
        st.code("\n".join(flat_sentences), language="text")

    # 5) åˆ†æ®µæ‘˜è¦ï¼ˆåƒ…è¨ˆç®—ï¼Œä¸é¡¯ç¤ºï¼‰
    status.update(label="æ•´ä½µé‡é»ï¼ˆå…§éƒ¨è¨ˆç®—ï¼‰...")
    map_blocks_text = map_summarize_blocks(flat_sentences)

    # 6) æœ€çµ‚æœƒè­°æ‘˜è¦ï¼ˆTab2ï¼šæ•˜è¿°ç‰ˆï¼‰ï¼Œå…§å®¹è§£æï¼ˆTab3ï¼šä¸»é¡Œé‡é»ï¼‰
    status.update(label="ç”Ÿæˆæœ€çµ‚æœƒè­°æ‘˜è¦èˆ‡å…§å®¹è§£æ...")
    final_minutes = reduce_finalize_json(map_blocks_text)   # çµæ§‹åŒ–ï¼Œçµ¦å…§å®¹è§£æç”¨
    final_md = reduce_finalize_markdown(map_blocks_text)    # æ•˜è¿°ç‰ˆï¼Œçµ¦é‡é»æ‘˜è¦ç”¨

    with tab2:
        st.markdown(final_md)
        st.download_button(
            "ä¸‹è¼‰æœƒè­°è¨˜éŒ„ JSON",
            data=json.dumps(final_minutes, ensure_ascii=False, indent=2),
            file_name="meeting_minutes.json",
            mime="application/json"
        )

    with tab3:
        render_topics_only(final_minutes, st)

    status.update(label="å…¨éƒ¨å®Œæˆï¼", state="complete", expanded=True)

# æ¸…ç†æš«å­˜
try:
    os.remove(temp_input_path)
    if 'wav_path' in locals() and wav_path != temp_input_path:
        os.remove(wav_path)
except Exception:
    pass
