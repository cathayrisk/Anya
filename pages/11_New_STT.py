# -*- coding: utf-8 -*-
# æœƒè­°éŒ„éŸ³ â†’ ç›´æ’­é€å­—ï¼ˆèˆŠç‰ˆç²¾ç°¡ï¼šåªç•™ã€Œè½‰éŒ„çµæœã€èˆ‡ã€ŒåŸå§‹å…§å®¹ã€ï¼‰
# è®Šæ›´æ‘˜è¦ï¼š
# - åœç”¨ refineï¼Œé¿å…æ­£é«”è¢«æ½¤é£¾æˆç°¡é«”
# - å®Œå…¨ç§»é™¤ã€Œå³æ™‚é‡é»ï¼ˆMap streamingï¼‰ã€èˆ‡ã€Œå…§å®¹è§£æã€
# - æ–°å¢å¯é¸ã€Œæ­£é«”åŒ–ä¿éšªï¼ˆOpenCC s2twpï¼‰ã€ï¼›æœªå®‰è£æ™‚ä¸æœƒä¸­æ–·ï¼Œåƒ…æç¤º

import os
import re
import hashlib
import tempfile
import multiprocessing
from typing import List, Dict, Any

import streamlit as st
from openai import OpenAI
from pydub import AudioSegment, silence
from pydub.utils import which

# ========== åŸºæœ¬è¨­å®š ==========
st.set_page_config(page_title="æœƒè­°éŒ„éŸ³ â†’ ç›´æ’­é€å­—ï¼ˆèˆŠç‰ˆï¼‰", page_icon="ğŸ“", layout="wide")

# è‡ªè¨‚æ¨£å¼ï¼ˆåŠ å¤§é ‚éƒ¨å…§è·é¿å…æ¨™é¡Œè¢«åˆ‡åˆ°ã€Tabs è¦–è¦ºã€å…§æ–‡å¯è®€æ€§ï¼‰
st.markdown("""
<style>
:root { --brand:#9c2b2f; --brand-weak:#9c2b2fcc; --bg:#FFF6F6; --border:#f2d9d9; }
.main .block-container{padding-top:2.2rem}
.pink-card{background:var(--bg);border:1px solid var(--border);padding:16px 22px;border-radius:12px;margin-bottom:12px;overflow:visible;}
.header-pill{display:flex;align-items:center;gap:12px;font-size:22px;font-weight:700;color:#2f2f2f;line-height:1.35;min-height:48px;}
.header-pill .emoji{font-size:22px;display:inline-block;transform:translateY(1px);}
.stTabs [data-baseweb="tab-list"]{gap:24px;border-bottom:1px solid #f0e2e2;margin-bottom:8px}
.stTabs [data-baseweb="tab"]{padding:10px 2px;color:var(--brand-weak);font-weight:600}
.stTabs [aria-selected="true"]{color:var(--brand);border-bottom:3px solid var(--brand)}
.stMarkdown p{line-height:1.8}
.transcript-readable{font-size:1.02rem;line-height:1.9;letter-spacing:0.02em;}
</style>
""", unsafe_allow_html=True)

# é ‚éƒ¨å¡ç‰‡æ¨™é¡Œï¼ˆå›åˆ°èˆŠç‰ˆåƒ…é€å­—è½‰éŒ„ï¼‰
st.markdown('<div class="pink-card header-pill"><span class="emoji">âœï¸</span> å®‰å¦®äºé–‹æœƒä¸æ¼æ¥ï¼šé€å­—è½‰éŒ„</div>', unsafe_allow_html=True)

# æª¢æŸ¥ FFmpeg
AudioSegment.converter = which("ffmpeg")
AudioSegment.ffprobe = which("ffprobe")
if not AudioSegment.converter or not AudioSegment.ffprobe:
    st.error("æ‰¾ä¸åˆ° ffmpeg/ffprobeï¼Œè«‹å…ˆæ–¼ç³»çµ±å®‰è£å¾Œå†è©¦ã€‚")
    st.stop()

# è®€å– API Key
OPENAI_KEY = st.secrets.get("OPENAI_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_KEY:
    st.error("æ‰¾ä¸åˆ° API Keyï¼Œè«‹åœ¨ Streamlit Secrets è¨­å®š OPENAI_KEY æˆ–ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEYã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_KEY)

# ========== åƒæ•¸ ==========
MODEL_STT = "gpt-4o-mini-transcribe"  # STT å¿ å¯¦è½‰éŒ„åŸèªè¨€
# æ³¨æ„ï¼šèˆŠç‰ˆç²¾ç°¡ï¼Œä¸ä½¿ç”¨ MODEL_MAP / MODEL_REDUCE
ENABLE_REFINE = False  # é—œé–‰å¯è®€ç‰ˆæ½¤é£¾ï¼Œé¿å…æ­£é«”â†’ç°¡é«”
# æ­£é«”åŒ–ä¿éšªæ”¹èµ° UI å‹¾é¸ï¼ˆOpenCCï¼‰ï¼Œé è¨­ä¸å•Ÿç”¨

# åˆ‡æ®µåƒæ•¸
MIN_SILENCE_LEN_MS = 700
KEEP_SILENCE_MS = 300
SILENCE_DB_OFFSET = 16
OVERLAP_MS = 1200

# ç‰‡æ®µé•·åº¦ä¿è­·èˆ‡å›é€€
MAX_CHUNK_MS = 30_000   # å–®æ®µæœ€é•· 30 ç§’
MIN_CHUNK_MS = 2_000    # å–®æ®µæœ€çŸ­ 2 ç§’
FALLBACK_WINDOW_MS = 20_000  # æ‰¾ä¸åˆ°éœéŸ³æ™‚ï¼Œå›ºå®šåˆ‡ 20 ç§’

DEFAULT_MAP_CHUNK_SIZE = 40  # å·²ä¸ä½¿ç”¨ï¼Œä½†ä¿ç•™å¸¸æ•¸ä»¥å…å¤–éƒ¨å¼•ç”¨å ±éŒ¯
MAX_STREAM_WORKERS = min(4, multiprocessing.cpu_count())

CACHE_DIR = ".stt_cache"
os.makedirs(CACHE_DIR, exist_ok=True)

# ========== å·¥å…·å‡½å¼ ==========
def _hash_bytes(b: bytes) -> str:
    return hashlib.md5(b).hexdigest()

def cache_get_text(key: str) -> str | None:
    path = os.path.join(CACHE_DIR, key + ".txt")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    return None

def cache_set_text(key: str, value: str):
    path = os.path.join(CACHE_DIR, key + ".txt")
    with open(path, "w", encoding="utf-8") as f:
        f.write(value)

def convert_to_wav(input_path: str, output_path: str, target_sr=16000):
    audio = AudioSegment.from_file(input_path)
    audio = audio.set_frame_rate(target_sr).set_channels(1)
    audio.export(output_path, format="wav")
    return output_path

def normalize_loudness(audio: AudioSegment, target_dbfs: float = -20.0) -> AudioSegment:
    gain = target_dbfs - audio.dBFS
    return audio.apply_gain(gain)

def trim_leading_silence(audio: AudioSegment, silence_threshold_db: float = -30.0, chunk_ms: int = 10) -> AudioSegment:
    trim_ms = 0
    while trim_ms < len(audio) and audio[trim_ms:trim_ms+chunk_ms].dBFS < silence_threshold_db:
        trim_ms += chunk_ms
    return audio[trim_ms:]

def apply_filters(audio: AudioSegment, use_high_pass: bool = False, hp_hz: int = 100,
                  use_low_pass: bool = False, lp_hz: int = 9500) -> AudioSegment:
    out = audio
    if use_high_pass:
        out = out.high_pass_filter(hp_hz)
    if use_low_pass:
        out = out.low_pass_filter(lp_hz)
    return out

def split_audio_on_silence_safe(audio: AudioSegment) -> List[AudioSegment]:
    silence_thresh = audio.dBFS - SILENCE_DB_OFFSET
    raw_chunks = silence.split_on_silence(
        audio,
        min_silence_len=MIN_SILENCE_LEN_MS,
        silence_thresh=silence_thresh,
        keep_silence=KEEP_SILENCE_MS
    )

    if not raw_chunks:
        chunks = []
        i = 0
        while i < len(audio):
            end = min(i + FALLBACK_WINDOW_MS, len(audio))
            chunks.append(audio[i:end])
            i = end
    else:
        filtered = []
        for c in raw_chunks:
            if len(c) < 250:
                if filtered:
                    filtered[-1] = filtered[-1] + c
                else:
                    filtered.append(c)
            else:
                filtered.append(c)
        if not filtered:
            filtered = raw_chunks

        chunks = []
        for i, c in enumerate(filtered):
            if i == 0:
                chunks.append(c)
            else:
                prev = filtered[i - 1]
                safe_overlap = min(OVERLAP_MS, len(prev))
                if safe_overlap > 0:
                    overlap = prev[-safe_overlap:]
                    chunks.append(overlap + c)
                else:
                    chunks.append(c)

    normalized = []
    for seg in chunks:
        if len(seg) <= MAX_CHUNK_MS:
            normalized.append(seg)
        else:
            start = 0
            while start < len(seg):
                end = min(start + MAX_CHUNK_MS, len(seg))
                normalized.append(seg[start:end])
                start = end

    final_chunks = []
    for seg in normalized:
        if final_chunks and len(seg) < MIN_CHUNK_MS:
            final_chunks[-1] = final_chunks[-1] + seg
        else:
            final_chunks.append(seg)

    return final_chunks

def split_sentences(text: str) -> List[str]:
    parts = re.split(r'([ã€‚ï¼ï¼Ÿï¼›;.!?\n])', text)
    result = []
    for i in range(0, len(parts) - 1, 2):
        s = (parts[i] + parts[i + 1]).strip()
        if s:
            result.append(s)
    if len(parts) % 2 != 0:
        tail = parts[-1].strip()
        if tail:
            result.append(tail)
    return result

def dedupe_against_prev(curr: List[str], prev: List[str], threshold=0.80) -> List[str]:
    import difflib
    out = []
    for s in curr:
        if all(difflib.SequenceMatcher(None, s, p).ratio() <= threshold for p in prev):
            out.append(s)
    return out

def add_cjk_spacing(text: str) -> str:
    text = re.sub(r'([\u4e00-\u9fff])([A-Za-z0-9$%#@&])', r'\1 \2', text)
    text = re.sub(r'([A-Za-z0-9$%#@&])([\u4e00-\u9fff])', r'\1 \2', text)
    return text

def normalize_symbols(text: str) -> str:
    text = text.replace("ï¼…", "%").replace("ï¼„", "$")
    text = text.replace("â€“", "-").replace("â€”", "-")
    text = text.replace("\u200b", "").replace("\u200c", "")
    return text

def pretty_format_sentences(sentences: List[str]) -> List[str]:
    pretty = []
    for s in sentences:
        s2 = add_cjk_spacing(s)
        s2 = normalize_symbols(s2)
        pretty.append(s2)
    return pretty

# æ³¨æ„ï¼šç‚ºäº†å›åˆ°èˆŠç‰ˆè¡Œç‚ºï¼Œrefine å‡½å¼ä¿ç•™ä½†é è¨­ä¸ä½¿ç”¨
def refine_zh_tw_via_prompt(lines: List[str]) -> List[str]:
    """
    å°‡å¤šè¡Œå¥å­é€è¡Œã€æ½¤é£¾ï¼‹å¿…è¦æ™‚ç¿»è­¯ã€ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚
    - é è¨­åœç”¨ï¼›è‹¥æœªä¾†æ‰‹å‹•é–‹å•Ÿï¼Œä»å¯ä½¿ç”¨æ­¤å‡½å¼ã€‚
    """
    if not lines:
        return lines

    SEP = "\u241E"  # â
    MAX_BATCH_CHARS = 9000
    MAX_BATCH_LINES = 120

    def _refine_batch(batch: List[str]) -> List[str]:
        blob = SEP.join(batch)
        dev_msg = (
            "ä½ å°‡æ”¶åˆ°å¤šè¡Œé€å­—ç¨¿ï¼Œè«‹é€è¡Œã€æ½¤é£¾ï¼‹å¿…è¦æ™‚ç¿»è­¯ã€ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚\n"
            "è¦æ±‚ï¼š\n"
            "1) ä¿ç•™åŸæ„ï¼Œåªåšèªå¥æ½¤é£¾èˆ‡æ­£é«”ç¿»è­¯ï¼Œä¸å¾—æé€ è³‡è¨Šã€‚\n"
            "2) è‹¥è©²è¡Œæ˜¯è‹±æ–‡æˆ–æ··é›œèªè¨€ï¼Œç¿»è­¯ç‚ºæ­£é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªï¼‰ã€‚\n"
            "3) åš´ç¦åˆä½µ/æ‹†åˆ†è¡Œï¼›åš´ç¦æ’å…¥æˆ–åˆªé™¤ç©ºè¡Œï¼›è¼¸å…¥å¹¾è¡Œå°±è¼¸å‡ºå¹¾è¡Œã€‚\n"
            "4) ä¿ç•™æ•¸å­—ã€å–®ä½ã€æ™‚é–“ã€é‡‘é¡ã€emojiã€ç¶²å€ã€ç°¡çŸ­ä»£ç¢¼ç‰‡æ®µç­‰éèªæ„å…§å®¹ã€‚\n"
            "5) ç”¨è©æ¡å°ç£æ…£ç”¨ã€å£å»ç°¡æ½”å°ˆæ¥­è‡ªç„¶ã€‚\n"
            "6) è¡Œèˆ‡è¡Œç”±ç‰¹æ®Šåˆ†éš”ç¬¦ âï¼ˆU+241Eï¼‰é€£æ¥ï¼›è«‹å‹™å¿…ä¿ç•™ç›¸åŒæ•¸é‡çš„åˆ†éš”ç¬¦ï¼Œä¸å¯æ–°å¢æˆ–ç§»é™¤ã€‚\n"
            "åªè¼¸å‡ºæœ€çµ‚æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡‹ã€‚"
        )
        try:
            resp = client.responses.create(
                model="gpt-4.1",
                input=[
                    {"role": "developer", "content": [{"type": "input_text", "text": dev_msg}]},
                    {"role": "user", "content": [{"type": "input_text", "text": blob}]},
                ],
                text={"format": {"type": "text"}},
                tools=[],
            )
            out = (resp.output_text or "").rstrip("\n")
            out_lines = out.split(SEP) if SEP in out else out.split("\n")
            return out_lines if len(out_lines) == len(batch) else batch
        except Exception:
            return batch

    refined_all: List[str] = []
    batch: List[str] = []
    size = 0
    for s in lines:
        if (len(batch) >= MAX_BATCH_LINES) or (size + len(s) + 1 > MAX_BATCH_CHARS):
            refined_all.extend(_refine_batch(batch))
            batch, size = [], 0
        batch.append(s)
        size += len(s) + 1
    if batch:
        refined_all.extend(_refine_batch(batch))
    return refined_all if refined_all else lines

def build_prompt(prev_text: str, glossary: str, style_seed: str, max_tokens: int = 220) -> str:
    parts = []
    parts.append("è«‹å…¨ç¨‹ä½¿ç”¨æ­£é«”ä¸­æ–‡ï¼ˆç¹é«”ï¼Œå°ç£ç”¨èªï¼‰ã€‚")
    if style_seed and style_seed.strip():
        parts.append(style_seed.strip())
    if glossary and glossary.strip():
        words = [w.strip() for w in glossary.splitlines() if w.strip()]
        if words:
            parts.append("Glossary: " + ", ".join(words))
    if prev_text and prev_text.strip():
        tail = prev_text.strip()
        if len(tail) > 1200:
            tail = tail[-1200:]
        parts.append(tail)
    prompt = "\n".join(parts).strip()
    toks = prompt.split()
    if len(toks) > max_tokens:
        prompt = " ".join(toks[-max_tokens:])
    return prompt

def stream_transcribe_all(
    chunks: List[AudioSegment],
    container,
    progress_bar,
    use_prompting: bool = False,
    glossary: str = "",
    style_seed: str = ""
):
    import time
    all_text = ""
    rolling_context = ""
    last_flush = 0.0
    FLUSH_INTERVAL = 0.15

    for i, chunk in enumerate(chunks):
        chunk_hash = _hash_bytes(chunk.raw_data)
        cache_key = f"stt_{MODEL_STT}_{chunk_hash}"
        cached = cache_get_text(cache_key)
        if cached:
            all_text += cached + "\n"
            rolling_context = (rolling_context + " " + cached).strip()
            if len(rolling_context) > 5000:
                rolling_context = rolling_context[-5000:]
            progress_bar.progress((i + 1) / len(chunks))
            container.markdown(all_text)
            continue

        full_text = ""
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                tmp_path = tmp.name
                chunk.export(tmp_path, format="wav", parameters=["-ac", "1", "-ar", "16000"])
            with open(tmp_path, "rb") as audio_file:
                extra_kwargs = {}
                if use_prompting:
                    prompt_str = build_prompt(rolling_context, glossary, style_seed, max_tokens=220)
                    if prompt_str:
                        extra_kwargs["prompt"] = prompt_str

                try:
                    stream = client.audio.transcriptions.create(
                        model=MODEL_STT,
                        file=audio_file,
                        response_format="text",
                        prompt=(
                            "This audio contains a discussion or presentation. "
                            "Always preserve the original language of each sentence. "
                            "If a sentence is in English, output it in English; "
                            "if in Chinese, output it in Traditional Chinese; "
                            "if mixed, output the original mixed-language sentence. "
                            "Do not translate or alter the language. "
                            "The audio may cover various topics such as updates, feedback, or informative lectures."
                        ),
                        stream=True,
                        **extra_kwargs
                    )
                except Exception:
                    try:
                        stream = client.audio.transcriptions.create(
                            model=MODEL_STT,
                            file=audio_file,
                            response_format="text",
                            prompt=(
                                "This audio contains a discussion or presentation. "
                                "Always preserve the original language of each sentence. "
                                "If a sentence is in English, output it in English; "
                                "if in Chinese, output it in Traditional Chinese; "
                                "if mixed, output the original mixed-language sentence. "
                                "Do not translate or alter the language. "
                                "The audio may cover various topics such as updates, feedback, or informative lectures."
                            ),
                            stream=True
                        )
                        container.warning("æ­¤è½‰éŒ„ç«¯é»ä¸æ”¯æ´ promptï¼Œå¼•å°å·²è‡ªå‹•åœç”¨ï¼ˆæœ¬æ¬¡ï¼‰ã€‚")
                    except Exception as e2:
                        container.error(f"API è½‰éŒ„å¤±æ•—ï¼š{e2}")
                        stream = None

                if stream is not None:
                    for event in stream:
                        delta = getattr(event, "delta", None)
                        final_text = getattr(event, "text", None)
                        if delta:
                            full_text += delta
                            now = time.time()
                            if now - last_flush > FLUSH_INTERVAL:
                                container.markdown(all_text + full_text)
                                last_flush = now
                        elif final_text:
                            full_text = final_text
                            container.markdown(all_text + full_text)
        finally:
            if tmp_path:
                try:
                    os.remove(tmp_path)
                except Exception:
                    pass

        cache_set_text(cache_key, full_text.strip())
        all_text += full_text + "\n"

        rolling_context = (rolling_context + " " + full_text).strip()
        if len(rolling_context) > 5000:
            rolling_context = rolling_context[-5000:]

        progress_bar.progress((i + 1) / len(chunks))
        container.markdown(all_text)

    return all_text.strip()

# æ®µè½ç¾¤çµ„ï¼ˆé¡¯ç¤ºç”¨ï¼‰
def group_into_paragraphs(sentences: List[str], max_chars: int = 260, max_sents: int = 4) -> List[str]:
    paras, cur, length = [], [], 0
    for s in sentences:
        s = s.strip()
        if not s:
            continue
        if cur and (len(cur) >= max_sents or length + len(s) > max_chars):
            paras.append(" ".join(cur))
            cur, length = [s], len(s)
        else:
            cur.append(s)
            length += len(s)
    if cur:
        paras.append(" ".join(cur))
    return paras

# Optionalï¼šOpenCCï¼ˆç°¡â†’ç¹-å°ç£ï¼‰ä¿éšªï¼Œå‹•æ…‹è¼‰å…¥ä»¥é¿å…æœªå®‰è£æ™‚ä¸­æ–·
def get_opencc_converter():
    try:
        from opencc import OpenCC
        return OpenCC('s2twp')
    except Exception:
        return None

def looks_simplified(converter, s: str) -> bool:
    if not converter:
        return False
    return converter.convert(s) != s

# ========== ä¸Šå‚³å€ ==========
with st.expander("ä¸Šå‚³æœƒè­°éŒ„éŸ³æª”æ¡ˆ", expanded=True):
    f = st.file_uploader("è«‹ä¸Šå‚³éŸ³æª”ï¼ˆ.wav, .mp3, .m4a, .mp4, .webmï¼‰", type=["wav", "mp3", "m4a", "mp4", "webm"])
    start_btn = st.button("é–‹å§‹ Streaming è½‰éŒ„ï¼ˆèˆŠç‰ˆé¡¯ç¤ºï¼‰")

# ========== å–®ä¸€æ•´é«”æ”¶åˆçš„é€²éšèª¿æ•´ ==========
with st.expander("é€²éšèª¿æ•´ï¼ˆå…¨éƒ¨è¨­å®šï¼Œå¯é¸ï¼‰", expanded=False):
    st.caption("å¹³å¸¸ç¶­æŒé è¨­å³å¯ï¼›åªæœ‰éŸ³æª”ç‰¹æ€§ç‰¹æ®Šæ™‚å†é–‹å•Ÿã€‚")

    st.markdown("###### éŸ³è¨Šå‰è™•ç†")
    cols = st.columns(2)
    with cols[0]:
        do_trim_leading = st.checkbox("å»å‰å°éœéŸ³ï¼ˆå»ºè­°é–‹ï¼‰", value=True)
        do_normalize = st.checkbox("éŸ³é‡æ­£è¦åŒ–åˆ° -20 dBFSï¼ˆå»ºè­°é–‹ï¼‰", value=True)
    with cols[1]:
        use_high_pass = st.checkbox("é«˜é€šæ¿¾æ³¢ï¼ˆé™ä½ä½é »å™ªï¼‰", value=False)
        hp_hz = st.slider("é«˜é€šæˆªæ­¢é »ç‡ (Hz)", 60, 300, 100, 10, disabled=not use_high_pass)
        use_low_pass = st.checkbox("ä½é€šæ¿¾æ³¢ï¼ˆé™é«˜é »å™ªï¼‰", value=False)
        lp_hz = st.slider("ä½é€šæˆªæ­¢é »ç‡ (Hz)", 4000, 12000, 9500, 100, disabled=not use_low_pass)

    st.markdown("###### STT Prompt å¼•å°ï¼ˆè‹¥ç«¯é»ä¸æ”¯æ´æœƒè‡ªå‹•å›é€€ï¼‰")
    use_prompting = st.checkbox("å•Ÿç”¨ Prompt å¼•å°ï¼ˆæ”¹å–„å°ˆæœ‰åè©æ‹¼å¯«èˆ‡é¢¨æ ¼ä¸€è‡´ï¼‰", value=False)
    glossary_input = st.text_area(
        "å°ˆæœ‰åè©æ‹¼å¯«æ¸…å–®ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
        height=120,
        placeholder="ä¾‹ï¼š\nAimee\nShawn\nBBQ\nZyntriQix",
        disabled=not use_prompting
    )
    style_seed = st.text_area(
        "é¢¨æ ¼ç¤ºä¾‹ï¼ˆ1ï½3 å¥ç¤ºä¾‹æ–‡æœ¬ï¼Œä¸æ˜¯æŒ‡ä»¤ï¼‰",
        height=80,
        placeholder="ä¾‹ï¼š\nä¿æŒç°¡æ½”ã€æ¨™é»ä¸€è‡´ã€‚ä¾‹å¥ï¼šwe discuss quarterly outlook and risks.",
        disabled=not use_prompting
    )

    st.markdown("###### æ­£é«”åŒ–ä¿éšªï¼ˆOpenCCï¼Œå¯é¸ï¼‰")
    use_opencc = st.checkbox("å•Ÿç”¨æ­£é«”åŒ–ä¿éšªï¼ˆç°¡â†’ç¹-å°ç£ï¼›éœ€è¦å®‰è£ opencc-python-reimplementedï¼‰", value=False)
    if use_opencc:
        if get_opencc_converter() is None:
            st.info("å°šæœªå®‰è£ opencc-python-reimplementedï¼Œè«‹å…ˆåŸ·è¡Œï¼špip install opencc-python-reimplemented")

if not (f and start_btn):
    st.stop()

# ========== ä¸»æµç¨‹ ==========
raw_bytes = f.read()
st.audio(raw_bytes)

# Tabsï¼šèˆŠç‰ˆåªç•™å…©é 
tab1, tab2 = st.tabs(["è½‰éŒ„çµæœ", "åŸå§‹å…§å®¹"])

with tab1:
    with st.status("è™•ç†ä¸­...", expanded=True) as status:
        status.update(label="å„²å­˜èˆ‡è½‰æª”...")
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{f.name.split('.')[-1]}") as temp_input:
            temp_input.write(raw_bytes)
            temp_input_path = temp_input.name

        wav_path = temp_input_path
        if not f.name.lower().endswith(".wav"):
            wav_path = temp_input_path + ".wav"
            convert_to_wav(temp_input_path, wav_path)

        status.update(label="è¼‰å…¥éŸ³æª”èˆ‡å‰è™•ç†...")
        audio = AudioSegment.from_file(wav_path, format="wav")
        if do_trim_leading:
            audio = trim_leading_silence(audio, silence_threshold_db=-30.0, chunk_ms=10)
        if do_normalize:
            audio = normalize_loudness(audio, target_dbfs=-20.0)
        if use_high_pass or use_low_pass:
            audio = apply_filters(audio, use_high_pass=use_high_pass, hp_hz=hp_hz, use_low_pass=use_low_pass, lp_hz=lp_hz)

        status.update(label="éœéŸ³åˆ‡æ®µï¼ˆé™„æœ€é•·/æœ€çŸ­ä¿è­·ï¼›æ‰¾ä¸åˆ°éœéŸ³æœƒå›é€€å›ºå®šåˆ‡ï¼‰...")
        chunks = split_audio_on_silence_safe(audio)
        if not chunks:
            st.error("ç„¡æ³•åˆ‡å‡ºæœ‰æ•ˆéŸ³è¨Šæ®µï¼Œè«‹æª¢æŸ¥éŸ³æª”æˆ–èª¿æ•´åƒæ•¸ã€‚")
            st.stop()

        st.markdown("#### è½‰éŒ„çµæœ")
        stream_container = st.empty()
        progress_bar = st.progress(0.0)

        status.update(label="é€æ®µ Streaming è½‰éŒ„ä¸­...")
        all_text = stream_transcribe_all(
            chunks,
            stream_container,
            progress_bar,
            use_prompting=use_prompting,
            glossary=glossary_input if use_prompting else "",
            style_seed=style_seed if use_prompting else ""
        )
        raw_stream_text = all_text.strip()

        status.update(label="åˆ†å¥èˆ‡è·¨æ®µå»é‡...")
        grouped_sentences = []
        for i, txt in enumerate(all_text.split("\n")):
            sents = split_sentences(txt)
            if i == 0:
                grouped_sentences.append(sents)
            else:
                unique = dedupe_against_prev(sents, grouped_sentences[-1], threshold=0.80)
                grouped_sentences.append(unique)
        flat_sentences = [s for group in grouped_sentences for s in group]

        # å¯è®€ç‰ˆï¼šè¼•é‡æ•´ç† â†’ ä¸åš refineï¼ˆèˆŠç‰ˆè¡Œç‚ºï¼‰ â†’ æ®µè½åŒ– â†’ Markdown å‘ˆç¾
        pretty_lines = pretty_format_sentences(flat_sentences)

        # æ­£é«”åŒ–ä¿éšªï¼ˆå¯é¸ï¼‰ï¼šOpenCC s2twp
        if use_opencc:
            cc = get_opencc_converter()
            if cc:
                pretty_lines = [cc.convert(x) for x in pretty_lines]
            else:
                st.warning("æœªå®‰è£ opencc-python-reimplementedï¼Œå·²è·³éæ­£é«”åŒ–ä¿éšªã€‚")

        paras = group_into_paragraphs(pretty_lines, max_chars=280, max_sents=4)
        final_md = "\n\n".join(paras)
        stream_container.markdown(final_md)

        # è‹¥æœ‰åµæ¸¬åˆ°ç–‘ä¼¼ç°¡é«”å…§å®¹ï¼Œå‹å–„æç¤ºï¼ˆä¸å½±éŸ¿é¡¯ç¤ºï¼‰
        if use_opencc:
            cc_check = get_opencc_converter()
            if cc_check and any(looks_simplified(cc_check, p) for p in pretty_lines[:50]):
                st.info("åµæ¸¬åˆ°å¯è½‰ç‚ºå°ç£æ­£é«”çš„å…§å®¹ï¼Œå·²å˜—è©¦è‡ªå‹•è½‰æ›ã€‚")

        st.success("Transcription complete!")
        status.update(label="å…¨éƒ¨å®Œæˆï¼", state="complete", expanded=True)

with tab2:
    st.markdown("#### åŸå§‹å…§å®¹ï¼ˆæœ€åŸå§‹ä¸²æµè¼¸å‡ºï¼Œæœªåˆ†å¥ï¼æœªå»é‡ï¼‰")
    st.code(raw_stream_text, language="text")

# æ¸…ç†æš«å­˜
try:
    os.remove(temp_input_path)
    if 'wav_path' in locals() and wav_path != temp_input_path:
        os.remove(wav_path)
except Exception:
    pass
