import streamlit as st
import base64
from io import BytesIO
from PIL import Image
from openai import OpenAI

# === 0. Trimming åƒæ•¸ï¼ˆå¯èª¿ï¼‰ ===
TRIM_LAST_N_USER_TURNS = 15        # å»ºè­°å…ˆæ”¶æ–‚ä¸€é»ï¼Œæ›´çœ token
MAX_STREAM_TIMEOUT_SEC = 60

# === 1. è¨­å®š Streamlit é é¢ ===
st.set_page_config(page_title="Anya Multimodal Agent", page_icon="ğŸ¥œ", layout="wide")

# === 1.1 å¿«å–ï¼šç¸®åœ– & data URL ===
@st.cache_data(show_spinner=False, max_entries=256)
def make_thumb(imgbytes: bytes, max_w=220) -> bytes:
    im = Image.open(BytesIO(imgbytes))
    if im.mode not in ("RGB", "L"):
        im = im.convert("RGB")
    im.thumbnail((max_w, max_w))
    out = BytesIO()
    im.save(out, format="JPEG", quality=80, optimize=True)
    return out.getvalue()

def _detect_mime_from_bytes(img_bytes: bytes) -> str:
    try:
        im = Image.open(BytesIO(img_bytes))
        fmt = (im.format or "").upper()
        if fmt == "PNG":  return "image/png"
        if fmt in ("JPG", "JPEG"): return "image/jpeg"
        if fmt == "WEBP": return "image/webp"
        if fmt == "GIF":  return "image/gif"
    except Exception:
        pass
    return "application/octet-stream"

@st.cache_data(show_spinner=False, max_entries=256)
def bytes_to_data_url(imgbytes: bytes) -> str:
    mime = _detect_mime_from_bytes(imgbytes)
    b64 = base64.b64encode(imgbytes).decode()
    return f"data:{mime};base64,{b64}"

# === 2. Session State ===
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [{
        "role": "assistant",
        "text": "å—¨å—¨ï½å®‰å¦®äºå¤§å‡ç´šäº†ï¼ğŸ‘‹ æœ‰ä»€éº¼æƒ³å•å®‰å¦®äºçš„å—ï¼Ÿ",
        "images": []  # [(name, thumb_bytes, orig_bytes)]
    }]
if "pending_ai" not in st.session_state:
    st.session_state.pending_ai = False
if "pending_content" not in st.session_state:
    st.session_state.pending_content = None

# === 3. OpenAI client ===
client = OpenAI(api_key=st.secrets["OPENAI_KEY"])

# === 4. ç³»çµ±æç¤º ===
ANYA_SYSTEM_PROMPT = """
ä½ æ˜¯å®‰å¦®äºï¼ˆAnya Forgerï¼‰ï¼Œä¾†è‡ªã€ŠSPYÃ—FAMILY é–“è«œå®¶å®¶é…’ã€‹çš„å°å¥³å­©ã€‚è«‹ç”¨æ­£é«”ä¸­æ–‡ã€å°ç£ç”¨èªï¼Œèªæ°£å¯æ„›ç°¡å–®ã€æ´»æ½‘æœ‰ç¦®ï¼›é©æ™‚åŠ å…¥emojiï¼›å¿…è¦æ™‚æ¢åˆ—æ•´ç†é‡é»ï¼›è‹¥è¢«è¦æ±‚ç¿»è­¯å‰‡æ”¹ç‚ºæ­£å¼é€å¥ç¿»è­¯ã€‚
"""

# === 5. å°‡ chat_history ä¿®å‰ªæˆã€Œæœ€è¿‘ N å€‹ä½¿ç”¨è€…å›åˆã€ä¸¦è½‰æˆ Responses API input ===
def build_trimmed_input_messages(pending_user_content_blocks):
    hist = st.session_state.chat_history
    if not hist:
        return [{"role": "user", "content": pending_user_content_blocks}]

    # 1) æ‰¾åˆ°æœ€è¿‘ N å€‹ã€Œä½¿ç”¨è€…å›åˆã€èµ·é»
    user_count = 0
    start_idx = 0
    for i in range(len(hist) - 1, -1, -1):
        if hist[i].get("role") == "user":
            user_count += 1
            if user_count == TRIM_LAST_N_USER_TURNS:
                start_idx = i
                break
    selected = hist[start_idx:]

    # 2) è½‰ Responses messagesï¼šåƒ…ä¿ç•™æ–‡å­—æ­·å²ï¼Œä¸”åªè®“ã€Œæœ€å¾Œä¸€è¼ªä½¿ç”¨è€…å›åˆã€å¸¶åœ–ç‰‡
    messages = []
    last_user_idx = max([i for i, m in enumerate(selected) if m.get("role") == "user"], default=-1)
    for i, msg in enumerate(selected):
        role = msg.get("role")
        if role == "user":
            blocks = []
            if msg.get("text"):
                blocks.append({"type": "input_text", "text": msg["text"]})
            # åƒ…æœ€å¾Œä¸€è¼ªä½¿ç”¨è€…å›åˆå¸¶åœ–ï¼Œé™ä½ payload
            if i == last_user_idx and msg.get("images"):
                for _fn, _thumb, orig in msg["images"]:
                    data_url = bytes_to_data_url(orig)
                    blocks.append({"type": "input_image", "image_url": data_url})
            if blocks:
                messages.append({"role": "user", "content": blocks})
        elif role == "assistant":
            if msg.get("text"):
                messages.append({
                    "role": "assistant",
                    "content": [{"type": "output_text", "text": msg["text"]}]
                })

    # 3) åŠ ä¸Šã€Œé€™ä¸€è¼ªã€ä½¿ç”¨è€…è¼¸å…¥
    messages.append({"role": "user", "content": pending_user_content_blocks})
    return messages

# === 6. Responses ä¸²æµ â†’ ç´”æ–‡å­—ç”¢ç”Ÿå™¨ï¼ˆçµ¦ st.write_streamï¼‰ ===
def responses_text_stream(client, *, model, messages, tools=None, tool_choice="none",
                          instructions=None, timeout=MAX_STREAM_TIMEOUT_SEC):
    # ä½¿ç”¨å®˜æ–¹ stream contextï¼Œé€äº‹ä»¶æ‹¿ delta
    with client.responses.stream(
        model=model,
        input=messages,
        tools=tools or [],
        tool_choice=tool_choice,
        instructions=instructions,
        truncation="auto",
        parallel_tool_calls=True,
        reasoning={"effort": "medium"},
        text={"verbosity": "medium"},
        timeout=timeout,
    ) as stream:
        for event in stream:
            et = getattr(event, "type", "")
            if et == "response.output_text.delta":
                delta = getattr(event, "delta", "")
                if delta:
                    yield delta
            elif et == "response.error":
                err = getattr(event, "error", "")
                yield f"\n[ç™¼ç”ŸéŒ¯èª¤] {err}\n"

# === 7. å´é‚Šæ§åˆ¶ï¼ˆå¯é¸ï¼‰ ===
st.sidebar.markdown("### åå¥½è¨­å®š")
allow_web = st.sidebar.toggle("å…è¨±ç¶²è·¯æœå°‹ï¼ˆå¯èƒ½ç¨æ…¢ï¼‰", value=False)
tool_choice = "auto" if allow_web else "none"
tools = [{"type": "web_search"}] if allow_web else []

# === 8. é¡¯ç¤ºæ­·å²ï¼ˆç¸®åœ–é¡¯ç¤ºï¼Œçœè¨˜æ†¶é«”ï¼‰ ===
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        if msg.get("text"):
            st.markdown(msg["text"])
        if msg.get("images"):
            for fn, thumb, _orig in msg["images"]:
                st.image(thumb, caption=fn, width=220)

# === 9. å›è¦†éšæ®µï¼ˆçœŸæ­£ä¸²æµè¼¸å‡ºï¼‰ ===
if st.session_state.pending_ai and st.session_state.pending_content:
    with st.chat_message("assistant"):
        status = st.status("æ€è€ƒä¸­â€¦âœ¨", expanded=False)
        try:
            status.update(label="æ€è€ƒä¸­â€¦âœ¨", state="running")
            trimmed_messages = build_trimmed_input_messages(st.session_state.pending_content)

            # ä¸²æµåˆ°ç•«é¢ï¼›write_stream æœƒå›å‚³å®Œæ•´æ–‡å­—
            ai_text = st.write_stream(
                responses_text_stream(
                    client,
                    model="gpt-5",
                    messages=trimmed_messages,
                    tools=tools,
                    tool_choice=tool_choice,
                    instructions=ANYA_SYSTEM_PROMPT,
                    timeout=MAX_STREAM_TIMEOUT_SEC,
                )
            )
            if not ai_text:
                ai_text = "å®‰å¦®äºæ‰¾ä¸åˆ°ç­”æ¡ˆï½ï¼ˆæŠ±æ­‰å•¦ï¼ï¼‰"
            status.update(label="å®Œæˆï¼ğŸ‰", state="complete")
        except Exception as e:
            ai_text = f"API ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
            status.update(label="å‡ºç¾å°ç‹€æ³äº†â€¦è«‹å†è©¦ä¸€æ¬¡ğŸ› ï¸", state="error")

        # å¯«å›æ­·å² & æ”¶å°¾
        st.session_state.chat_history.append({
            "role": "assistant",
            "text": ai_text,
            "images": []
        })
        st.session_state.pending_ai = False
        st.session_state.pending_content = None
        st.rerun()

# === 10. ä½¿ç”¨è€…è¼¸å…¥ ===
prompt = st.chat_input(
    "wakuwakuï¼å®‰å¦®äºå¯ä»¥å¹«ä½ çœ‹åœ–èªªæ•…äº‹åš•ï¼",
    accept_file="multiple",
    file_type=["jpg", "jpeg", "png"]
)

if prompt:
    user_text = prompt.text.strip() if getattr(prompt, "text", None) else ""
    images_for_history = []
    content_blocks = []

    if user_text:
        content_blocks.append({"type": "input_text", "text": user_text})

    files = getattr(prompt, "files", []) or []
    for f in files:
        imgbytes = f.getvalue()
        thumb = make_thumb(imgbytes)
        images_for_history.append((f.name, thumb, imgbytes))
        # ç•¶å›åˆé€æ¨¡å‹æ‰éœ€è¦ data_urlï¼Œé€™è£¡å…ˆä¸è½‰ï¼›ç”± build_trimmed_input_messages è™•ç†

    # å¯«å…¥æ­·å²ï¼ˆé¡¯ç¤ºç”¨ï¼‰
    st.session_state.chat_history.append({
        "role": "user",
        "text": user_text,
        "images": images_for_history
    })

    # è¨­å®šé€™ä¸€è¼ªè¦é€çµ¦æ¨¡å‹çš„å…§å®¹ï¼ˆå«åœ–ç‰‡ï¼‰
    for _fn, _thumb, orig in images_for_history:
        data_url = bytes_to_data_url(orig)
        content_blocks.append({"type": "input_image", "image_url": data_url})

    st.session_state.pending_ai = True
    st.session_state.pending_content = content_blocks
    st.rerun()
