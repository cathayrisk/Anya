import streamlit as st
import asyncio
from openai.types.shared.reasoning import Reasoning
from pydantic import BaseModel
import os
from agents import Agent, ModelSettings, WebSearchTool, Runner, handoff
from openai.types.responses import ResponseTextDeltaEvent
import time
import nest_asyncio
nest_asyncio.apply()

os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_KEY"]

def stream_text_gen(result_streaming):
    async def gen():
        async for event in result_streaming.stream_events():
            if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
                yield event.data.delta or ""
    return gen()

def emoji_token_stream(full_text, emoji="ğŸŒ¸", cursor_symbol=" "):
    placeholder = st.empty()
    tokens = []
    cursor_visible = True

    for idx, token in enumerate(full_text):
        tokens.append(token)
        cursor_visible = not cursor_visible
        cursor = cursor_symbol if cursor_visible else " "
        safe_text = ''.join(tokens[:-1])
        # 1. å…ˆç”¨ emoji é¡¯ç¤ºæ–°å­—
        placeholder.markdown(safe_text + emoji + cursor)
        time.sleep(0.03)
        # 2. å†æ›æˆæ­£å¸¸å­—
        placeholder.markdown(''.join(tokens) + cursor)
        time.sleep(0.01)
    # æœ€å¾Œé¡¯ç¤ºå®Œæ•´å…§å®¹ï¼ˆä¸é¡¯ç¤ºæ¸¸æ¨™ï¼‰
    placeholder.markdown(''.join(tokens))

#---Planner
planner_agent_PROMPT = (
    "You are a helpful research assistant. Given a query, come up with a set of web searches "
    "to perform to best answer the query. Output between 5 and 20 terms to query for."
)

class WebSearchItem(BaseModel):
    reason: str
    "Your reasoning for why this search is important to the query."

    query: str
    "The search term to use for the web search."

class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]
    """A list of web searches to perform to best answer the query."""

planner_agent = Agent(
    name="PlannerAgent",
    instructions=planner_agent_PROMPT,
    model="gpt-5",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=WebSearchPlan,
)

#----search_agent
INSTRUCTIONS = (
    "You are a research assistant. Given a search term, you search the web for that term and "
    "produce a concise summary of the results. The summary must be 2-3 paragraphs and less than 300 "
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
    "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
    "essence and ignore any fluff. Do not include any additional commentary other than the summary "
    "itself."
)

search_agent = Agent(
    name="Search agent",
    model="gpt-4.1",
    instructions=INSTRUCTIONS,
    tools=[WebSearchTool()],
    model_settings=ModelSettings(tool_choice="required"),
)

#---writer_agent
writer_agent_PROMPT = (
    "You are a senior researcher tasked with writing a cohesive report for a research query. "
    "You will be provided with the original query, and some initial research done by a research "
    "assistant.\n"
    "You should first come up with an outline for the report that describes the structure and "
    "flow of the report. Then, generate the report and return that as your final output.\n"
    "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
    "for 5-10 pages of content, at least 1000 words."
    "è«‹å‹™å¿…ä»¥æ­£é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦éµå¾ªå°ç£ç”¨èªç¿’æ…£"
)

class ReportData(BaseModel):
    short_summary: str
    """A short 2-3 sentence summary of the findings."""

    markdown_report: str
    """The final report"""

    follow_up_questions: list[str]
    """Suggested topics to research further"""

writer_agent = Agent(
    name="WriterAgent",
    instructions=writer_agent_PROMPT,
    model="gpt-5-mini",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=ReportData,
)

#---RouterAgentï¼ˆLLMè‡ªå‹•åˆ¤æ–·æ˜¯å¦handoffï¼‰
ROUTER_PROMPT = """
ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œæœƒæ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚è‡ªå‹•æ±ºå®šè¦æ€éº¼è™•ç†å•é¡Œã€‚
- å¦‚æœç”¨æˆ¶çš„å•é¡Œæ˜¯ã€Œéœ€è¦ç ”ç©¶ã€æŸ¥è³‡æ–™ã€åˆ†æã€å¯«å ±å‘Šã€æ–‡ç»æ¢è¨ã€ç­‰ï¼Œè«‹ä½¿ç”¨ transfer_to_planner_agent å·¥å…·ï¼ŒæŠŠå•é¡Œäº¤çµ¦ç ”ç©¶è¦åŠƒåŠ©ç†ã€‚
- å¦‚æœåªæ˜¯ä¸€èˆ¬èŠå¤©ã€çŸ¥è­˜å•ç­”ã€é–’èŠï¼Œè«‹ç›´æ¥ç”¨ä½ è‡ªå·±çš„çŸ¥è­˜å›ç­”ã€‚å¿…è¦çš„æ™‚å€™å¯ä»¥ä½¿ç”¨WebSearchToolä¾†æœå°‹ç¶²è·¯è³‡è¨Šã€‚
è«‹æ ¹æ“šç”¨æˆ¶çš„è¼¸å…¥ï¼Œè‡ªè¡Œåˆ¤æ–·è¦ä¸è¦ handoffã€‚
"""

router_agent = Agent(
    name="RouterAgent",
    instructions=ROUTER_PROMPT,
    model="gpt-5",
    tools=[WebSearchTool()],
    model_settings=ModelSettings(
        reasoning=Reasoning(effort="low"),  # "minimal", "low", "medium", "high"
        verbosity="medium",  # "low", "medium", "high"
    ),
    handoffs=[
        handoff(planner_agent)
    ]
)

def run_async(coro):
    return asyncio.get_event_loop().run_until_complete(coro)

st.set_page_config(page_title="AI ç ”ç©¶åŠ©ç† Chat", layout="wide", page_icon="ğŸ¤–")

st.title("AI ç ”ç©¶åŠ©ç† Chat ç‰ˆ")
st.write("ç”¨å°è©±æ–¹å¼å•ç ”ç©¶å•é¡Œï¼ŒAI æœƒåƒèŠå¤©ä¸€æ¨£å¹«ä½ æŸ¥è³‡æ–™ã€å¯«å ±å‘Šï¼")

# åˆå§‹åŒ–å°è©±æ­·å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.markdown(msg["content"])

# èŠå¤©è¼¸å…¥
user_input = st.chat_input("è«‹è¼¸å…¥ä½ æƒ³ç ”ç©¶çš„å•é¡Œæˆ–ç¹¼çºŒè¿½å•...")

if user_input:
    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
    })
    with st.chat_message("user"):
        st.markdown(user_input)

    # AI è™•ç†ï¼ˆé¡¯ç¤º spinnerï¼‰
    with st.chat_message("assistant"):
        with st.spinner("AI æ­£åœ¨åŠªåŠ›æ€è€ƒä¸­..."):
            # åªå‘¼å« RouterAgentï¼Œè®“ LLM è‡ªå·±æ±ºå®šè¦ä¸è¦ handoff
            loop = asyncio.get_event_loop()
            router_result = loop.run_until_complete(Runner.run(router_agent, user_input))

            # å¦‚æœ LLM handoff çµ¦ planner_agentï¼Œå‰‡é€²è¡Œç ”ç©¶æµç¨‹
            if isinstance(router_result.final_output, WebSearchPlan):
                # Step 1: è¦åŠƒ
                plan_result = router_result  # å°±æ˜¯ planner_agent çš„çµæœ
                search_plan = plan_result.final_output.searches

                plan_md = "### ğŸ” æœå°‹è¦åŠƒ\n"
                for idx, item in enumerate(search_plan):
                    plan_md += f"**{idx+1}. {item.query}**\n> {item.reason}\n"

                # Step 2: ä¸¦è¡Œæœå°‹
                search_tasks = [
                    Runner.run(search_agent, f"Search term: {item.query}\nReason: {item.reason}")
                    for item in search_plan
                ]
                search_results = run_async(asyncio.gather(*search_tasks))
                summaries = [str(r.final_output) for r in search_results]

                summary_md = "### ğŸ“ å„é …æœå°‹æ‘˜è¦\n"
                for idx, summary in enumerate(summaries):
                    summary_md += f"**{search_plan[idx].query}**\n{summary}\n\n"

                with st.expander("ğŸ” æœå°‹è¦åŠƒèˆ‡å„é …æœå°‹æ‘˜è¦", expanded=True):
                    st.markdown("### æœå°‹è¦åŠƒ")
                    for idx, item in enumerate(search_plan):
                        st.markdown(f"**{idx+1}. {item.query}**\n> {item.reason}")

                    st.markdown("### å„é …æœå°‹æ‘˜è¦")
                    for idx, summary in enumerate(summaries):
                        st.markdown(f"**{search_plan[idx].query}**\n{summary}\n")

                # Step 3: æ•´åˆå¯«ä½œ
                writer_input = f"Original query: {user_input}\nSummarized search results: {summaries}"
                report = run_async(Runner.run(writer_agent, writer_input))

                st.markdown("### ğŸ“‹ Executive Summary")
                emoji_token_stream(report.final_output.short_summary, emoji="ğŸŒŸ")  # ç”¨æ˜Ÿæ˜Ÿ

                st.markdown("### ğŸ“– å®Œæ•´å ±å‘Š")
                emoji_token_stream(report.final_output.markdown_report, emoji="ğŸŒ¸")  # ç”¨èŠ±æœµ

                st.markdown("### â“ å¾ŒçºŒå»ºè­°å•é¡Œ")
                for q in report.final_output.follow_up_questions:
                    emoji_token_stream(q, emoji="ğŸ¥œ")  # ç”¨èŠ±ç”Ÿ

                # æŠŠ AI å›è¦†å­˜é€²æ­·å²
                ai_reply = (
                    plan_md + "\n" +
                    summary_md + "\n" +
                    "#### Executive Summary\n" + report.final_output.short_summary + "\n" +
                    "#### å®Œæ•´å ±å‘Š\n" + report.final_output.markdown_report + "\n" +
                    "#### å¾ŒçºŒå»ºè­°å•é¡Œ\n" + "\n".join([f"- {q}" for q in report.final_output.follow_up_questions])
                )
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": ai_reply,
                })
            else:
                # ä¸€èˆ¬å°è©±ï¼Œç›´æ¥é¡¯ç¤º RouterAgent çš„å›è¦†
                router_result = run_async(Runner.run(router_agent, user_input))
                full_text = str(router_result.final_output)
                emoji_token_stream(full_text)
                    
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_text,  # st.write_stream å›å‚³å®Œæ•´æ–‡å­—
                })
