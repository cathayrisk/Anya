import streamlit as st
import os
import mimetypes
from openai import OpenAI
import base64
import openai


def file_to_data_url(file):
    # è®€å–åœ–ç‰‡å…§å®¹
    file_bytes = file.read()
    # åˆ¤æ–·å‰¯æª”å
    ext = file.name.split(".")[-1].lower()
    mime = "image/jpeg" if ext in ["jpg", "jpeg"] else "image/png"
    # è½‰ base64
    b64 = base64.b64encode(file_bytes).decode("utf-8")
    return f"data:{mime};base64,{b64}"
    
# ====== åƒæ•¸è¨­å®š ======
OPENAI_API_KEY = st.secrets["OPENAI_KEY"]
VECTOR_STORE_NAME = "my_knowledge_base"
ALLOWED_FILE_TYPES = ["txt", "pdf", "jpg", "jpeg", "png", "docx", "pptx", "md"]

# ====== åˆå§‹åŒ– OpenAI ç‰©ä»¶èˆ‡ Vector Store ======
@st.cache_resource
def get_openai_client():
    return OpenAI(api_key=st.secrets["OPENAI_KEY"])

@st.cache_resource
def get_vector_store(_client):
    vector_store = client.vector_stores.create(name=VECTOR_STORE_NAME)
    return vector_store.id

client = get_openai_client()
vector_store_id = get_vector_store(client)

# ====== æª”æ¡ˆä¸Šå‚³åˆ° Vector Store ======
def upload_file_to_vector_store(file, client, vector_store_id):
    # å…ˆå­˜åˆ°æœ¬åœ°æš«å­˜
    temp_path = f"temp_{file.name}"
    with open(temp_path, "wb") as f:
        f.write(file.read())
    # ä¸Šå‚³åˆ° OpenAI
    file_resp = client.files.create(file=open(temp_path, "rb"), purpose="assistants")
    client.vector_stores.files.create(
        vector_store_id=vector_store_id,
        file_id=file_resp.id
    )
    os.remove(temp_path)
    return file_resp.id

# ====== å¤šæ¨¡æ…‹æŸ¥è©¢ ======
def multimodal_query(client, vector_store_id, user_text=None, image_file=None):
    input_content = []
    if user_text:
        input_content.append({"type": "input_text", "text": user_text})
    if image_file:
        data_url = file_to_data_url(image_file)
        input_content.append({"type": "input_image", "image_url": data_url})

    params = {
        "model": "gpt-4o",
        "input": [{"role": "user", "content": input_content}],
        "tools": [{
            "type": "file_search",
            "vector_store_ids": [vector_store_id]
        }]
    }
    try:
        response = client.responses.create(**params)
        return response
    except openai.BadRequestError as e:
        st.error(f"API BadRequestError: {e}")
        return None
    except Exception as e:
        st.error(f"API Error: {e}")
        return None

# ====== Citation æ ¼å¼åŒ– ======
def format_response(response):
    # å…ˆæª¢æŸ¥ output æ˜¯å¦å­˜åœ¨ä¸”é•·åº¦è¶³å¤ 
    if not hasattr(response, "output") or not response.output or len(response.output) < 2:
        return ":red[âš ï¸ Assistant æ²’æœ‰å›æ‡‰ï¼Œè«‹æª¢æŸ¥è¼¸å…¥æ ¼å¼æˆ–APIç‹€æ…‹ï¼]"
    output = response.output[1]
    if not hasattr(output, "content") or not output.content or len(output.content) == 0:
        return ":red[âš ï¸ Assistant æ²’æœ‰ç”¢ç”Ÿå…§å®¹ï¼Œè«‹æª¢æŸ¥è¼¸å…¥æ ¼å¼æˆ–APIç‹€æ…‹ï¼]"
    text = output.content[0].text
    citations = output.content[0].annotations if hasattr(output.content[0], "annotations") else []
    for i, cite in enumerate(citations):
        if hasattr(cite, "filename"):
            text += f"\n[ä¾†æº{i+1}: {cite.filename}]"
    return text

# ====== Streamlit UI ======
st.title("ğŸ¦¸â€â™€ï¸ å¤šæ¨¡æ…‹ Responses API Chatbot by å®‰å¦®äº")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Chat UI
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input
user_input = st.chat_input(
    "è«‹è¼¸å…¥å•é¡Œï¼Œæˆ–ä¸Šå‚³æª”æ¡ˆä¸€èµ·å•æˆ‘å§ï¼",
    accept_file="multiple",
    file_type=ALLOWED_FILE_TYPES,
    key="chat_input"
)

if user_input:
    # 1. è™•ç†æª”æ¡ˆä¸Šå‚³
    uploaded_files = user_input.files if hasattr(user_input, "files") else []
    user_text = user_input.text if hasattr(user_input, "text") else user_input

    # 2. æª”æ¡ˆå…¨éƒ¨ä¸Šå‚³åˆ° Vector Store
    for file in uploaded_files:
        upload_file_to_vector_store(file, client, vector_store_id)

    # 3. å¤šæ¨¡æ…‹æŸ¥è©¢ï¼ˆåªä¸Ÿç¬¬ä¸€å¼µåœ–ç‰‡çµ¦ LLMï¼Œå…¶ä»–éƒ½é€²çŸ¥è­˜åº«ï¼‰
    image_file = None
    for file in uploaded_files:
        mime, _ = mimetypes.guess_type(file.name)
        if mime and mime.startswith("image/"):
            image_file = file
            break

    # 4. å‘¼å« Responses API
    response = multimodal_query(client, vector_store_id, user_text, image_file)

    # 5. é¡¯ç¤ºå°è©±
    st.session_state.chat_history.append({"role": "user", "content": user_text})
    with st.chat_message("user"):
        st.markdown(user_text)

    answer = format_response(response)
    st.session_state.chat_history.append({"role": "assistant", "content": answer})
    with st.chat_message("assistant"):
        st.markdown(answer)
