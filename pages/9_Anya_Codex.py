import streamlit as st
import asyncio
from pydantic import BaseModel
import os
import nest_asyncio
nest_asyncio.apply()

from openai.types.shared.reasoning import Reasoning
from agents import Agent, ModelSettings, WebSearchTool, Runner, handoff

# å¤šæ¨¡æ…‹
import base64
from io import BytesIO
from PIL import Image
from openai import OpenAI
import time

# =========================
# åŸºæœ¬ç’°å¢ƒè¨­å®š
# =========================
st.set_page_config(page_title="AI ç ”ç©¶åŠ©ç† Chatï¼ˆé™„ä»¶ï¼‹30è¼ªä¸Šä¸‹æ–‡ï¼‹æ·¡å…¥ï¼‰", layout="wide", page_icon="ğŸ¤–")
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_KEY"]

client = OpenAI(api_key=st.secrets["OPENAI_KEY"])

def run_async(coro):
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(coro)

# =========================
# é€å­—å‹•ç•«ï¼ˆç„¡é–ƒçˆï¼‰
# =========================
def emoji_token_stream(
    full_text: str,
    min_cps: int = 20,     # ç©©å®šã€ç¨æ…¢
    max_cps: int = 110,
    short_len: int = 300,
    long_len: int = 1200,
    punctuation_pause: float = 0.50,  # å¥æœ«å°åœé “
    code_speedup: float = 1.8,
    ph=None
):
    if not full_text:
        return ""
    try:
        import regex as re
        tokens = re.findall(r"\X", full_text)  # ä»¥å­—ç´ å¢é›†æ‹†åˆ†ï¼Œé¿å…åˆ‡å£ emoji/åˆå­—
    except Exception:
        tokens = list(full_text)

    n = len(tokens)
    def lerp(a, b, t): return a + (b - a) * t
    if n <= short_len:
        base_cps = min_cps
    elif n >= long_len:
        base_cps = max_cps
    else:
        t = (n - short_len) / max(1, (long_len - short_len))
        base_cps = lerp(min_cps, max_cps, t)
    per_char_delay = 1.0 / max(1.0, base_cps)

    placeholder = ph or st.empty()
    out, i, inside_code = [], 0, False
    punct = set(".!?;:ï¼Œã€‚ï¼ï¼Ÿï¼šã€â€¦\n")

    def chunk_size(idx):
        if inside_code: return 10
        if idx < 100:   return 1
        if idx < 300:   return 2
        if idx < 1000:  return 3
        return 4

    def render(txt): placeholder.markdown(txt)

    while i < n:
        k = min(chunk_size(i), n - i)
        chunk_tokens = tokens[i:i+k]
        chunk_text = "".join(chunk_tokens)
        i += k

        if "```" in chunk_text and chunk_text.count("```") % 2 == 1:
            inside_code = not inside_code

        intended = per_char_delay * k
        if inside_code:
            intended = max(intended / code_speedup, 0.002)

        last_char = chunk_tokens[-1]
        if last_char in punct and not inside_code:
            intended += per_char_delay * punctuation_pause

        start_t = time.monotonic()
        out.append(chunk_text)
        render("".join(out))
        elapsed = time.monotonic() - start_t
        remain = max(0.0, intended - elapsed)
        time.sleep(remain)

    render("".join(out))
    return "".join(out)

# =========================
# æ®µè½æ·¡å…¥ + é€å­—ï¼ˆç°è‰²å¹½éˆ â†’ æ‰“å­—ï¼‰
# =========================
def split_md_paragraphs(md: str):
    parts, buf, in_code = [], [], False
    for line in md.splitlines(keepends=True):
        if line.strip().startswith("```"):
            in_code = not in_code
            buf.append(line); continue
        if not in_code and line.strip() == "":
            if buf:
                parts.append("".join(buf).strip("\n")); buf=[]
        else:
            buf.append(line)
    if buf: parts.append("".join(buf).strip("\n"))
    return [p for p in parts if p.strip()]

def paragraph_type_with_fade(md_text: str, fade_ms: int = 160):
    paragraphs = split_md_paragraphs(md_text)
    for para in paragraphs:
        ph = st.empty()
        ph.markdown(f":grey[{para}]")       # ç°è‰²å¹½éˆ
        time.sleep(fade_ms / 1000.0)
        emoji_token_stream(para, ph=ph)     # å†é€å­—ï¼ˆç„¡é è¦½ã€ç„¡é–ƒçˆï¼‰
        st.markdown("")                     # æ®µè½é–“è·

# =========================
# æœ€è¿‘ 30 è¼ªä¸Šä¸‹æ–‡
# =========================
MAX_TURNS_CTX = 30        # åªç”¨æœ€è¿‘ 30 å‰‡ï¼ˆuser/assistant åˆè¨ˆï¼‰
MAX_CTX_CHARS = 8000      # é é˜²è¶…é•·ï¼›ä½ å¯ä¾éœ€æ±‚èª¿æ•´

if "messages" not in st.session_state:
    st.session_state.messages = []   # [{"role": "user"/"assistant", "content": str, "images": [(name, bytes), ...]}]

def build_context_snippet(messages, max_turns=MAX_TURNS_CTX, max_chars=MAX_CTX_CHARS):
    recent = messages[-max_turns:]
    lines = []
    for msg in recent:
        role = "ä½¿ç”¨è€…" if msg["role"] == "user" else "åŠ©ç†"
        text = msg.get("content", "").strip()
        if not text:
            continue
        # å£“æ‰å¤šé¤˜ç©ºç™½
        text = " ".join(text.split())
        lines.append(f"{role}: {text}")
    ctx = "\n".join(lines)
    if len(ctx) > max_chars:
        ctx = ctx[-max_chars:]
    return ctx

# =========================
# è¦åŠƒ/æœå°‹/å¯«ä½œ/è·¯ç”± Agents
# =========================
planner_agent_PROMPT = (
    "You are a helpful research assistant. Given a query, come up with a set of web searches "
    "to perform to best answer the query. Output between 5 and 20 terms to query for."
)

class WebSearchItem(BaseModel):
    reason: str
    query: str

class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]

planner_agent = Agent(
    name="PlannerAgent",
    instructions=planner_agent_PROMPT,
    model="gpt-5",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=WebSearchPlan,
)

INSTRUCTIONS = (
    "You are a research assistant. Given a search term, you search the web for that term and "
    "produce a concise summary of the results. The summary must be 2-3 paragraphs and less than 300 "
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
    "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
    "essence and ignore any fluff. Do not include any additional commentary other than the summary "
    "itself."
)

search_agent = Agent(
    name="Search agent",
    model="gpt-4.1",
    instructions=INSTRUCTIONS,
    tools=[WebSearchTool()],
    model_settings=ModelSettings(tool_choice="required"),
)

writer_agent_PROMPT = (
    "You are a senior researcher tasked with writing a cohesive report for a research query. "
    "You will be provided with the original query, and some initial research done by a research "
    "assistant.\n"
    "You should first come up with an outline for the report that describes the structure and "
    "flow of the report. Then, generate the report and return that as your final output.\n"
    "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
    "for 5-10 pages of content, at least 1000 words."
    "è«‹å‹™å¿…ä»¥æ­£é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦éµå¾ªå°ç£ç”¨èªç¿’æ…£"
)

class ReportData(BaseModel):
    short_summary: str
    markdown_report: str
    follow_up_questions: list[str]

writer_agent = Agent(
    name="WriterAgent",
    instructions=writer_agent_PROMPT,
    model="gpt-5-mini",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=ReportData,
)

ROUTER_PROMPT = """
ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œæœƒæ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚è‡ªå‹•æ±ºå®šè¦æ€éº¼è™•ç†å•é¡Œã€‚
- å¦‚æœç”¨æˆ¶çš„å•é¡Œæ˜¯ã€Œéœ€è¦ç ”ç©¶ã€æŸ¥è³‡æ–™ã€åˆ†æã€å¯«å ±å‘Šã€æ–‡ç»æ¢è¨ã€ç­‰ï¼Œè«‹ä½¿ç”¨ transfer_to_planner_agent å·¥å…·ï¼ŒæŠŠå•é¡Œäº¤çµ¦ç ”ç©¶è¦åŠƒåŠ©ç†ã€‚
- å¦‚æœåªæ˜¯ä¸€èˆ¬èŠå¤©ã€çŸ¥è­˜å•ç­”ã€é–’èŠï¼Œè«‹ç›´æ¥ç”¨ä½ è‡ªå·±çš„çŸ¥è­˜å›ç­”ã€‚å¿…è¦çš„æ™‚å€™å¯ä»¥ä½¿ç”¨WebSearchToolä¾†æœå°‹ç¶²è·¯è³‡è¨Šã€‚
è«‹æ ¹æ“šç”¨æˆ¶çš„è¼¸å…¥ï¼Œè‡ªè¡Œåˆ¤æ–·è¦ä¸è¦ handoffã€‚
"""

router_agent = Agent(
    name="RouterAgent",
    instructions=ROUTER_PROMPT,
    model="gpt-5",
    tools=[WebSearchTool()],
    model_settings=ModelSettings(
        reasoning=Reasoning(effort="low"),
        verbosity="medium",
    ),
    handoffs=[handoff(planner_agent)]
)

# =========================
# å¤šæ¨¡æ…‹ç³»çµ±æç¤º
# =========================
VISION_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½å¤šæ¨¡æ…‹åŠ©ç†ã€‚æ”¶åˆ°åœ–ç‰‡èˆ‡ï¼ˆå¯é¸ï¼‰æ–‡å­—æŒ‡ç¤ºæ™‚ï¼š
- å…ˆæè¿°åœ–ç‰‡é—œéµå…§å®¹ï¼ˆç‰©ä»¶ã€æ–‡å­—ã€é—œä¿‚ã€å ´æ™¯ã€ç‰ˆé¢ï¼‰ã€‚
- è‹¥æœ‰å¤šå¼µåœ–ç‰‡ï¼Œè«‹æ¯”è¼ƒå·®ç•°æˆ–å»ºç«‹æ­¥é©Ÿæ¨è«–ã€‚
- é©åº¦çµåˆOCRèˆ‡æ¨ç†ï¼›è‹¥èˆ‡ä½¿ç”¨è€…æå•ç›¸é—œï¼Œæä¾›æ¢åˆ—å¼çµè«–èˆ‡å¯è¡Œå»ºè­°ã€‚
è«‹ä»¥æ­£é«”ä¸­æ–‡ä½œç­”ã€‚
"""

# =========================
# UI èˆ‡æµç¨‹ï¼ˆç²¾ç°¡èŠå¤©ï¼‹é™„ä»¶ï¼‰
# =========================
st.title("AI ç ”ç©¶åŠ©ç† Chat ç‰ˆï¼ˆé™„ä»¶ï¼‹30è¼ªä¸Šä¸‹æ–‡ï¼‹æ·¡å…¥ï¼‰")
st.write("ç›´æ¥åœ¨è¼¸å…¥æ¡†æ‰“å­—ï¼Œæˆ–åŒæ™‚ä¸Šå‚³åœ–ç‰‡ï¼ˆå¤šå¼µå¯ï¼‰ï¼ŒAI æœƒè‡ªå‹•åˆ‡æ›å¤šæ¨¡æ…‹ï¼›ä½¿ç”¨æœ€è¿‘ 30 è¼ªä¸Šä¸‹æ–‡ã€‚")

# é¡¯ç¤ºæ­·å²ï¼ˆç²¾ç°¡ï¼šä½¿ç”¨è€…è¨Šæ¯å¯é¡¯ç¤ºç¸®åœ–ï¼‰
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        if msg.get("content"):
            st.markdown(msg["content"])
        if msg.get("images"):
            try:
                st.image([Image.open(BytesIO(b)) for _, b in msg["images"]], width=220)
            except Exception:
                pass

# ä½¿ç”¨è€…è¼¸å…¥ï¼ˆæ”¯æ´å¤šå¼µåœ–ç‰‡ï¼‰
prompt = st.chat_input(
    "è¼¸å…¥å•é¡Œï¼Œæˆ–ä¸Šå‚³åœ–ç‰‡è®“æˆ‘å¹«ä½ çœ‹åœ–èªªæ•…äº‹ï½",
    accept_file="multiple",
    file_type=["png", "jpg", "jpeg", "webp"]
)

if prompt:
    user_text = prompt.text.strip() if hasattr(prompt, "text") and prompt.text else (prompt.strip() if isinstance(prompt, str) else "")
    files = prompt.files if hasattr(prompt, "files") and prompt.files else []

    content_blocks = []
    images_for_history = []

    if user_text:
        content_blocks.append({"type": "input_text", "text": user_text})

    for f in files:
        imgbytes = f.getbuffer()
        mime = getattr(f, "type", None) or "image/png"
        b64 = base64.b64encode(imgbytes).decode()
        content_blocks.append({"type": "input_image", "image_url": f"data:{mime};base64,{b64}"})
        images_for_history.append((getattr(f, "name", "image"), imgbytes))

    # å¯«å…¥ä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({
        "role": "user",
        "content": user_text,
        "images": images_for_history
    })
    with st.chat_message("user"):
        if user_text:
            st.markdown(user_text)
        if images_for_history:
            st.image([Image.open(BytesIO(b)) for _, b in images_for_history], width=220)

    # åŠ©ç†å›è¦†
    with st.chat_message("assistant"):
        with st.spinner("å®‰å¦®äºåŠªåŠ›æ€è€ƒä¸­â€¦"):
            ctx_snippet = build_context_snippet(st.session_state.messages)

            # æœ‰åœ–ç‰‡ â†’ å¤šæ¨¡æ…‹
            if any(b["type"] == "input_image" for b in content_blocks):
                # æŠŠæœ€è¿‘ 30 è¼ªä¸Šä¸‹æ–‡ä¸Ÿåœ¨æœ€å‰é¢
                if ctx_snippet:
                    content_blocks.insert(0, {"type": "input_text", "text": f"æœ€è¿‘å°è©±ï¼ˆæœ€å¤š30è¼ªï¼‰ï¼š\n{ctx_snippet}"})
                try:
                    resp = client.responses.create(
                        model="gpt-5",
                        input=[{"role": "user", "content": content_blocks}],
                        instructions=VISION_SYSTEM_PROMPT,
                        reasoning={"effort":"medium"},
                        text={"verbosity":"medium"},
                        store=False,
                        truncation="auto",
                    )
                    out_text = ""
                    if hasattr(resp, "output") and resp.output:
                        for item in resp.output:
                            if hasattr(item, "content") and item.content:
                                for c in item.content:
                                    if getattr(c, "type", None) == "output_text":
                                        out_text += c.text
                    if not out_text.strip():
                        out_text = "å®‰å¦®äºçœ‹éäº†ï¼Œä½†é‚„æ²’æŠ“åˆ°ä½ æƒ³å•çš„é‡é»ï½å¯ä»¥å†å…·é«”ä¸€é»å—ï¼Ÿ"

                    paragraph_type_with_fade(out_text, fade_ms=140)

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": out_text,
                        "images": []
                    })

                except Exception as e:
                    err = f"åœ–ç‰‡åˆ†æå¤±æ•—ï¼š{e}"
                    st.error(err)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": err,
                        "images": []
                    })

            else:
                # ç´”æ–‡å­— â†’ å¸¶å…¥æœ€è¿‘30è¼ªä¸Šä¸‹æ–‡çµ¦ Router
                router_input = (
                    (f"[æœ€è¿‘å°è©±]\n{ctx_snippet}\n\n" if ctx_snippet else "") +
                    f"[ç•¶å‰ä½¿ç”¨è€…å•é¡Œ]\n{user_text}"
                )
                router_result = run_async(Runner.run(router_agent, router_input))

                if isinstance(router_result.final_output, WebSearchPlan):
                    # è¦åŠƒ
                    search_plan = router_result.final_output.searches
                    plan_md = "### ğŸ” æœå°‹è¦åŠƒ\n"
                    for idx, item in enumerate(search_plan):
                        plan_md += f"**{idx+1}. {item.query}**\n> {item.reason}\n"

                    # ä¸¦è¡Œæœå°‹
                    tasks = [
                        Runner.run(search_agent, f"Search term: {item.query}\nReason: {item.reason}")
                        for item in search_plan
                    ]
                    results = run_async(asyncio.gather(*tasks))
                    summaries = [str(r.final_output) for r in results]

                    summary_md = "### ğŸ“ å„é …æœå°‹æ‘˜è¦\n"
                    for idx, summary in enumerate(summaries):
                        summary_md += f"**{search_plan[idx].query}**\n{summary}\n\n"

                    with st.expander("ğŸ” æœå°‹è¦åŠƒèˆ‡å„é …æœå°‹æ‘˜è¦", expanded=False):
                        st.markdown("### æœå°‹è¦åŠƒ")
                        for idx, item in enumerate(search_plan):
                            st.markdown(f"**{idx+1}. {item.query}**\n> {item.reason}")
                        st.markdown("### å„é …æœå°‹æ‘˜è¦")
                        for idx, summary in enumerate(summaries):
                            st.markdown(f"**{search_plan[idx].query}**\n{summary}\n")

                    # å¯«ä½œ
                    writer_input = (
                        (f"[æœ€è¿‘å°è©±]\n{ctx_snippet}\n\n" if ctx_snippet else "") +
                        f"[åŸå§‹å•é¡Œ]\n{user_text}\n\n[æœå°‹æ‘˜è¦]\n{summaries}"
                    )
                    report = run_async(Runner.run(writer_agent, writer_input))

                    st.markdown("### ğŸ“‹ Executive Summary")
                    paragraph_type_with_fade(report.final_output.short_summary, fade_ms=120)

                    st.markdown("### ğŸ“– å®Œæ•´å ±å‘Š")
                    paragraph_type_with_fade(report.final_output.markdown_report, fade_ms=160)

                    st.markdown("### â“ å¾ŒçºŒå»ºè­°å•é¡Œ")
                    for q in report.final_output.follow_up_questions:
                        paragraph_type_with_fade(q, fade_ms=100)

                    ai_reply = (
                        plan_md + "\n" +
                        summary_md + "\n" +
                        "#### Executive Summary\n" + report.final_output.short_summary + "\n" +
                        "#### å®Œæ•´å ±å‘Š\n" + report.final_output.markdown_report + "\n" +
                        "#### å¾ŒçºŒå»ºè­°å•é¡Œ\n" + "\n".join([f"- {q}" for q in report.final_output.follow_up_questions])
                    )
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_reply,
                        "images": []
                    })

                else:
                    # ä¸€èˆ¬å°è©±
                    full_text = str(router_result.final_output)
                    paragraph_type_with_fade(full_text, fade_ms=120)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": full_text,
                        "images": []
                    })
