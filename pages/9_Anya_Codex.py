import streamlit as st
import asyncio
from pydantic import BaseModel
import os
import nest_asyncio
nest_asyncio.apply()

from openai.types.shared.reasoning import Reasoning
from agents import Agent, ModelSettings, WebSearchTool, Runner, handoff

# å¤šæ¨¡æ…‹éœ€è¦çš„å·¥å…·
import base64
from io import BytesIO
from PIL import Image
from openai import OpenAI
import time

# =========================
# åŸºæœ¬ç’°å¢ƒè¨­å®š
# =========================
st.set_page_config(page_title="AI ç ”ç©¶åŠ©ç† Chatï¼ˆst.chat_input é™„ä»¶ç‰ˆï¼‰", layout="wide", page_icon="ğŸ¤–")
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_KEY"]

def run_async(coro):
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(coro)

# =========================
# æ‰“å­—å‹•ç•«ï¼ˆç„¡åœæ­¢åŠŸèƒ½ã€åªæœ‰ emojiï¼Œç¯€å¥ç¨æ…¢ï¼‰
# =========================
def emoji_token_stream(
    full_text: str,
    emoji: str = "ğŸŒ¸",
    min_cps: int = 20,
    max_cps: int = 110,
    short_len: int = 300,
    long_len: int = 1200,
    punctuation_pause: float = 0.50,
    preview_ratio: float = 0.40,
    code_speedup: float = 1.8,
    ph=None
):
    if not full_text:
        return ""
    try:
        import regex as re
        tokens = re.findall(r"\X", full_text)
    except Exception:
        tokens = list(full_text)

    n = len(tokens)
    def lerp(a, b, t): return a + (b - a) * t
    if n <= short_len:
        base_cps = min_cps
    elif n >= long_len:
        base_cps = max_cps
    else:
        t = (n - short_len) / max(1, (long_len - short_len))
        base_cps = lerp(min_cps, max_cps, t)
    per_char_delay = 1.0 / max(1.0, base_cps)

    placeholder = ph or st.empty()
    out, i, inside_code = [], 0, False
    punct = set(".!?;:ï¼Œã€‚ï¼ï¼Ÿï¼šã€â€¦\n")

    def chunk_size(idx):
        if inside_code: return 8
        if idx < 80:    return 1
        if idx < 240:   return 2
        if idx < 900:   return 3
        return 4

    def render(txt): placeholder.markdown(txt)

    while i < n:
        k = min(chunk_size(i), n - i)
        chunk_tokens = tokens[i:i+k]
        chunk_text = "".join(chunk_tokens)
        i += k

        if "```" in chunk_text:
            if chunk_text.count("```") % 2 == 1:
                inside_code = not inside_code

        intended = per_char_delay * k
        if inside_code:
            intended = max(intended / code_speedup, 0.002)

        last_char = chunk_tokens[-1]
        if last_char in punct and not inside_code:
            intended += per_char_delay * punctuation_pause

        start_t = time.monotonic()

        # é è¦½ï¼šåªæœ‰ emoji
        current_text = "".join(out)
        if not inside_code:
            render(current_text + emoji)
            time.sleep(min(intended * preview_ratio, 0.07))

        # æ­£å¼å¯«å…¥
        out.append(chunk_text)
        render("".join(out))

        elapsed = time.monotonic() - start_t
        remain = max(0.0, intended - elapsed)
        time.sleep(remain)

    render("".join(out))
    return "".join(out)

# =========================
# æ®µè½æ·¡å…¥ + é€å­—ï¼ˆæ–¹æ¡ˆ2ï¼‰
# =========================
def split_md_paragraphs(md: str):
    parts, buf, in_code = [], [], False
    for line in md.splitlines(keepends=True):
        if line.strip().startswith("```"):
            in_code = not in_code
            buf.append(line); continue
        if not in_code and line.strip() == "":
            if buf:
                parts.append("".join(buf).strip("\n")); buf=[]
        else:
            buf.append(line)
    if buf: parts.append("".join(buf).strip("\n"))
    return [p for p in parts if p.strip()]

def paragraph_type_with_fade(md_text: str, emoji: str = "ğŸŒ¸", fade_ms: int = 160):
    paragraphs = split_md_paragraphs(md_text)
    for para in paragraphs:
        ph = st.empty()
        ph.markdown(f":grey[{para}]")
        time.sleep(fade_ms / 1000.0)
        emoji_token_stream(para, emoji=emoji, ph=ph)
        st.markdown("")

# =========================
# å¤šæ¨¡æ…‹ç³»çµ±æç¤º
# =========================
client = OpenAI(api_key=st.secrets["OPENAI_KEY"])
VISION_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½å¤šæ¨¡æ…‹åŠ©ç†ã€‚æ”¶åˆ°åœ–ç‰‡èˆ‡ï¼ˆå¯é¸ï¼‰æ–‡å­—æŒ‡ç¤ºæ™‚ï¼š
- å…ˆæè¿°åœ–ç‰‡é—œéµå…§å®¹ï¼ˆç‰©ä»¶ã€æ–‡å­—ã€é—œä¿‚ã€å ´æ™¯ã€ç‰ˆé¢ï¼‰ã€‚
- è‹¥æœ‰å¤šå¼µåœ–ç‰‡ï¼Œè«‹æ¯”è¼ƒå·®ç•°æˆ–å»ºç«‹æ­¥é©Ÿæ¨è«–ã€‚
- é©åº¦çµåˆOCRèˆ‡æ¨ç†ï¼›è‹¥èˆ‡ä½¿ç”¨è€…æå•ç›¸é—œï¼Œæä¾›æ¢åˆ—å¼çµè«–èˆ‡å¯è¡Œå»ºè­°ã€‚
è«‹ä»¥æ­£é«”ä¸­æ–‡ä½œç­”ã€‚
"""

# =========================
# è¦åŠƒ/æœå°‹/å¯«ä½œ/è·¯ç”± Agents
# =========================
planner_agent_PROMPT = (
    "You are a helpful research assistant. Given a query, come up with a set of web searches "
    "to perform to best answer the query. Output between 5 and 20 terms to query for."
)

class WebSearchItem(BaseModel):
    reason: str
    query: str

class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]

planner_agent = Agent(
    name="PlannerAgent",
    instructions=planner_agent_PROMPT if (planner_agent_PROMPT:=planner_agent_PROMPT) else "",
    model="gpt-5",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=WebSearchPlan,
)

INSTRUCTIONS = (
    "You are a research assistant. Given a search term, you search the web for that term and "
    "produce a concise summary of the results. The summary must be 2-3 paragraphs and less than 300 "
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
    "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
    "essence and ignore any fluff. Do not include any additional commentary other than the summary "
    "itself."
)

search_agent = Agent(
    name="Search agent",
    model="gpt-4.1",
    instructions=INSTRUCTIONS,
    tools=[WebSearchTool()],
    model_settings=ModelSettings(tool_choice="required"),
)

writer_agent_PROMPT = (
    "You are a senior researcher tasked with writing a cohesive report for a research query. "
    "You will be provided with the original query, and some initial research done by a research "
    "assistant.\n"
    "You should first come up with an outline for the report that describes the structure and "
    "flow of the report. Then, generate the report and return that as your final output.\n"
    "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
    "for 5-10 pages of content, at least 1000 words."
    "è«‹å‹™å¿…ä»¥æ­£é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦éµå¾ªå°ç£ç”¨èªç¿’æ…£"
)

class ReportData(BaseModel):
    short_summary: str
    markdown_report: str
    follow_up_questions: list[str]

writer_agent = Agent(
    name="WriterAgent",
    instructions=writer_agent_PROMPT,
    model="gpt-5-mini",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=ReportData,
)

ROUTER_PROMPT = """
ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œæœƒæ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚è‡ªå‹•æ±ºå®šè¦æ€éº¼è™•ç†å•é¡Œã€‚
- å¦‚æœç”¨æˆ¶çš„å•é¡Œæ˜¯ã€Œéœ€è¦ç ”ç©¶ã€æŸ¥è³‡æ–™ã€åˆ†æã€å¯«å ±å‘Šã€æ–‡ç»æ¢è¨ã€ç­‰ï¼Œè«‹ä½¿ç”¨ transfer_to_planner_agent å·¥å…·ï¼ŒæŠŠå•é¡Œäº¤çµ¦ç ”ç©¶è¦åŠƒåŠ©ç†ã€‚
- å¦‚æœåªæ˜¯ä¸€èˆ¬èŠå¤©ã€çŸ¥è­˜å•ç­”ã€é–’èŠï¼Œè«‹ç›´æ¥ç”¨ä½ è‡ªå·±çš„çŸ¥è­˜å›ç­”ã€‚å¿…è¦çš„æ™‚å€™å¯ä»¥ä½¿ç”¨WebSearchToolä¾†æœå°‹ç¶²è·¯è³‡è¨Šã€‚
è«‹æ ¹æ“šç”¨æˆ¶çš„è¼¸å…¥ï¼Œè‡ªè¡Œåˆ¤æ–·è¦ä¸è¦ handoffã€‚
"""

router_agent = Agent(
    name="RouterAgent",
    instructions=ROUTER_PROMPT,
    model="gpt-5",
    tools=[WebSearchTool()],
    model_settings=ModelSettings(
        reasoning=Reasoning(effort="low"),
        verbosity="medium",
    ),
    handoffs=[handoff(planner_agent)]
)

# =========================
# ä»‹é¢èˆ‡ä¸»è¦æµç¨‹ï¼ˆç²¾ç°¡èŠå¤©å€ï¼‹é™„ä»¶ï¼‰
# =========================
st.title("AI ç ”ç©¶åŠ©ç† Chat ç‰ˆï¼ˆç²¾ç°¡èŠå¤©ï¼‹é™„ä»¶ä¸Šå‚³ï¼‰")
st.write("ç›´æ¥åœ¨è¼¸å…¥æ¡†è²¼æ–‡å­—ï¼Œæˆ–ä¸€èµ·ä¸Šå‚³åœ–ç‰‡ï¼ŒAI æœƒè‡ªå‹•åˆ‡æ›åˆ°å¤šæ¨¡æ…‹æ¨¡å¼å–”ï½")

# åˆå§‹åŒ–å°è©±æ­·å²ï¼ˆåŠ å…¥ images æ¬„ä½ï¼‰
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºæ­·å²è¨Šæ¯ï¼ˆç²¾ç°¡ï¼šåªåœ¨ä½¿ç”¨è€…è¨Šæ¯ä¸­é¡¯ç¤ºç¸®åœ–ï¼‰
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        # æ–‡å­—
        if msg.get("content"):
            st.markdown(msg["content"])
        # åœ–ç‰‡ï¼ˆåªæœ‰ user ç«¯å¯èƒ½æœ‰ï¼‰
        if msg.get("images"):
            thumbs = []
            for name, imgbytes in msg["images"]:
                try:
                    thumbs.append(Image.open(BytesIO(imgbytes)))
                except Exception:
                    pass
            if thumbs:
                st.image(thumbs, width=220)

# ä½¿ç”¨è€…è¼¸å…¥ï¼ˆæ”¯æ´å¤šå¼µåœ–ç‰‡ï¼‰
prompt = st.chat_input(
    "è¼¸å…¥å•é¡Œï¼Œæˆ–ä¸€èµ·ä¸Šå‚³åœ–ç‰‡è®“æˆ‘å¹«ä½ çœ‹åœ–èªªæ•…äº‹ï½",
    accept_file="multiple",
    file_type=["png", "jpg", "jpeg", "webp"]
)

if prompt:
    # å…¼å®¹ï¼šæœ‰äº›ç‰ˆæœ¬å›å‚³å­—ä¸²ï¼›æœ‰äº›å›å‚³å¸¶ text/files çš„ç‰©ä»¶
    user_text = prompt.text.strip() if hasattr(prompt, "text") and prompt.text else (prompt.strip() if isinstance(prompt, str) else "")
    files = prompt.files if hasattr(prompt, "files") and prompt.files else []

    # å°‡åœ–ç‰‡è½‰ base64ï¼Œä¸åœ¨é€™è£¡é¡¯ç¤ºexpanderï¼Œä¿æŒèŠå¤©å€ç°¡æ½”
    content_blocks = []
    images_for_history = []

    if user_text:
        content_blocks.append({"type": "input_text", "text": user_text})

    for f in files:
        imgbytes = f.getbuffer()
        mime = getattr(f, "type", None) or "image/png"
        b64 = base64.b64encode(imgbytes).decode()
        content_blocks.append({
            "type": "input_image",
            "image_url": f"data:{mime};base64,{b64}"
        })
        images_for_history.append((getattr(f, "name", "image"), imgbytes))

    # æŠŠä½¿ç”¨è€…è¨Šæ¯ï¼ˆå«ç¸®åœ–ï¼‰å¯«å…¥æ­·å²ä¸¦é¡¯ç¤º
    st.session_state.messages.append({
        "role": "user",
        "content": user_text,
        "images": images_for_history
    })
    with st.chat_message("user"):
        if user_text:
            st.markdown(user_text)
        if images_for_history:
            st.image([Image.open(BytesIO(b)) for _, b in images_for_history], width=220)

    # åŠ©ç†å›è¦†
    with st.chat_message("assistant"):
        with st.spinner("å®‰å¦®äºåŠªåŠ›æ€è€ƒä¸­â€¦"):
            # å¦‚æœæœ‰åœ–ç‰‡ï¼Œèµ°å¤šæ¨¡æ…‹ï¼›å¦å‰‡èµ°ç ”ç©¶/ä¸€èˆ¬èŠå¤©è·¯ç·š
            if any(block["type"] == "input_image" for block in content_blocks):
                try:
                    resp = client.responses.create(
                        model="gpt-5",
                        input=[{"role": "user", "content": content_blocks}],
                        instructions=VISION_SYSTEM_PROMPT,
                        reasoning={"effort": "medium"},
                        text={"verbosity": "medium"},
                        store=False,
                        truncation="auto",
                    )
                    out_text = ""
                    if hasattr(resp, "output") and resp.output:
                        for item in resp.output:
                            if hasattr(item, "content") and item.content:
                                for c in item.content:
                                    if getattr(c, "type", None) == "output_text":
                                        out_text += c.text
                    if not out_text.strip():
                        out_text = "å®‰å¦®äºçœ‹éäº†ï¼Œä½†é‚„æ²’æŠ“åˆ°ä½ æƒ³å•çš„é‡é»ï½å¯ä»¥å†å…·é«”ä¸€é»å—ï¼Ÿ"

                    # é¡¯ç¤ºï¼šæ®µè½æ·¡å…¥ï¼‹é€å­—
                    paragraph_type_with_fade(out_text, emoji="ğŸŒ¸", fade_ms=140)

                    # å¯«å…¥æ­·å²
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": out_text,
                        "images": []
                    })

                except Exception as e:
                    err = f"åœ–ç‰‡åˆ†æå¤±æ•—ï¼š{e}"
                    st.error(err)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": err,
                        "images": []
                    })

            else:
                # ç´”æ–‡å­—ï¼šè®“ Router æ±ºå®šæ˜¯å¦ handoff åšç ”ç©¶
                router_result = run_async(Runner.run(router_agent, user_text))

                if isinstance(router_result.final_output, WebSearchPlan):
                    # Step 1 è¦åŠƒ
                    search_plan = router_result.final_output.searches
                    plan_md = "### ğŸ” æœå°‹è¦åŠƒ\n"
                    for idx, item in enumerate(search_plan):
                        plan_md += f"**{idx+1}. {item.query}**\n> {item.reason}\n"

                    # Step 2 ä¸¦è¡Œæœå°‹
                    tasks = [
                        Runner.run(search_agent, f"Search term: {item.query}\nReason: {item.reason}")
                        for item in search_plan
                    ]
                    results = run_async(asyncio.gather(*tasks))
                    summaries = [str(r.final_output) for r in results]

                    summary_md = "### ğŸ“ å„é …æœå°‹æ‘˜è¦\n"
                    for idx, summary in enumerate(summaries):
                        summary_md += f"**{search_plan[idx].query}**\n{summary}\n\n"

                    with st.expander("ğŸ” æœå°‹è¦åŠƒèˆ‡å„é …æœå°‹æ‘˜è¦", expanded=False):
                        st.markdown("### æœå°‹è¦åŠƒ")
                        for idx, item in enumerate(search_plan):
                            st.markdown(f"**{idx+1}. {item.query}**\n> {item.reason}")
                        st.markdown("### å„é …æœå°‹æ‘˜è¦")
                        for idx, summary in enumerate(summaries):
                            st.markdown(f"**{search_plan[idx].query}**\n{summary}\n")

                    # Step 3 å¯«ä½œ
                    writer_input = f"Original query: {user_text}\nSummarized search results: {summaries}"
                    report = run_async(Runner.run(writer_agent, writer_input))

                    st.markdown("### ğŸ“‹ Executive Summary")
                    emoji_token_stream(report.final_output.short_summary, emoji="ğŸŒŸ")

                    st.markdown("### ğŸ“– å®Œæ•´å ±å‘Š")
                    paragraph_type_with_fade(report.final_output.markdown_report, emoji="ğŸŒ¸", fade_ms=160)

                    st.markdown("### â“ å¾ŒçºŒå»ºè­°å•é¡Œ")
                    for q in report.final_output.follow_up_questions:
                        emoji_token_stream(q, emoji="ğŸ¥œ")

                    ai_reply = (
                        plan_md + "\n" +
                        summary_md + "\n" +
                        "#### Executive Summary\n" + report.final_output.short_summary + "\n" +
                        "#### å®Œæ•´å ±å‘Š\n" + report.final_output.markdown_report + "\n" +
                        "#### å¾ŒçºŒå»ºè­°å•é¡Œ\n" + "\n".join([f"- {q}" for q in report.final_output.follow_up_questions])
                    )
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_reply,
                        "images": []
                    })

                else:
                    # ä¸€èˆ¬å°è©±
                    full_text = str(router_result.final_output)
                    emoji_token_stream(full_text, emoji="ğŸŒ¸")
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": full_text,
                        "images": []
                    })
