import streamlit as st
import asyncio
from pydantic import BaseModel
import os
import nest_asyncio
nest_asyncio.apply()

from openai.types.shared.reasoning import Reasoning
from agents import Agent, ModelSettings, WebSearchTool, Runner, handoff

# å¤šæ¨¡æ…‹
import base64
from io import BytesIO
from PIL import Image
from openai import OpenAI
import time

# =========================
# åŸºæœ¬ç’°å¢ƒè¨­å®š
# =========================
st.set_page_config(page_title="Anyaç ”ç©¶åŠ©ç†(æ¸¬è©¦ä¸­)", layout="wide", page_icon="ğŸ¤–")
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_KEY"]

client = OpenAI(api_key=st.secrets["OPENAI_KEY"])

def run_async(coro):
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(coro)

# =========================
# é€å­—å‹•ç•«
# =========================
def emoji_token_stream(
    full_text: str,
    prefix_emoji: str | None = "ğŸŒ¸",  # å›ºå®šåœ¨æœ€å‰é¢é¡¯ç¤ºä¸€æ¬¡ï¼Œä¸æœƒé–ƒ
    min_cps: int = 20,
    max_cps: int = 110,
    short_len: int = 300,
    long_len: int = 1200,
    punctuation_pause: float = 0.50,
    code_speedup: float = 1.8,
    ph=None
):
    import time, streamlit as st
    if not full_text:
        return ""

    try:
        import regex as re
        tokens = re.findall(r"\X", full_text)  # ä»¥å­—ç´ å¢é›†æ‹†åˆ†ï¼Œé¿å…åˆ‡å£ emoji/åˆå­—
    except Exception:
        tokens = list(full_text)

    n = len(tokens)
    def lerp(a,b,t): return a + (b - a) * t
    if n <= short_len: base_cps = min_cps
    elif n >= long_len: base_cps = max_cps
    else:
        t = (n - short_len) / max(1, (long_len - short_len))
        base_cps = lerp(min_cps, max_cps, t)
    per_char_delay = 1.0 / max(1.0, base_cps)

    placeholder = ph or st.empty()
    out, i = [], 0
    inside_code = False
    punct = set(".!?;:ï¼Œã€‚ï¼ï¼Ÿï¼šã€â€¦\n")
    emoji_prefix_rendered = False

    def chunk_size(idx):
        if inside_code: return 10
        if idx < 100:   return 1
        if idx < 300:   return 2
        if idx < 1000:  return 3
        return 4

    def render():
        prefix = ""
        if (not inside_code) and (prefix_emoji is not None):
            prefix = (prefix_emoji + " ") if (not emoji_prefix_rendered) else ""
        placeholder.markdown(prefix + "".join(out))

    while i < n:
        k = min(chunk_size(i), n - i)
        chunk_tokens = tokens[i:i+k]
        chunk_text = "".join(chunk_tokens)
        i += k

        if "```" in chunk_text and (chunk_text.count("```") % 2 == 1):
            inside_code = not inside_code

        intended = per_char_delay * k
        if inside_code:
            intended = max(intended / code_speedup, 0.002)

        last_char = chunk_tokens[-1]
        if (last_char in punct) and (not inside_code):
            intended += per_char_delay * punctuation_pause

        start_t = time.monotonic()
        out.append(chunk_text)

        if (not inside_code) and (prefix_emoji is not None) and (not emoji_prefix_rendered):
            emoji_prefix_rendered = True

        render()
        elapsed = time.monotonic() - start_t
        remain = max(0.0, intended - elapsed)
        time.sleep(remain)

    render()
    return "".join(out)


def split_md_paragraphs(md: str):
    parts, buf, in_code = [], [], False
    for line in md.splitlines(keepends=True):
        if line.strip().startswith("```"):
            in_code = not in_code
            buf.append(line); continue
        if (not in_code) and (line.strip() == ""):
            if buf:
                parts.append("".join(buf).strip("\n")); buf=[]
        else:
            buf.append(line)
    if buf: parts.append("".join(buf).strip("\n"))
    return [p for p in parts if p.strip()]


def paragraph_type_with_fade(
    md_text: str,
    prefix_emoji: str = "ğŸŒ¸",
    fade_ms: int = 360,         # èª¿é•·ï¼Œæ·¡å…¥æ›´æ˜é¡¯
    two_step_ghost: bool = True # å…©æ®µå¼ï¼šæ–œé«”å¼•ç”¨ â†’ æ™®é€šå¼•ç”¨ â†’ æ­£å¸¸é€å­—
):
    """
    ç”¨ç´” Markdown çš„å¼•ç”¨ï¼ˆ>ï¼‰ç•¶ä½œã€Œç°è‰²å¹½éˆã€ï¼š
    - Step A: æ–œé«”å¼•ç”¨ï¼ˆæ›´æ·¡ï¼‰
    - Step B: æ™®é€šå¼•ç”¨ï¼ˆè¼ƒæ¿ƒï¼‰
    - Step C: é€å­—è¼¸å‡ºï¼ˆå¸¶å›ºå®šå‰ç¶´ emojiï¼‰
    æ³¨æ„ï¼šcode å€å¡Šè‡ªå‹•é—œé–‰ emoji å‰ç¶´ä¸¦è·³éå¹½éˆæ­¥é©Ÿï¼Œé¿å…ç ´ç‰ˆã€‚
    """
    import time, streamlit as st

    paragraphs = split_md_paragraphs(md_text)
    for para in paragraphs:
        ph = st.empty()
        is_code = para.strip().startswith("```")
        prefix = "" if is_code else (prefix_emoji + " ")

        if two_step_ghost and not is_code:
            # Step Aï¼šæ–œé«”å¼•ç”¨ï¼ˆæ›´æ·¡ï¼‰
            ph.markdown(f"> _{prefix}{para}_")
            time.sleep(fade_ms * 0.55 / 1000.0)

        # Step Bï¼šæ™®é€šå¼•ç”¨ï¼ˆæ›´æ¸…æ¥šï¼‰
        if not is_code:
            ph.markdown(f"> {prefix}{para}")
            time.sleep(fade_ms * (0.45 if two_step_ghost else 1.0) / 1000.0)
        else:
            # code ç›´æ¥ç•¥éå¹½éˆï¼Œä»€éº¼éƒ½ä¸åšï¼Œå¾€ä¸‹é€²é€å­—
            pass

        # Step Cï¼šæ­£å¼é€å­—ï¼ˆåŒä¸€å€‹ placeholder è¦†è“‹ï¼Œé¿å…é–ƒçˆï¼‰
        emoji_token_stream(para, prefix_emoji=None if is_code else prefix_emoji, ph=ph)
        st.markdown("")  # æ®µè½é–“è·

# =========================
# æœ€è¿‘ 30 è¼ªä¸Šä¸‹æ–‡
# =========================
MAX_TURNS_CTX = 30        # åªç”¨æœ€è¿‘ 30 å‰‡ï¼ˆuser/assistant åˆè¨ˆï¼‰
MAX_CTX_CHARS = 8000      # é é˜²è¶…é•·ï¼›ä½ å¯ä¾éœ€æ±‚èª¿æ•´

if "messages" not in st.session_state:
    st.session_state.messages = []   # [{"role": "user"/"assistant", "content": str, "images": [(name, bytes), ...]}]

def build_context_snippet(messages, max_turns=MAX_TURNS_CTX, max_chars=MAX_CTX_CHARS):
    recent = messages[-max_turns:]
    lines = []
    for msg in recent:
        role = "ä½¿ç”¨è€…" if msg["role"] == "user" else "åŠ©ç†"
        text = msg.get("content", "").strip()
        if not text:
            continue
        # å£“æ‰å¤šé¤˜ç©ºç™½
        text = " ".join(text.split())
        lines.append(f"{role}: {text}")
    ctx = "\n".join(lines)
    if len(ctx) > max_chars:
        ctx = ctx[-max_chars:]
    return ctx

# =========================
# è¦åŠƒ/æœå°‹/å¯«ä½œ/è·¯ç”± Agents
# =========================
planner_agent_PROMPT = (
    "You are a helpful research assistant. Given a query, come up with a set of web searches "
    "to perform to best answer the query. Output between 5 and 20 terms to query for."
)

class WebSearchItem(BaseModel):
    reason: str
    query: str

class WebSearchPlan(BaseModel):
    searches: list[WebSearchItem]

planner_agent = Agent(
    name="PlannerAgent",
    instructions=planner_agent_PROMPT,
    model="gpt-5",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=WebSearchPlan,
)

INSTRUCTIONS = (
    "You are a research assistant. Given a search term, you search the web for that term and "
    "produce a concise summary of the results. The summary must be 2-3 paragraphs and less than 300 "
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good "
    "grammar. This will be consumed by someone synthesizing a report, so its vital you capture the "
    "essence and ignore any fluff. Do not include any additional commentary other than the summary "
    "itself."
)

search_agent = Agent(
    name="Search agent",
    model="gpt-4.1",
    instructions=INSTRUCTIONS,
    tools=[WebSearchTool()],
    model_settings=ModelSettings(tool_choice="required"),
)

writer_agent_PROMPT = (
    "You are a senior researcher tasked with writing a cohesive report for a research query. "
    "You will be provided with the original query, and some initial research done by a research "
    "assistant.\n"
    "You should first come up with an outline for the report that describes the structure and "
    "flow of the report. Then, generate the report and return that as your final output.\n"
    "The final output should be in markdown format, and it should be lengthy and detailed. Aim "
    "for 5-10 pages of content, at least 1000 words."
    "è«‹å‹™å¿…ä»¥æ­£é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦éµå¾ªå°ç£ç”¨èªç¿’æ…£"
)

class ReportData(BaseModel):
    short_summary: str
    markdown_report: str
    follow_up_questions: list[str]

writer_agent = Agent(
    name="WriterAgent",
    instructions=writer_agent_PROMPT,
    model="gpt-5-mini",
    model_settings=ModelSettings(reasoning=Reasoning(effort="medium")),
    output_type=ReportData,
)

ROUTER_PROMPT = """
ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œæœƒæ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚è‡ªå‹•æ±ºå®šè¦æ€éº¼è™•ç†å•é¡Œã€‚
- å¦‚æœç”¨æˆ¶çš„å•é¡Œæ˜¯ã€Œéœ€è¦ç ”ç©¶ã€æŸ¥è³‡æ–™ã€åˆ†æã€å¯«å ±å‘Šã€æ–‡ç»æ¢è¨ã€ç­‰ï¼Œè«‹ä½¿ç”¨ transfer_to_planner_agent å·¥å…·ï¼ŒæŠŠå•é¡Œäº¤çµ¦ç ”ç©¶è¦åŠƒåŠ©ç†ã€‚
- å¦‚æœåªæ˜¯ä¸€èˆ¬èŠå¤©ã€çŸ¥è­˜å•ç­”ã€é–’èŠï¼Œè«‹ç›´æ¥ç”¨ä½ è‡ªå·±çš„çŸ¥è­˜å›ç­”ã€‚å¿…è¦çš„æ™‚å€™å¯ä»¥ä½¿ç”¨WebSearchToolä¾†æœå°‹ç¶²è·¯è³‡è¨Šã€‚
è«‹æ ¹æ“šç”¨æˆ¶çš„è¼¸å…¥ï¼Œè‡ªè¡Œåˆ¤æ–·è¦ä¸è¦ handoffã€‚
"""

router_agent = Agent(
    name="RouterAgent",
    instructions=ROUTER_PROMPT,
    model="gpt-5",
    tools=[WebSearchTool()],
    model_settings=ModelSettings(
        reasoning=Reasoning(effort="low"),
        verbosity="medium",
    ),
    handoffs=[handoff(planner_agent)]
)

# =========================
# å¤šæ¨¡æ…‹ç³»çµ±æç¤º
# =========================
VISION_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½å¤šæ¨¡æ…‹åŠ©ç†ã€‚æ”¶åˆ°åœ–ç‰‡èˆ‡ï¼ˆå¯é¸ï¼‰æ–‡å­—æŒ‡ç¤ºæ™‚ï¼š
- å…ˆæè¿°åœ–ç‰‡é—œéµå…§å®¹ï¼ˆç‰©ä»¶ã€æ–‡å­—ã€é—œä¿‚ã€å ´æ™¯ã€ç‰ˆé¢ï¼‰ã€‚
- è‹¥æœ‰å¤šå¼µåœ–ç‰‡ï¼Œè«‹æ¯”è¼ƒå·®ç•°æˆ–å»ºç«‹æ­¥é©Ÿæ¨è«–ã€‚
- é©åº¦çµåˆOCRèˆ‡æ¨ç†ï¼›è‹¥èˆ‡ä½¿ç”¨è€…æå•ç›¸é—œï¼Œæä¾›æ¢åˆ—å¼çµè«–èˆ‡å¯è¡Œå»ºè­°ã€‚
è«‹ä»¥æ­£é«”ä¸­æ–‡ä½œç­”ã€‚
"""

# =========================
# UI èˆ‡æµç¨‹ï¼ˆç²¾ç°¡èŠå¤©ï¼‹é™„ä»¶ï¼‰
# =========================
st.title("Anyaç ”ç©¶åŠ©ç†(æ¸¬è©¦ä¸­)")

# é¡¯ç¤ºæ­·å²ï¼ˆç²¾ç°¡ï¼šä½¿ç”¨è€…è¨Šæ¯å¯é¡¯ç¤ºç¸®åœ–ï¼‰
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        if msg.get("content"):
            st.markdown(msg["content"])
        if msg.get("images"):
            try:
                st.image([Image.open(BytesIO(b)) for _, b in msg["images"]], width=220)
            except Exception:
                pass

# ä½¿ç”¨è€…è¼¸å…¥ï¼ˆæ”¯æ´å¤šå¼µåœ–ç‰‡ï¼‰
prompt = st.chat_input(
    "è¼¸å…¥å•é¡Œï¼Œæˆ–ä¸Šå‚³åœ–ç‰‡è®“æˆ‘å¹«ä½ çœ‹åœ–èªªæ•…äº‹ï½",
    accept_file="multiple",
    file_type=["png", "jpg", "jpeg", "webp"]
)

if prompt:
    user_text = prompt.text.strip() if hasattr(prompt, "text") and prompt.text else (prompt.strip() if isinstance(prompt, str) else "")
    files = prompt.files if hasattr(prompt, "files") and prompt.files else []

    content_blocks = []
    images_for_history = []

    if user_text:
        content_blocks.append({"type": "input_text", "text": user_text})

    for f in files:
        imgbytes = f.getbuffer()
        mime = getattr(f, "type", None) or "image/png"
        b64 = base64.b64encode(imgbytes).decode()
        content_blocks.append({"type": "input_image", "image_url": f"data:{mime};base64,{b64}"})
        images_for_history.append((getattr(f, "name", "image"), imgbytes))

    # å¯«å…¥ä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({
        "role": "user",
        "content": user_text,
        "images": images_for_history
    })
    with st.chat_message("user"):
        if user_text:
            st.markdown(user_text)
        if images_for_history:
            st.image([Image.open(BytesIO(b)) for _, b in images_for_history], width=220)

    # åŠ©ç†å›è¦†
    with st.chat_message("assistant"):
        with st.spinner("å®‰å¦®äºåŠªåŠ›æ€è€ƒä¸­â€¦", show_time=False):
            ctx_snippet = build_context_snippet(st.session_state.messages)

            # æœ‰åœ–ç‰‡ â†’ å¤šæ¨¡æ…‹
            if any(b["type"] == "input_image" for b in content_blocks):
                # æŠŠæœ€è¿‘ 30 è¼ªä¸Šä¸‹æ–‡ä¸Ÿåœ¨æœ€å‰é¢
                if ctx_snippet:
                    content_blocks.insert(0, {"type": "input_text", "text": f"æœ€è¿‘å°è©±ï¼ˆæœ€å¤š30è¼ªï¼‰ï¼š\n{ctx_snippet}"})
                try:
                    resp = client.responses.create(
                        model="gpt-5",
                        input=[{"role": "user", "content": content_blocks}],
                        instructions=VISION_SYSTEM_PROMPT,
                        reasoning={"effort":"medium"},
                        text={"verbosity":"medium"},
                        store=False,
                        truncation="auto",
                    )
                    out_text = ""
                    if hasattr(resp, "output") and resp.output:
                        for item in resp.output:
                            if hasattr(item, "content") and item.content:
                                for c in item.content:
                                    if getattr(c, "type", None) == "output_text":
                                        out_text += c.text
                    if not out_text.strip():
                        out_text = "å®‰å¦®äºçœ‹éäº†ï¼Œä½†é‚„æ²’æŠ“åˆ°ä½ æƒ³å•çš„é‡é»ï½å¯ä»¥å†å…·é«”ä¸€é»å—ï¼Ÿ"

                    paragraph_type_with_fade(out_text, fade_ms=140)

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": out_text,
                        "images": []
                    })

                except Exception as e:
                    err = f"åœ–ç‰‡åˆ†æå¤±æ•—ï¼š{e}"
                    st.error(err)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": err,
                        "images": []
                    })

            else:
                # ç´”æ–‡å­— â†’ å¸¶å…¥æœ€è¿‘30è¼ªä¸Šä¸‹æ–‡çµ¦ Router
                router_input = (
                    (f"[æœ€è¿‘å°è©±]\n{ctx_snippet}\n\n" if ctx_snippet else "") +
                    f"[ç•¶å‰ä½¿ç”¨è€…å•é¡Œ]\n{user_text}"
                )
                router_result = run_async(Runner.run(router_agent, router_input))

                if isinstance(router_result.final_output, WebSearchPlan):
                    # è¦åŠƒ
                    search_plan = router_result.final_output.searches
                    plan_md = "### ğŸ” æœå°‹è¦åŠƒ\n"
                    for idx, item in enumerate(search_plan):
                        plan_md += f"**{idx+1}. {item.query}**\n> {item.reason}\n"

                    # ä¸¦è¡Œæœå°‹
                    tasks = [
                        Runner.run(search_agent, f"Search term: {item.query}\nReason: {item.reason}")
                        for item in search_plan
                    ]
                    results = run_async(asyncio.gather(*tasks))
                    summaries = [str(r.final_output) for r in results]

                    summary_md = "### ğŸ“ å„é …æœå°‹æ‘˜è¦\n"
                    for idx, summary in enumerate(summaries):
                        summary_md += f"**{search_plan[idx].query}**\n{summary}\n\n"

                    with st.expander("ğŸ” æœå°‹è¦åŠƒèˆ‡å„é …æœå°‹æ‘˜è¦", expanded=False):
                        st.markdown("### æœå°‹è¦åŠƒ")
                        for idx, item in enumerate(search_plan):
                            st.markdown(f"**{idx+1}. {item.query}**\n> {item.reason}")
                        st.markdown("### å„é …æœå°‹æ‘˜è¦")
                        for idx, summary in enumerate(summaries):
                            st.markdown(f"**{search_plan[idx].query}**\n{summary}\n")

                    # å¯«ä½œ
                    writer_input = (
                        (f"[æœ€è¿‘å°è©±]\n{ctx_snippet}\n\n" if ctx_snippet else "") +
                        f"[åŸå§‹å•é¡Œ]\n{user_text}\n\n[æœå°‹æ‘˜è¦]\n{summaries}"
                    )
                    report = run_async(Runner.run(writer_agent, writer_input))

                    st.markdown("### ğŸ“‹ Executive Summary")
                    paragraph_type_with_fade(report.final_output.short_summary, fade_ms=120)

                    st.markdown("### ğŸ“– å®Œæ•´å ±å‘Š")
                    paragraph_type_with_fade(report.final_output.markdown_report, fade_ms=160)

                    st.markdown("### â“ å¾ŒçºŒå»ºè­°å•é¡Œ")
                    for q in report.final_output.follow_up_questions:
                        paragraph_type_with_fade(q, fade_ms=100)

                    ai_reply = (
                        plan_md + "\n" +
                        summary_md + "\n" +
                        "#### Executive Summary\n" + report.final_output.short_summary + "\n" +
                        "#### å®Œæ•´å ±å‘Š\n" + report.final_output.markdown_report + "\n" +
                        "#### å¾ŒçºŒå»ºè­°å•é¡Œ\n" + "\n".join([f"- {q}" for q in report.final_output.follow_up_questions])
                    )
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_reply,
                        "images": []
                    })

                else:
                    # ä¸€èˆ¬å°è©±
                    full_text = str(router_result.final_output)
                    paragraph_type_with_fade(full_text, prefix_emoji="ğŸŒ¸", fade_ms=360)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": full_text,
                        "images": []
                    })
